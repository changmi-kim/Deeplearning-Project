{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손 동작 인식\n",
    "- 01. LSTM\n",
    "- 02. KNN\n",
    "- 03. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 12:21:30.632211: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-13 12:21:30.632252: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-13 12:21:30.633226: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-13 12:21:30.642898: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 12:21:31.637874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, activations, initializers, losses, optimizers, metrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 확인\n",
    "# npy_data = np.load('./dataset/seq_go_1700819427.npy')\n",
    "# npy_data = np.load('./dataset/seq_back_1700819496.npy')\n",
    "# npy_data = np.load('./dataset/seq_go_1700819427.npy')\n",
    "# npy_data = np.load('./dataset/seq_go_1700819427.npy')\n",
    "# npy_data = np.load('./dataset/seq_go_1700819427.npy')\n",
    "\n",
    "# print(npy_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 4.94774967e-01  3.51795256e-01 -3.25392330e-06 ...  8.35602570e+00\n",
      "    9.24419403e+00  1.00000000e+00]\n",
      "  [ 5.27333975e-01  3.01514894e-01 -1.54961290e-05 ...  5.74501944e+00\n",
      "    1.93553519e+00  1.00000000e+00]\n",
      "  [ 5.35418749e-01  2.92026222e-01 -5.74814585e-05 ...  7.16517448e+00\n",
      "    5.56461620e+00  1.00000000e+00]\n",
      "  ...\n",
      "  [ 5.43501794e-01  2.69603789e-01 -7.90387930e-05 ...  7.59894466e+00\n",
      "    2.94394970e+00  1.00000000e+00]\n",
      "  [ 5.44378996e-01  2.69676566e-01 -1.14748429e-04 ...  1.72810173e+00\n",
      "    2.50596070e+00  1.00000000e+00]\n",
      "  [ 5.57296395e-01  2.65040636e-01 -1.08185253e-04 ...  4.28049469e+00\n",
      "    4.65404654e+00  1.00000000e+00]]\n",
      "\n",
      " [[ 5.27333975e-01  3.01514894e-01 -1.54961290e-05 ...  5.74501944e+00\n",
      "    1.93553519e+00  1.00000000e+00]\n",
      "  [ 5.35418749e-01  2.92026222e-01 -5.74814585e-05 ...  7.16517448e+00\n",
      "    5.56461620e+00  1.00000000e+00]\n",
      "  [ 5.39594948e-01  2.76303411e-01 -1.18120872e-04 ...  6.02782917e+00\n",
      "    3.02525759e+00  1.00000000e+00]\n",
      "  ...\n",
      "  [ 5.44378996e-01  2.69676566e-01 -1.14748429e-04 ...  1.72810173e+00\n",
      "    2.50596070e+00  1.00000000e+00]\n",
      "  [ 5.57296395e-01  2.65040636e-01 -1.08185253e-04 ...  4.28049469e+00\n",
      "    4.65404654e+00  1.00000000e+00]\n",
      "  [ 5.53937495e-01  2.74522454e-01 -1.22505080e-04 ...  8.44587231e+00\n",
      "    4.80651331e+00  1.00000000e+00]]\n",
      "\n",
      " [[ 5.35418749e-01  2.92026222e-01 -5.74814585e-05 ...  7.16517448e+00\n",
      "    5.56461620e+00  1.00000000e+00]\n",
      "  [ 5.39594948e-01  2.76303411e-01 -1.18120872e-04 ...  6.02782917e+00\n",
      "    3.02525759e+00  1.00000000e+00]\n",
      "  [ 5.41977108e-01  2.46277452e-01 -4.99049856e-05 ...  2.96383929e+00\n",
      "    2.13758779e+00  1.00000000e+00]\n",
      "  ...\n",
      "  [ 5.57296395e-01  2.65040636e-01 -1.08185253e-04 ...  4.28049469e+00\n",
      "    4.65404654e+00  1.00000000e+00]\n",
      "  [ 5.53937495e-01  2.74522454e-01 -1.22505080e-04 ...  8.44587231e+00\n",
      "    4.80651331e+00  1.00000000e+00]\n",
      "  [ 5.55792749e-01  2.69241691e-01 -1.65982303e-04 ...  7.39400101e+00\n",
      "    6.26712132e+00  1.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 4.46078986e-01  2.76519179e-01 -5.54130856e-05 ...  2.43936348e+00\n",
      "    6.08118153e+00  1.00000000e+00]\n",
      "  [ 4.36179936e-01  2.65904903e-01 -1.07652937e-04 ...  3.03486300e+00\n",
      "    3.23777199e+00  1.00000000e+00]\n",
      "  [ 4.27479118e-01  2.74563193e-01 -8.38683845e-05 ...  4.76090860e+00\n",
      "    4.82146406e+00  1.00000000e+00]\n",
      "  ...\n",
      "  [ 5.81443608e-01  2.27592826e-01 -9.30710085e-05 ...  5.96239948e+00\n",
      "    2.49528837e+00  1.00000000e+00]\n",
      "  [ 5.85794330e-01  2.36064404e-01 -6.33452728e-05 ...  3.78040218e+00\n",
      "    2.22436309e+00  1.00000000e+00]\n",
      "  [ 6.01231813e-01  2.19597816e-01 -3.90780770e-05 ...  1.55313146e+00\n",
      "    1.22960830e+00  1.00000000e+00]]\n",
      "\n",
      " [[ 4.36179936e-01  2.65904903e-01 -1.07652937e-04 ...  3.03486300e+00\n",
      "    3.23777199e+00  1.00000000e+00]\n",
      "  [ 4.27479118e-01  2.74563193e-01 -8.38683845e-05 ...  4.76090860e+00\n",
      "    4.82146406e+00  1.00000000e+00]\n",
      "  [ 4.21196818e-01  2.86400497e-01 -6.27232148e-05 ...  2.94642591e+00\n",
      "    5.99371147e+00  1.00000000e+00]\n",
      "  ...\n",
      "  [ 5.85794330e-01  2.36064404e-01 -6.33452728e-05 ...  3.78040218e+00\n",
      "    2.22436309e+00  1.00000000e+00]\n",
      "  [ 6.01231813e-01  2.19597816e-01 -3.90780770e-05 ...  1.55313146e+00\n",
      "    1.22960830e+00  1.00000000e+00]\n",
      "  [ 6.10157669e-01  2.25817755e-01 -9.01116364e-05 ...  2.76027656e+00\n",
      "    4.85850239e+00  1.00000000e+00]]\n",
      "\n",
      " [[ 4.27479118e-01  2.74563193e-01 -8.38683845e-05 ...  4.76090860e+00\n",
      "    4.82146406e+00  1.00000000e+00]\n",
      "  [ 4.21196818e-01  2.86400497e-01 -6.27232148e-05 ...  2.94642591e+00\n",
      "    5.99371147e+00  1.00000000e+00]\n",
      "  [ 4.27871794e-01  2.92782843e-01 -1.21998601e-04 ...  1.40872192e+00\n",
      "    4.55137587e+00  1.00000000e+00]\n",
      "  ...\n",
      "  [ 6.01231813e-01  2.19597816e-01 -3.90780770e-05 ...  1.55313146e+00\n",
      "    1.22960830e+00  1.00000000e+00]\n",
      "  [ 6.10157669e-01  2.25817755e-01 -9.01116364e-05 ...  2.76027656e+00\n",
      "    4.85850239e+00  1.00000000e+00]\n",
      "  [ 6.19367480e-01  1.74892187e-01 -6.10324751e-05 ...  1.03726614e+00\n",
      "    2.28914738e+00  1.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "# npy_data = np.load('../data/dataset_opensource_bbang/raw_away_1627646273.npy')\n",
    "npy_data = np.load(\"../data/dataset_opensource_bbang/seq_away_1627646273.npy\")\n",
    "\n",
    "print(npy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-1. LSTM - 데이터셋 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m secs_for_action \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 미디어파이프 패키지에서 손 인식을 위한 객체 생성\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m mp_hands \u001b[38;5;241m=\u001b[39m \u001b[43mmp\u001b[49m\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mhands\n\u001b[1;32m     11\u001b[0m mp_drawing \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mdrawing_utils\n\u001b[1;32m     13\u001b[0m hands \u001b[38;5;241m=\u001b[39m mp_hands\u001b[38;5;241m.\u001b[39mHands(\n\u001b[1;32m     14\u001b[0m     max_num_hands \u001b[38;5;241m=\u001b[39m max_num_hands,\n\u001b[1;32m     15\u001b[0m     min_detection_confidence \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m     16\u001b[0m     min_tracking_confidence \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mp' is not defined"
     ]
    }
   ],
   "source": [
    "max_num_hands = 1\n",
    "actions = ['back']\n",
    "# actions = ['go', 'back', 'stop', 'left_spin', 'right_spin', 'speed_up', 'speed_down', 'bad_gesture']\n",
    "\n",
    "# 시퀀스 길이 지정\n",
    "seq_length = 40\n",
    "secs_for_action = 2\n",
    "\n",
    "# 미디어파이프 패키지에서 손 인식을 위한 객체 생성\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands = max_num_hands,\n",
    "    min_detection_confidence = 0.5,\n",
    "    min_tracking_confidence = 0.5)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "created_time = str(time.strftime('%X', time.localtime(time.time())))\n",
    "# exist_ok를 True로 설정하지 않았을 땐, 해당 디렉토리가 존재하는 경우 exception 에러 발생\n",
    "os.makedirs('../data/dataset', exist_ok=True)\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    for idx, action in enumerate(actions):\n",
    "\n",
    "        data = []\n",
    "\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            print(\"카메라 연결 실패\")\n",
    "            # break\n",
    "            continue\n",
    "\n",
    "        img = cv2.flip(img, 1)\n",
    "        cv2.putText(img, f'Waiting for collecting {action.upper()} action...', org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "        cv2.imshow('Dataset', img)\n",
    "        cv2.waitKey(3000)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        while time.time() - start_time < secs_for_action:\n",
    "\n",
    "            ret, img = cap.read()\n",
    "            img = cv2.flip(img, 1)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            result = hands.process(img)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            if result.multi_hand_landmarks is not None:\n",
    "\n",
    "                for res in result.multi_hand_landmarks:\n",
    "\n",
    "                    joint = np.zeros((21, 4))\n",
    "\n",
    "                    for j, lm in enumerate(res.landmark):\n",
    "                        \n",
    "                        joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "\n",
    "                    v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3]\n",
    "                    v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3]\n",
    "                    v = v2 - v1\n",
    "\n",
    "                    v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "                    angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                        v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                        v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:]))\n",
    "\n",
    "                    angle = np.degrees(angle)\n",
    "\n",
    "                    angle_label = np.array([angle], dtype=np.float32)\n",
    "                    angle_label = np.append(angle_label, 0)\n",
    "\n",
    "                    d = np.concatenate([joint.flatten(), angle_label])\n",
    "\n",
    "                    data.append(d)\n",
    "                    # print(data)\n",
    "\n",
    "                    mp_drawing.draw_landmarks(img,\n",
    "                            res,\n",
    "                            mp_hands.HAND_CONNECTIONS\n",
    "                        #   mp_hands.get_default_hand_landmarks_style(),\n",
    "                        #   mp_hands.get_default_hand_connections_style()\n",
    "                    )\n",
    "\n",
    "            cv2.imshow('Dataset', img)\n",
    "            \n",
    "            key = cv2.waitKey(5) & 0xFF\n",
    "            \n",
    "            if key == 27:  # ESC를 눌렀을 경우\n",
    "                cv2.destroyAllWindows()\n",
    "                cap.release()  # 비디오 캡처 객체 해제\n",
    "                break\n",
    "\n",
    "        data = np.array(data)\n",
    "        print(action, data.shape)\n",
    "        np.save(os.path.join('../data', f'raw_{action}_{created_time}'), data)\n",
    "\n",
    "        # seq 데이터 저장\n",
    "        full_seq_data = []\n",
    "        for seq in range(len(data) - seq_length):\n",
    "            full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "        full_seq_data = np.array(full_seq_data)\n",
    "        print(action, full_seq_data.shape)\n",
    "        np.save(os.path.join('../data', f'seq_{action}_{created_time}'), full_seq_data)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-2. LSTM - 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_go = np.loadtxt('../data/dataset_10_231211/go_04:54:34 PM.csv', delimiter=',')\n",
    "data_back= np.loadtxt('../data/dataset_10_231211/back_04:55:04 PM.csv', delimiter=',')\n",
    "data_stop= np.loadtxt('../data/dataset_10_231211/stop_04:55:31 PM.csv', delimiter=',')\n",
    "data_left= np.loadtxt('../data/dataset_10_231211/left_spin_04:55:49 PM.csv', delimiter=',')\n",
    "data_right= np.loadtxt('../data/dataset_10_231211/right_spin_04:56:08 PM.csv', delimiter=',')\n",
    "data_up= np.loadtxt('../data/dataset_10_231211/speed_up_04:57:54 PM.csv', delimiter=',')\n",
    "data_down= np.loadtxt('../data/dataset_10_231211/speed_down_04:58:18 PM.csv', delimiter=',')\n",
    "data_bad= np.loadtxt('../data/dataset_10_231211/bad_gesture_05:00:03 PM.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 4\n",
    "full_seq_data = []\n",
    "\n",
    "for seq in range(len(data) - seq_length):\n",
    "    full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "full_seq_data = np.array(full_seq_data)\n",
    "np.save('../data/dataset_10_231211/go_04:54:34 PM.npy', full_seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_list_csv: ['left_spin_04:55:49 PM.csv', 'stop_04:55:31 PM.csv', 'back_04:55:04 PM.csv', 'speed_down_04:58:18 PM.csv', 'right_spin_04:56:08 PM.csv', 'bad_gesture_05:00:03 PM.csv', 'go_04:54:34 PM.csv', 'speed_up_04:57:54 PM.csv']\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/dataset_10_231211/\"\n",
    "file_list = os.listdir(path)\n",
    "file_list_csv = [file for file in file_list if file.endswith(\".csv\")]\n",
    "\n",
    "for idx, item in enumerate(file_list_csv):\n",
    "    if 'total' in item:\n",
    "        file_list_csv.pop(idx)\n",
    "        \n",
    "print (\"file_list_csv: {}\".format(file_list_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 4\n",
    "path = \"../data/dataset_10_231211/\"\n",
    "\n",
    "for i in file_list_csv:\n",
    "\n",
    "    data = np.loadtxt(os.path.join(path, i), delimiter=',')\n",
    "    \n",
    "    full_seq_data = []\n",
    "\n",
    "    for seq in range(len(data) - seq_length):\n",
    "        full_seq_data.append(data[seq:seq + seq_length])\n",
    "\n",
    "    full_seq_data = np.array(full_seq_data)\n",
    "    file_name = i[:-3] + 'npy'\n",
    "    \n",
    "    np.save(os.path.join(path, file_name), full_seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[25.22230721 11.00061989  3.74292803  8.67022514  4.13462257\n",
      "    4.78328991  6.38954878  4.63100338  2.95631075 11.21782017\n",
      "    2.8860054   4.35454798  9.90952969  5.00848675  4.92671442\n",
      "    0.        ]\n",
      "  [20.90683365  0.82439792 14.36915016 11.35307789  2.78413177\n",
      "    4.70296955  7.14317322  3.27179718  3.34591889  6.6673975\n",
      "    1.08580434  4.81011009  9.88743019  5.01040792  6.5122242\n",
      "    0.        ]\n",
      "  [22.68040085  2.81343961  9.87323856  7.59725952  5.36380768\n",
      "    5.19823265  6.05508327  3.62320542  3.59546733 11.55345631\n",
      "    1.74758208  3.29339623 19.27939987  6.60300875  2.85511494\n",
      "    0.        ]\n",
      "  [32.37450409 14.99724197  5.6236968   8.32962132  3.99058628\n",
      "    4.90189457  5.78559017  4.96204185  3.32574391 11.64232349\n",
      "    1.98341656  2.88235879 20.65109825  3.5706706   2.50652409\n",
      "    0.        ]]\n",
      "\n",
      " [[20.90683365  0.82439792 14.36915016 11.35307789  2.78413177\n",
      "    4.70296955  7.14317322  3.27179718  3.34591889  6.6673975\n",
      "    1.08580434  4.81011009  9.88743019  5.01040792  6.5122242\n",
      "    0.        ]\n",
      "  [22.68040085  2.81343961  9.87323856  7.59725952  5.36380768\n",
      "    5.19823265  6.05508327  3.62320542  3.59546733 11.55345631\n",
      "    1.74758208  3.29339623 19.27939987  6.60300875  2.85511494\n",
      "    0.        ]\n",
      "  [32.37450409 14.99724197  5.6236968   8.32962132  3.99058628\n",
      "    4.90189457  5.78559017  4.96204185  3.32574391 11.64232349\n",
      "    1.98341656  2.88235879 20.65109825  3.5706706   2.50652409\n",
      "    0.        ]\n",
      "  [26.88437653 16.65114403  2.95811677 13.33452225  7.50809956\n",
      "    7.31458282 10.07243347  7.10538721  5.85189772 14.24841976\n",
      "    3.48434567  5.47686148 22.39838409  5.61053944  4.7468071\n",
      "    0.        ]]\n",
      "\n",
      " [[22.68040085  2.81343961  9.87323856  7.59725952  5.36380768\n",
      "    5.19823265  6.05508327  3.62320542  3.59546733 11.55345631\n",
      "    1.74758208  3.29339623 19.27939987  6.60300875  2.85511494\n",
      "    0.        ]\n",
      "  [32.37450409 14.99724197  5.6236968   8.32962132  3.99058628\n",
      "    4.90189457  5.78559017  4.96204185  3.32574391 11.64232349\n",
      "    1.98341656  2.88235879 20.65109825  3.5706706   2.50652409\n",
      "    0.        ]\n",
      "  [26.88437653 16.65114403  2.95811677 13.33452225  7.50809956\n",
      "    7.31458282 10.07243347  7.10538721  5.85189772 14.24841976\n",
      "    3.48434567  5.47686148 22.39838409  5.61053944  4.7468071\n",
      "    0.        ]\n",
      "  [30.12934685 17.28508759  2.29074454 10.22429657  5.98873615\n",
      "    3.18803716  6.88014984  6.9294405   2.16016698 11.53809452\n",
      "    3.08419371  2.17876172 16.52121544  4.07085037  2.51624465\n",
      "    0.        ]]\n",
      "\n",
      " [[32.37450409 14.99724197  5.6236968   8.32962132  3.99058628\n",
      "    4.90189457  5.78559017  4.96204185  3.32574391 11.64232349\n",
      "    1.98341656  2.88235879 20.65109825  3.5706706   2.50652409\n",
      "    0.        ]\n",
      "  [26.88437653 16.65114403  2.95811677 13.33452225  7.50809956\n",
      "    7.31458282 10.07243347  7.10538721  5.85189772 14.24841976\n",
      "    3.48434567  5.47686148 22.39838409  5.61053944  4.7468071\n",
      "    0.        ]\n",
      "  [30.12934685 17.28508759  2.29074454 10.22429657  5.98873615\n",
      "    3.18803716  6.88014984  6.9294405   2.16016698 11.53809452\n",
      "    3.08419371  2.17876172 16.52121544  4.07085037  2.51624465\n",
      "    0.        ]\n",
      "  [28.69950676 16.26829338  2.73366165 10.84986877  4.85259485\n",
      "    4.07710695  9.16573524  5.62209749  2.72780061 10.96872044\n",
      "    2.39226079  3.71879673  5.64820433  3.71242595  4.79387474\n",
      "    0.        ]]\n",
      "\n",
      " [[26.88437653 16.65114403  2.95811677 13.33452225  7.50809956\n",
      "    7.31458282 10.07243347  7.10538721  5.85189772 14.24841976\n",
      "    3.48434567  5.47686148 22.39838409  5.61053944  4.7468071\n",
      "    0.        ]\n",
      "  [30.12934685 17.28508759  2.29074454 10.22429657  5.98873615\n",
      "    3.18803716  6.88014984  6.9294405   2.16016698 11.53809452\n",
      "    3.08419371  2.17876172 16.52121544  4.07085037  2.51624465\n",
      "    0.        ]\n",
      "  [28.69950676 16.26829338  2.73366165 10.84986877  4.85259485\n",
      "    4.07710695  9.16573524  5.62209749  2.72780061 10.96872044\n",
      "    2.39226079  3.71879673  5.64820433  3.71242595  4.79387474\n",
      "    0.        ]\n",
      "  [23.18796158  8.02673531  4.46659517 11.31622601  4.44058371\n",
      "    5.29603004  8.50949097  3.63649058  3.08611965  5.90082979\n",
      "    2.0002718   4.14872551 13.67386055  6.73467588  2.74633384\n",
      "    0.        ]]\n",
      "\n",
      " [[30.12934685 17.28508759  2.29074454 10.22429657  5.98873615\n",
      "    3.18803716  6.88014984  6.9294405   2.16016698 11.53809452\n",
      "    3.08419371  2.17876172 16.52121544  4.07085037  2.51624465\n",
      "    0.        ]\n",
      "  [28.69950676 16.26829338  2.73366165 10.84986877  4.85259485\n",
      "    4.07710695  9.16573524  5.62209749  2.72780061 10.96872044\n",
      "    2.39226079  3.71879673  5.64820433  3.71242595  4.79387474\n",
      "    0.        ]\n",
      "  [23.18796158  8.02673531  4.46659517 11.31622601  4.44058371\n",
      "    5.29603004  8.50949097  3.63649058  3.08611965  5.90082979\n",
      "    2.0002718   4.14872551 13.67386055  6.73467588  2.74633384\n",
      "    0.        ]\n",
      "  [23.59089661  5.754426    8.55853844  6.75881624  4.54353762\n",
      "    5.40046406  7.44827652  3.17004395  3.66287827 12.06697464\n",
      "    1.81731105  3.35413265 20.35484505  6.19600677  2.98365307\n",
      "    0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "npy_data_create = np.load('../data/dataset_10_231211/go_04:54:34 PM.npy')\n",
    "print(npy_data_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4, 16)\n"
     ]
    }
   ],
   "source": [
    "print(npy_data_create.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 4, 16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = ['go', 'back', 'stop', 'left_spin', 'right_spin', 'speed_up', 'speed_down', 'bad_gesture']\n",
    "\n",
    "# 8가지 제스처\n",
    "data = np.concatenate([\n",
    "    np.load('../data/dataset_10_231211/go_04:54:34 PM.npy'),\n",
    "    np.load('../data/dataset_10_231211/back_04:55:04 PM.npy'),\n",
    "    np.load('../data/dataset_10_231211/stop_04:55:31 PM.npy'),\n",
    "    np.load('../data/dataset_10_231211/left_spin_04:55:49 PM.npy'),\n",
    "    np.load('../data/dataset_10_231211/right_spin_04:56:08 PM.npy'),\n",
    "    np.load('../data/dataset_10_231211/speed_up_04:57:54 PM.npy'),\n",
    "    np.load('../data/dataset_10_231211/speed_down_04:58:18 PM.npy'),\n",
    "    np.load('../data/dataset_10_231211/bad_gesture_05:00:03 PM.npy')\n",
    "], axis=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 4, 15)\n",
      "(48,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = to_categorical(labels, num_classes=None)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 4, 15) (38, 8)\n",
      "(10, 4, 15) (10, 8)\n"
     ]
    }
   ],
   "source": [
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 64)                20480     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22824 (89.16 KB)\n",
      "Trainable params: 22824 (89.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 1s - loss: 26.7493 - acc: 0.1875\n",
      "Epoch 1: val_acc improved from -inf to 0.40000, saving model to ../model/model_.h5\n",
      "2/2 [==============================] - 2s 326ms/step - loss: 25.4997 - acc: 0.1842 - val_loss: 13.6725 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 15.9046 - acc: 0.1562\n",
      "Epoch 2: val_acc did not improve from 0.40000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 16.2563 - acc: 0.1579 - val_loss: 11.5418 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 11.3148 - acc: 0.1250\n",
      "Epoch 3: val_acc did not improve from 0.40000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 11.3483 - acc: 0.1316 - val_loss: 9.4076 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.6191 - acc: 0.2188\n",
      "Epoch 4: val_acc did not improve from 0.40000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 7.7380 - acc: 0.2105 - val_loss: 7.9806 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 5.4857 - acc: 0.2500\n",
      "Epoch 5: val_acc did not improve from 0.40000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 5.3072 - acc: 0.2632 - val_loss: 7.4576 - val_acc: 0.3000 - lr: 0.0010\n",
      "Epoch 6/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 0s - loss: 4.3543 - acc: 0.3438\n",
      "Epoch 6: val_acc did not improve from 0.40000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.8906 - acc: 0.3947 - val_loss: 7.1433 - val_acc: 0.3000 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.9655 - acc: 0.3438\n",
      "Epoch 7: val_acc did not improve from 0.40000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.7984 - acc: 0.3947 - val_loss: 6.7569 - val_acc: 0.3000 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5743 - acc: 0.5000\n",
      "Epoch 8: val_acc did not improve from 0.40000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.6596 - acc: 0.5000 - val_loss: 6.2581 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9035 - acc: 0.7188\n",
      "Epoch 9: val_acc did not improve from 0.40000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0910 - acc: 0.7105 - val_loss: 5.7290 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.9039 - acc: 0.7812\n",
      "Epoch 10: val_acc improved from 0.40000 to 0.50000, saving model to ../model/model_.h5\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.8247 - acc: 0.7895 - val_loss: 5.4475 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5780 - acc: 0.7812\n",
      "Epoch 11: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4947 - acc: 0.8158 - val_loss: 5.3714 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2131 - acc: 0.9375\n",
      "Epoch 12: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1873 - acc: 0.9474 - val_loss: 5.3894 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1171 - acc: 1.0000\n",
      "Epoch 13: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1076 - acc: 1.0000 - val_loss: 5.4691 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0573 - acc: 1.0000\n",
      "Epoch 14: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0636 - acc: 1.0000 - val_loss: 5.4438 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0435 - acc: 1.0000\n",
      "Epoch 15: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0432 - acc: 1.0000 - val_loss: 5.3686 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0312 - acc: 1.0000\n",
      "Epoch 16: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0295 - acc: 1.0000 - val_loss: 5.3165 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 17: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0230 - acc: 1.0000 - val_loss: 5.2840 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 18: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0189 - acc: 1.0000 - val_loss: 5.2518 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 19: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 5.2049 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 20: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 5.1400 - val_acc: 0.4000 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 21: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 5.0748 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 22: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 5.0293 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 23: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 5.0019 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 24: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 4.9886 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 25: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 4.9871 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 26: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 4.9851 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 27: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 4.9762 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 28: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 4.9580 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 29: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 4.9396 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 30: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 4.9219 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 31: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 4.9036 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.6718e-04 - acc: 1.0000\n",
      "Epoch 32: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 4.8883 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 33: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 4.8758 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 34: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 4.8641 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 35: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 4.8533 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.7755e-04 - acc: 1.0000\n",
      "Epoch 36: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 9.8650e-04 - acc: 1.0000 - val_loss: 4.8434 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.0883e-04 - acc: 1.0000\n",
      "Epoch 37: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 9.1994e-04 - acc: 1.0000 - val_loss: 4.8346 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.0774e-04 - acc: 1.0000\n",
      "Epoch 38: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 8.4554e-04 - acc: 1.0000 - val_loss: 4.8266 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.6512e-04 - acc: 1.0000\n",
      "Epoch 39: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 7.3632e-04 - acc: 1.0000 - val_loss: 4.8186 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 5.7557e-04 - acc: 1.0000\n",
      "Epoch 40: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 6.3095e-04 - acc: 1.0000 - val_loss: 4.8111 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 5.5102e-04 - acc: 1.0000\n",
      "Epoch 41: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 5.0560e-04 - acc: 1.0000 - val_loss: 4.8052 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 4.8717e-04 - acc: 1.0000\n",
      "Epoch 42: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 4.4685e-04 - acc: 1.0000 - val_loss: 4.8002 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 4.1322e-04 - acc: 1.0000\n",
      "Epoch 43: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 4.5124e-04 - acc: 1.0000 - val_loss: 4.7965 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 5.0011e-04 - acc: 1.0000\n",
      "Epoch 44: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 4.5876e-04 - acc: 1.0000 - val_loss: 4.7941 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.9465e-04 - acc: 1.0000\n",
      "Epoch 45: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.7545e-04 - acc: 1.0000 - val_loss: 4.7929 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.5137e-04 - acc: 1.0000\n",
      "Epoch 46: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.2391e-04 - acc: 1.0000 - val_loss: 4.7927 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.4820e-04 - acc: 1.0000\n",
      "Epoch 47: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.1414e-04 - acc: 1.0000 - val_loss: 4.7927 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0242e-04 - acc: 1.0000\n",
      "Epoch 48: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.9398e-04 - acc: 1.0000 - val_loss: 4.7922 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.9198e-04 - acc: 1.0000\n",
      "Epoch 49: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.7437e-04 - acc: 1.0000 - val_loss: 4.7915 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0345e-04 - acc: 1.0000\n",
      "Epoch 50: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.3909e-04 - acc: 1.0000 - val_loss: 4.7896 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2736e-04 - acc: 1.0000\n",
      "Epoch 51: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.0627e-04 - acc: 1.0000 - val_loss: 4.7833 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.9181e-04 - acc: 1.0000\n",
      "Epoch 52: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.6901e-04 - acc: 1.0000 - val_loss: 4.7791 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4736e-04 - acc: 1.0000\n",
      "Epoch 53: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.4850e-04 - acc: 1.0000 - val_loss: 4.7711 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5511e-04 - acc: 1.0000\n",
      "Epoch 54: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.3592e-04 - acc: 1.0000 - val_loss: 4.7613 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3872e-04 - acc: 1.0000\n",
      "Epoch 55: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.2993e-04 - acc: 1.0000 - val_loss: 4.7572 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2815e-04 - acc: 1.0000\n",
      "Epoch 56: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1697e-04 - acc: 1.0000 - val_loss: 4.7634 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1318e-04 - acc: 1.0000\n",
      "Epoch 57: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0036e-04 - acc: 1.0000 - val_loss: 4.7750 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.5069e-05 - acc: 1.0000\n",
      "Epoch 58: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 8.8534e-05 - acc: 1.0000 - val_loss: 4.7865 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 5.1658e-05 - acc: 1.0000\n",
      "Epoch 59: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 8.2067e-05 - acc: 1.0000 - val_loss: 4.7939 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.3890e-05 - acc: 1.0000\n",
      "Epoch 60: val_acc did not improve from 0.50000\n",
      "\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 7.6733e-05 - acc: 1.0000 - val_loss: 4.7981 - val_acc: 0.5000 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.5280e-05 - acc: 1.0000\n",
      "Epoch 61: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 7.0822e-05 - acc: 1.0000 - val_loss: 4.7999 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 62/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.7416e-05 - acc: 1.0000\n",
      "Epoch 62: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 6.8395e-05 - acc: 1.0000 - val_loss: 4.8017 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 63/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.6933e-05 - acc: 1.0000\n",
      "Epoch 63: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 6.6323e-05 - acc: 1.0000 - val_loss: 4.8032 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 64/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.0218e-05 - acc: 1.0000\n",
      "Epoch 64: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 6.4376e-05 - acc: 1.0000 - val_loss: 4.8047 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 65/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.1001e-05 - acc: 1.0000\n",
      "Epoch 65: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 6.3015e-05 - acc: 1.0000 - val_loss: 4.8060 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 66/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.2961e-05 - acc: 1.0000\n",
      "Epoch 66: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 6.1848e-05 - acc: 1.0000 - val_loss: 4.8045 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 67/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 5.5707e-05 - acc: 1.0000\n",
      "Epoch 67: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 6.0466e-05 - acc: 1.0000 - val_loss: 4.8065 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 68/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.5422e-05 - acc: 1.0000\n",
      "Epoch 68: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 5.8957e-05 - acc: 1.0000 - val_loss: 4.8119 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 69/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.1869e-05 - acc: 1.0000\n",
      "Epoch 69: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 5.7749e-05 - acc: 1.0000 - val_loss: 4.8153 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 70/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.1801e-05 - acc: 1.0000\n",
      "Epoch 70: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.7366e-05 - acc: 1.0000 - val_loss: 4.8154 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 71/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.0356e-05 - acc: 1.0000\n",
      "Epoch 71: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 5.6053e-05 - acc: 1.0000 - val_loss: 4.8118 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 72/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 5.5880e-05 - acc: 1.0000\n",
      "Epoch 72: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 5.4087e-05 - acc: 1.0000 - val_loss: 4.8078 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 73/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.0668e-05 - acc: 1.0000\n",
      "Epoch 73: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 5.2312e-05 - acc: 1.0000 - val_loss: 4.8017 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 74/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 5.4481e-05 - acc: 1.0000\n",
      "Epoch 74: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 5.1215e-05 - acc: 1.0000 - val_loss: 4.7884 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 75/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.8423e-05 - acc: 1.0000\n",
      "Epoch 75: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 5.0061e-05 - acc: 1.0000 - val_loss: 4.7754 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 76/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 5.5026e-05 - acc: 1.0000\n",
      "Epoch 76: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 4.9447e-05 - acc: 1.0000 - val_loss: 4.7624 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 77/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 5.1656e-05 - acc: 1.0000\n",
      "Epoch 77: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4.8346e-05 - acc: 1.0000 - val_loss: 4.7519 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 78/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 4.4955e-05 - acc: 1.0000\n",
      "Epoch 78: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 4.7355e-05 - acc: 1.0000 - val_loss: 4.7434 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 79/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.6381e-05 - acc: 1.0000\n",
      "Epoch 79: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.6186e-05 - acc: 1.0000 - val_loss: 4.7360 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 80/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.5975e-05 - acc: 1.0000\n",
      "Epoch 80: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 4.5032e-05 - acc: 1.0000 - val_loss: 4.7272 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 81/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 5.1259e-05 - acc: 1.0000\n",
      "Epoch 81: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4.4235e-05 - acc: 1.0000 - val_loss: 4.7185 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 82/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 4.4923e-05 - acc: 1.0000\n",
      "Epoch 82: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 4.3072e-05 - acc: 1.0000 - val_loss: 4.7124 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 83/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.4660e-05 - acc: 1.0000\n",
      "Epoch 83: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 4.1714e-05 - acc: 1.0000 - val_loss: 4.7073 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 84/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.9911e-05 - acc: 1.0000\n",
      "Epoch 84: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 4.1024e-05 - acc: 1.0000 - val_loss: 4.7073 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 85/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 4.3315e-05 - acc: 1.0000\n",
      "Epoch 85: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.9644e-05 - acc: 1.0000 - val_loss: 4.7145 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 86/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.7803e-05 - acc: 1.0000\n",
      "Epoch 86: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.8274e-05 - acc: 1.0000 - val_loss: 4.7200 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 87/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.9341e-05 - acc: 1.0000\n",
      "Epoch 87: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.7160e-05 - acc: 1.0000 - val_loss: 4.7231 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 88/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 4.0124e-05 - acc: 1.0000\n",
      "Epoch 88: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.6201e-05 - acc: 1.0000 - val_loss: 4.7245 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 89/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.5713e-05 - acc: 1.0000\n",
      "Epoch 89: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.5319e-05 - acc: 1.0000 - val_loss: 4.7264 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 90/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 4.0470e-05 - acc: 1.0000\n",
      "Epoch 90: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.4783e-05 - acc: 1.0000 - val_loss: 4.7284 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 91/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.1303e-05 - acc: 1.0000\n",
      "Epoch 91: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.4212e-05 - acc: 1.0000 - val_loss: 4.7283 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 92/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0894e-05 - acc: 1.0000\n",
      "Epoch 92: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.3679e-05 - acc: 1.0000 - val_loss: 4.7230 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 93/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.8720e-05 - acc: 1.0000\n",
      "Epoch 93: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.2983e-05 - acc: 1.0000 - val_loss: 4.7118 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 94/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.6947e-05 - acc: 1.0000\n",
      "Epoch 94: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.2048e-05 - acc: 1.0000 - val_loss: 4.7013 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 95/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2038e-05 - acc: 1.0000\n",
      "Epoch 95: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 3.0922e-05 - acc: 1.0000 - val_loss: 4.6882 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 96/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.1081e-05 - acc: 1.0000\n",
      "Epoch 96: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.0643e-05 - acc: 1.0000 - val_loss: 4.6754 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 97/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.2534e-05 - acc: 1.0000\n",
      "Epoch 97: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.9737e-05 - acc: 1.0000 - val_loss: 4.6684 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 98/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2924e-05 - acc: 1.0000\n",
      "Epoch 98: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.8909e-05 - acc: 1.0000 - val_loss: 4.6603 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 99/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3.2400e-05 - acc: 1.0000\n",
      "Epoch 99: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.8492e-05 - acc: 1.0000 - val_loss: 4.6516 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 100/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.7408e-05 - acc: 1.0000\n",
      "Epoch 100: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.7880e-05 - acc: 1.0000 - val_loss: 4.6454 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 101/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.4000e-05 - acc: 1.0000\n",
      "Epoch 101: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.7300e-05 - acc: 1.0000 - val_loss: 4.6424 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 102/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.6422e-05 - acc: 1.0000\n",
      "Epoch 102: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.6758e-05 - acc: 1.0000 - val_loss: 4.6422 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 103/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.9923e-05 - acc: 1.0000\n",
      "Epoch 103: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.6036e-05 - acc: 1.0000 - val_loss: 4.6456 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 104/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.7144e-05 - acc: 1.0000\n",
      "Epoch 104: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.5399e-05 - acc: 1.0000 - val_loss: 4.6488 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 105/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.5707e-05 - acc: 1.0000\n",
      "Epoch 105: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2.4800e-05 - acc: 1.0000 - val_loss: 4.6510 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 106/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.5517e-05 - acc: 1.0000\n",
      "Epoch 106: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.4204e-05 - acc: 1.0000 - val_loss: 4.6515 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 107/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0477e-05 - acc: 1.0000\n",
      "Epoch 107: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 2.3514e-05 - acc: 1.0000 - val_loss: 4.6481 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 108/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.3978e-05 - acc: 1.0000\n",
      "Epoch 108: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.2918e-05 - acc: 1.0000 - val_loss: 4.6374 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 109/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.5565e-05 - acc: 1.0000\n",
      "Epoch 109: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.2363e-05 - acc: 1.0000 - val_loss: 4.6304 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 110/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0410e-05 - acc: 1.0000\n",
      "Epoch 110: val_acc did not improve from 0.50000\n",
      "\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 2.1927e-05 - acc: 1.0000 - val_loss: 4.6241 - val_acc: 0.5000 - lr: 5.0000e-04\n",
      "Epoch 111/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.5003e-05 - acc: 1.0000\n",
      "Epoch 111: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.1846e-05 - acc: 1.0000 - val_loss: 4.6213 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 112/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.5461e-05 - acc: 1.0000\n",
      "Epoch 112: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 2.1729e-05 - acc: 1.0000 - val_loss: 4.6215 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 113/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8417e-05 - acc: 1.0000\n",
      "Epoch 113: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.1544e-05 - acc: 1.0000 - val_loss: 4.6274 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 114/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8190e-05 - acc: 1.0000\n",
      "Epoch 114: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2.1124e-05 - acc: 1.0000 - val_loss: 4.6380 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 115/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8395e-05 - acc: 1.0000\n",
      "Epoch 115: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.0277e-05 - acc: 1.0000 - val_loss: 4.6479 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 116/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2358e-05 - acc: 1.0000\n",
      "Epoch 116: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.9967e-05 - acc: 1.0000 - val_loss: 4.6604 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 117/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2772e-05 - acc: 1.0000\n",
      "Epoch 117: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.9609e-05 - acc: 1.0000 - val_loss: 4.6710 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 118/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7847e-05 - acc: 1.0000\n",
      "Epoch 118: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.9468e-05 - acc: 1.0000 - val_loss: 4.6784 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 119/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2217e-05 - acc: 1.0000\n",
      "Epoch 119: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.9418e-05 - acc: 1.0000 - val_loss: 4.6834 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 120/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.1419e-05 - acc: 1.0000\n",
      "Epoch 120: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.9327e-05 - acc: 1.0000 - val_loss: 4.6865 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 121/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.2023e-05 - acc: 1.0000\n",
      "Epoch 121: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.9226e-05 - acc: 1.0000 - val_loss: 4.6889 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 122/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7359e-05 - acc: 1.0000\n",
      "Epoch 122: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.9088e-05 - acc: 1.0000 - val_loss: 4.6892 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 123/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4558e-05 - acc: 1.0000\n",
      "Epoch 123: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.8778e-05 - acc: 1.0000 - val_loss: 4.6843 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 124/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3251e-05 - acc: 1.0000\n",
      "Epoch 124: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.8339e-05 - acc: 1.0000 - val_loss: 4.6747 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 125/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8030e-05 - acc: 1.0000\n",
      "Epoch 125: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.7921e-05 - acc: 1.0000 - val_loss: 4.6632 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 126/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 2.0093e-05 - acc: 1.0000\n",
      "Epoch 126: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.7852e-05 - acc: 1.0000 - val_loss: 4.6522 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 127/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7389e-05 - acc: 1.0000\n",
      "Epoch 127: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.7667e-05 - acc: 1.0000 - val_loss: 4.6443 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 128/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8223e-05 - acc: 1.0000\n",
      "Epoch 128: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.7523e-05 - acc: 1.0000 - val_loss: 4.6389 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 129/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8045e-05 - acc: 1.0000\n",
      "Epoch 129: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.7329e-05 - acc: 1.0000 - val_loss: 4.6341 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 130/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.9173e-05 - acc: 1.0000\n",
      "Epoch 130: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.7256e-05 - acc: 1.0000 - val_loss: 4.6303 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 131/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2364e-05 - acc: 1.0000\n",
      "Epoch 131: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.7100e-05 - acc: 1.0000 - val_loss: 4.6294 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 132/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7508e-05 - acc: 1.0000\n",
      "Epoch 132: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.6949e-05 - acc: 1.0000 - val_loss: 4.6297 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 133/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5545e-05 - acc: 1.0000\n",
      "Epoch 133: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.6720e-05 - acc: 1.0000 - val_loss: 4.6309 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 134/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8447e-05 - acc: 1.0000\n",
      "Epoch 134: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.6547e-05 - acc: 1.0000 - val_loss: 4.6331 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 135/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8104e-05 - acc: 1.0000\n",
      "Epoch 135: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.6253e-05 - acc: 1.0000 - val_loss: 4.6356 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 136/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7076e-05 - acc: 1.0000\n",
      "Epoch 136: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.5989e-05 - acc: 1.0000 - val_loss: 4.6374 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 137/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4107e-05 - acc: 1.0000\n",
      "Epoch 137: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.5779e-05 - acc: 1.0000 - val_loss: 4.6386 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 138/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.8223e-05 - acc: 1.0000\n",
      "Epoch 138: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.5575e-05 - acc: 1.0000 - val_loss: 4.6398 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 139/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.6312e-05 - acc: 1.0000\n",
      "Epoch 139: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.5368e-05 - acc: 1.0000 - val_loss: 4.6404 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 140/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.6257e-05 - acc: 1.0000\n",
      "Epoch 140: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.5208e-05 - acc: 1.0000 - val_loss: 4.6404 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 141/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3872e-05 - acc: 1.0000\n",
      "Epoch 141: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.4998e-05 - acc: 1.0000 - val_loss: 4.6409 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 142/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.6212e-05 - acc: 1.0000\n",
      "Epoch 142: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.4863e-05 - acc: 1.0000 - val_loss: 4.6420 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 143/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.7136e-05 - acc: 1.0000\n",
      "Epoch 143: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.4672e-05 - acc: 1.0000 - val_loss: 4.6428 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 144/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5143e-05 - acc: 1.0000\n",
      "Epoch 144: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.4461e-05 - acc: 1.0000 - val_loss: 4.6435 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 145/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.6096e-05 - acc: 1.0000\n",
      "Epoch 145: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.4355e-05 - acc: 1.0000 - val_loss: 4.6443 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 146/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5392e-05 - acc: 1.0000\n",
      "Epoch 146: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.4176e-05 - acc: 1.0000 - val_loss: 4.6450 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 147/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4383e-05 - acc: 1.0000\n",
      "Epoch 147: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.4016e-05 - acc: 1.0000 - val_loss: 4.6458 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 148/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5135e-05 - acc: 1.0000\n",
      "Epoch 148: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.3912e-05 - acc: 1.0000 - val_loss: 4.6470 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 149/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1120e-05 - acc: 1.0000\n",
      "Epoch 149: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.3800e-05 - acc: 1.0000 - val_loss: 4.6482 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 150/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.6063e-05 - acc: 1.0000\n",
      "Epoch 150: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.3705e-05 - acc: 1.0000 - val_loss: 4.6493 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 151/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4908e-05 - acc: 1.0000\n",
      "Epoch 151: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.3627e-05 - acc: 1.0000 - val_loss: 4.6508 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 152/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4543e-05 - acc: 1.0000\n",
      "Epoch 152: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.3545e-05 - acc: 1.0000 - val_loss: 4.6527 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 153/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.5713e-05 - acc: 1.0000\n",
      "Epoch 153: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.3486e-05 - acc: 1.0000 - val_loss: 4.6548 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 154/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4640e-05 - acc: 1.0000\n",
      "Epoch 154: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.3417e-05 - acc: 1.0000 - val_loss: 4.6566 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 155/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4446e-05 - acc: 1.0000\n",
      "Epoch 155: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.3351e-05 - acc: 1.0000 - val_loss: 4.6582 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 156/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.8209e-06 - acc: 1.0000\n",
      "Epoch 156: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.3288e-05 - acc: 1.0000 - val_loss: 4.6604 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 157/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4942e-05 - acc: 1.0000\n",
      "Epoch 157: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.3229e-05 - acc: 1.0000 - val_loss: 4.6630 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 158/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0736e-05 - acc: 1.0000\n",
      "Epoch 158: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.3160e-05 - acc: 1.0000 - val_loss: 4.6655 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 159/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4543e-05 - acc: 1.0000\n",
      "Epoch 159: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.3103e-05 - acc: 1.0000 - val_loss: 4.6678 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 160/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3165e-05 - acc: 1.0000\n",
      "Epoch 160: val_acc did not improve from 0.50000\n",
      "\n",
      "Epoch 160: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.3044e-05 - acc: 1.0000 - val_loss: 4.6701 - val_acc: 0.5000 - lr: 2.5000e-04\n",
      "Epoch 161/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4066e-05 - acc: 1.0000\n",
      "Epoch 161: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.2996e-05 - acc: 1.0000 - val_loss: 4.6712 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 162/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4223e-05 - acc: 1.0000\n",
      "Epoch 162: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.2949e-05 - acc: 1.0000 - val_loss: 4.6723 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 163/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3422e-05 - acc: 1.0000\n",
      "Epoch 163: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.2937e-05 - acc: 1.0000 - val_loss: 4.6735 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 164/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.8420e-06 - acc: 1.0000\n",
      "Epoch 164: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.2909e-05 - acc: 1.0000 - val_loss: 4.6748 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 165/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3556e-05 - acc: 1.0000\n",
      "Epoch 165: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2874e-05 - acc: 1.0000 - val_loss: 4.6763 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 166/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4819e-05 - acc: 1.0000\n",
      "Epoch 166: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.2846e-05 - acc: 1.0000 - val_loss: 4.6778 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 167/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0084e-05 - acc: 1.0000\n",
      "Epoch 167: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2827e-05 - acc: 1.0000 - val_loss: 4.6793 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 168/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2975e-05 - acc: 1.0000\n",
      "Epoch 168: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2805e-05 - acc: 1.0000 - val_loss: 4.6808 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 169/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 5.3904e-06 - acc: 1.0000\n",
      "Epoch 169: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.2774e-05 - acc: 1.0000 - val_loss: 4.6823 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 170/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4029e-05 - acc: 1.0000\n",
      "Epoch 170: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2755e-05 - acc: 1.0000 - val_loss: 4.6838 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 171/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4733e-05 - acc: 1.0000\n",
      "Epoch 171: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.2708e-05 - acc: 1.0000 - val_loss: 4.6853 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 172/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3668e-05 - acc: 1.0000\n",
      "Epoch 172: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2686e-05 - acc: 1.0000 - val_loss: 4.6867 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 173/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4256e-05 - acc: 1.0000\n",
      "Epoch 173: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2664e-05 - acc: 1.0000 - val_loss: 4.6880 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 174/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3194e-05 - acc: 1.0000\n",
      "Epoch 174: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2633e-05 - acc: 1.0000 - val_loss: 4.6894 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 175/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3019e-05 - acc: 1.0000\n",
      "Epoch 175: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.2601e-05 - acc: 1.0000 - val_loss: 4.6909 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 176/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4323e-05 - acc: 1.0000\n",
      "Epoch 176: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.2576e-05 - acc: 1.0000 - val_loss: 4.6922 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 177/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3243e-05 - acc: 1.0000\n",
      "Epoch 177: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.2545e-05 - acc: 1.0000 - val_loss: 4.6932 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 178/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4509e-05 - acc: 1.0000\n",
      "Epoch 178: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.2517e-05 - acc: 1.0000 - val_loss: 4.6941 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 179/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.2084e-06 - acc: 1.0000\n",
      "Epoch 179: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.2498e-05 - acc: 1.0000 - val_loss: 4.6949 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 180/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2543e-05 - acc: 1.0000\n",
      "Epoch 180: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.2454e-05 - acc: 1.0000 - val_loss: 4.6956 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 181/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2341e-05 - acc: 1.0000\n",
      "Epoch 181: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2429e-05 - acc: 1.0000 - val_loss: 4.6964 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 182/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1205e-05 - acc: 1.0000\n",
      "Epoch 182: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.2410e-05 - acc: 1.0000 - val_loss: 4.6971 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 183/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1269e-05 - acc: 1.0000\n",
      "Epoch 183: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.2372e-05 - acc: 1.0000 - val_loss: 4.6977 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 184/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3537e-05 - acc: 1.0000\n",
      "Epoch 184: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.2347e-05 - acc: 1.0000 - val_loss: 4.6986 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 185/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3630e-05 - acc: 1.0000\n",
      "Epoch 185: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.2309e-05 - acc: 1.0000 - val_loss: 4.6994 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 186/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2449e-05 - acc: 1.0000\n",
      "Epoch 186: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.2281e-05 - acc: 1.0000 - val_loss: 4.7001 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 187/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.4118e-05 - acc: 1.0000\n",
      "Epoch 187: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.2253e-05 - acc: 1.0000 - val_loss: 4.7008 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 188/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2543e-05 - acc: 1.0000\n",
      "Epoch 188: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.2218e-05 - acc: 1.0000 - val_loss: 4.7014 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 189/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3545e-05 - acc: 1.0000\n",
      "Epoch 189: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2193e-05 - acc: 1.0000 - val_loss: 4.7017 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 190/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3645e-05 - acc: 1.0000\n",
      "Epoch 190: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2165e-05 - acc: 1.0000 - val_loss: 4.7017 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 191/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3101e-05 - acc: 1.0000\n",
      "Epoch 191: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2140e-05 - acc: 1.0000 - val_loss: 4.7016 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 192/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2848e-05 - acc: 1.0000\n",
      "Epoch 192: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.2115e-05 - acc: 1.0000 - val_loss: 4.7016 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 193/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.5552e-06 - acc: 1.0000\n",
      "Epoch 193: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2093e-05 - acc: 1.0000 - val_loss: 4.7016 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 194/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3392e-05 - acc: 1.0000\n",
      "Epoch 194: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2065e-05 - acc: 1.0000 - val_loss: 4.7016 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 195/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1019e-05 - acc: 1.0000\n",
      "Epoch 195: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.2037e-05 - acc: 1.0000 - val_loss: 4.7020 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 196/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1283e-05 - acc: 1.0000\n",
      "Epoch 196: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2021e-05 - acc: 1.0000 - val_loss: 4.7028 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 197/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3940e-05 - acc: 1.0000\n",
      "Epoch 197: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1989e-05 - acc: 1.0000 - val_loss: 4.7037 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 198/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2777e-05 - acc: 1.0000\n",
      "Epoch 198: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.1964e-05 - acc: 1.0000 - val_loss: 4.7043 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 199/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3519e-05 - acc: 1.0000\n",
      "Epoch 199: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1939e-05 - acc: 1.0000 - val_loss: 4.7048 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 200/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3813e-05 - acc: 1.0000\n",
      "Epoch 200: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1908e-05 - acc: 1.0000 - val_loss: 4.7053 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 201/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3224e-05 - acc: 1.0000\n",
      "Epoch 201: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1880e-05 - acc: 1.0000 - val_loss: 4.7057 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 202/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2718e-05 - acc: 1.0000\n",
      "Epoch 202: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1858e-05 - acc: 1.0000 - val_loss: 4.7061 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 203/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3519e-05 - acc: 1.0000\n",
      "Epoch 203: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1833e-05 - acc: 1.0000 - val_loss: 4.7069 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 204/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.0651e-06 - acc: 1.0000\n",
      "Epoch 204: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1811e-05 - acc: 1.0000 - val_loss: 4.7077 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 205/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3750e-05 - acc: 1.0000\n",
      "Epoch 205: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.1789e-05 - acc: 1.0000 - val_loss: 4.7086 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 206/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3370e-05 - acc: 1.0000\n",
      "Epoch 206: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1767e-05 - acc: 1.0000 - val_loss: 4.7096 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 207/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.0614e-06 - acc: 1.0000\n",
      "Epoch 207: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1739e-05 - acc: 1.0000 - val_loss: 4.7104 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 208/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0896e-05 - acc: 1.0000\n",
      "Epoch 208: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1713e-05 - acc: 1.0000 - val_loss: 4.7109 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 209/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2364e-05 - acc: 1.0000\n",
      "Epoch 209: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1673e-05 - acc: 1.0000 - val_loss: 4.7113 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 210/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3172e-05 - acc: 1.0000\n",
      "Epoch 210: val_acc did not improve from 0.50000\n",
      "\n",
      "Epoch 210: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.1641e-05 - acc: 1.0000 - val_loss: 4.7114 - val_acc: 0.5000 - lr: 1.2500e-04\n",
      "Epoch 211/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2207e-05 - acc: 1.0000\n",
      "Epoch 211: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.1622e-05 - acc: 1.0000 - val_loss: 4.7115 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 212/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0978e-05 - acc: 1.0000\n",
      "Epoch 212: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1597e-05 - acc: 1.0000 - val_loss: 4.7116 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 213/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0594e-05 - acc: 1.0000\n",
      "Epoch 213: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1.1591e-05 - acc: 1.0000 - val_loss: 4.7118 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 214/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3507e-05 - acc: 1.0000\n",
      "Epoch 214: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1575e-05 - acc: 1.0000 - val_loss: 4.7120 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 215/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0717e-05 - acc: 1.0000\n",
      "Epoch 215: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1563e-05 - acc: 1.0000 - val_loss: 4.7122 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 216/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.3557e-06 - acc: 1.0000\n",
      "Epoch 216: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.1557e-05 - acc: 1.0000 - val_loss: 4.7124 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 217/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2900e-05 - acc: 1.0000\n",
      "Epoch 217: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.1538e-05 - acc: 1.0000 - val_loss: 4.7127 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 218/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0486e-05 - acc: 1.0000\n",
      "Epoch 218: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1516e-05 - acc: 1.0000 - val_loss: 4.7129 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 219/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.4115e-06 - acc: 1.0000\n",
      "Epoch 219: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1506e-05 - acc: 1.0000 - val_loss: 4.7133 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 220/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2591e-05 - acc: 1.0000\n",
      "Epoch 220: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1488e-05 - acc: 1.0000 - val_loss: 4.7137 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 221/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3075e-05 - acc: 1.0000\n",
      "Epoch 221: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1475e-05 - acc: 1.0000 - val_loss: 4.7141 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 222/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2345e-05 - acc: 1.0000\n",
      "Epoch 222: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1466e-05 - acc: 1.0000 - val_loss: 4.7144 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 223/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3351e-05 - acc: 1.0000\n",
      "Epoch 223: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1447e-05 - acc: 1.0000 - val_loss: 4.7149 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 224/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0598e-05 - acc: 1.0000\n",
      "Epoch 224: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1437e-05 - acc: 1.0000 - val_loss: 4.7153 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 225/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3541e-05 - acc: 1.0000\n",
      "Epoch 225: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1.1422e-05 - acc: 1.0000 - val_loss: 4.7157 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 226/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1477e-05 - acc: 1.0000\n",
      "Epoch 226: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.1412e-05 - acc: 1.0000 - val_loss: 4.7160 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 227/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2714e-05 - acc: 1.0000\n",
      "Epoch 227: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1397e-05 - acc: 1.0000 - val_loss: 4.7161 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 228/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2170e-05 - acc: 1.0000\n",
      "Epoch 228: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1390e-05 - acc: 1.0000 - val_loss: 4.7162 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 229/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2904e-05 - acc: 1.0000\n",
      "Epoch 229: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1372e-05 - acc: 1.0000 - val_loss: 4.7165 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 230/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3124e-05 - acc: 1.0000\n",
      "Epoch 230: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1356e-05 - acc: 1.0000 - val_loss: 4.7167 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 231/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2230e-05 - acc: 1.0000\n",
      "Epoch 231: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1343e-05 - acc: 1.0000 - val_loss: 4.7169 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 232/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2919e-05 - acc: 1.0000\n",
      "Epoch 232: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1337e-05 - acc: 1.0000 - val_loss: 4.7171 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 233/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1332e-05 - acc: 1.0000\n",
      "Epoch 233: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1328e-05 - acc: 1.0000 - val_loss: 4.7174 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 234/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2330e-05 - acc: 1.0000\n",
      "Epoch 234: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.1318e-05 - acc: 1.0000 - val_loss: 4.7177 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 235/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.7000e-06 - acc: 1.0000\n",
      "Epoch 235: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1296e-05 - acc: 1.0000 - val_loss: 4.7181 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 236/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0639e-05 - acc: 1.0000\n",
      "Epoch 236: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1287e-05 - acc: 1.0000 - val_loss: 4.7186 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 237/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3161e-05 - acc: 1.0000\n",
      "Epoch 237: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1274e-05 - acc: 1.0000 - val_loss: 4.7190 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 238/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2528e-05 - acc: 1.0000\n",
      "Epoch 238: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1262e-05 - acc: 1.0000 - val_loss: 4.7194 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 239/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3116e-05 - acc: 1.0000\n",
      "Epoch 239: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1249e-05 - acc: 1.0000 - val_loss: 4.7199 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 240/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2628e-05 - acc: 1.0000\n",
      "Epoch 240: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.1237e-05 - acc: 1.0000 - val_loss: 4.7203 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 241/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2829e-05 - acc: 1.0000\n",
      "Epoch 241: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1221e-05 - acc: 1.0000 - val_loss: 4.7208 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 242/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.8304e-06 - acc: 1.0000\n",
      "Epoch 242: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.1212e-05 - acc: 1.0000 - val_loss: 4.7212 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 243/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2293e-05 - acc: 1.0000\n",
      "Epoch 243: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1199e-05 - acc: 1.0000 - val_loss: 4.7214 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 244/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1831e-05 - acc: 1.0000\n",
      "Epoch 244: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1186e-05 - acc: 1.0000 - val_loss: 4.7215 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 245/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.3250e-05 - acc: 1.0000\n",
      "Epoch 245: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1177e-05 - acc: 1.0000 - val_loss: 4.7215 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 246/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.2923e-06 - acc: 1.0000\n",
      "Epoch 246: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1155e-05 - acc: 1.0000 - val_loss: 4.7215 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 247/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0460e-05 - acc: 1.0000\n",
      "Epoch 247: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1143e-05 - acc: 1.0000 - val_loss: 4.7215 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 248/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2140e-05 - acc: 1.0000\n",
      "Epoch 248: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1130e-05 - acc: 1.0000 - val_loss: 4.7215 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 249/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.7112e-06 - acc: 1.0000\n",
      "Epoch 249: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1127e-05 - acc: 1.0000 - val_loss: 4.7217 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 250/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 4.9918e-06 - acc: 1.0000\n",
      "Epoch 250: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1108e-05 - acc: 1.0000 - val_loss: 4.7219 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 251/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1343e-05 - acc: 1.0000\n",
      "Epoch 251: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1102e-05 - acc: 1.0000 - val_loss: 4.7222 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 252/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2923e-05 - acc: 1.0000\n",
      "Epoch 252: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1080e-05 - acc: 1.0000 - val_loss: 4.7225 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 253/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2692e-05 - acc: 1.0000\n",
      "Epoch 253: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1061e-05 - acc: 1.0000 - val_loss: 4.7227 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 254/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2174e-05 - acc: 1.0000\n",
      "Epoch 254: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1052e-05 - acc: 1.0000 - val_loss: 4.7228 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 255/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0438e-05 - acc: 1.0000\n",
      "Epoch 255: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1036e-05 - acc: 1.0000 - val_loss: 4.7230 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 256/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2654e-05 - acc: 1.0000\n",
      "Epoch 256: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1030e-05 - acc: 1.0000 - val_loss: 4.7231 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 257/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2870e-05 - acc: 1.0000\n",
      "Epoch 257: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1017e-05 - acc: 1.0000 - val_loss: 4.7232 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 258/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.6367e-06 - acc: 1.0000\n",
      "Epoch 258: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.1004e-05 - acc: 1.0000 - val_loss: 4.7233 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 259/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2315e-05 - acc: 1.0000\n",
      "Epoch 259: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0989e-05 - acc: 1.0000 - val_loss: 4.7233 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 260/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.5550e-06 - acc: 1.0000\n",
      "Epoch 260: val_acc did not improve from 0.50000\n",
      "\n",
      "Epoch 260: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0976e-05 - acc: 1.0000 - val_loss: 4.7234 - val_acc: 0.5000 - lr: 6.2500e-05\n",
      "Epoch 261/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.6553e-06 - acc: 1.0000\n",
      "Epoch 261: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0967e-05 - acc: 1.0000 - val_loss: 4.7235 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 262/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.0782e-06 - acc: 1.0000\n",
      "Epoch 262: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0964e-05 - acc: 1.0000 - val_loss: 4.7236 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 263/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1976e-05 - acc: 1.0000\n",
      "Epoch 263: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0954e-05 - acc: 1.0000 - val_loss: 4.7237 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 264/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.4095e-06 - acc: 1.0000\n",
      "Epoch 264: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0945e-05 - acc: 1.0000 - val_loss: 4.7238 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 265/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.9459e-06 - acc: 1.0000\n",
      "Epoch 265: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0939e-05 - acc: 1.0000 - val_loss: 4.7238 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 266/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.5585e-06 - acc: 1.0000\n",
      "Epoch 266: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0932e-05 - acc: 1.0000 - val_loss: 4.7239 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 267/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2725e-05 - acc: 1.0000\n",
      "Epoch 267: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0926e-05 - acc: 1.0000 - val_loss: 4.7240 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 268/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1537e-05 - acc: 1.0000\n",
      "Epoch 268: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0917e-05 - acc: 1.0000 - val_loss: 4.7240 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 269/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2580e-05 - acc: 1.0000\n",
      "Epoch 269: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0907e-05 - acc: 1.0000 - val_loss: 4.7241 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 270/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2408e-05 - acc: 1.0000\n",
      "Epoch 270: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0898e-05 - acc: 1.0000 - val_loss: 4.7242 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 271/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1138e-05 - acc: 1.0000\n",
      "Epoch 271: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0895e-05 - acc: 1.0000 - val_loss: 4.7244 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 272/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2584e-05 - acc: 1.0000\n",
      "Epoch 272: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0888e-05 - acc: 1.0000 - val_loss: 4.7247 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 273/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.6197e-06 - acc: 1.0000\n",
      "Epoch 273: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0879e-05 - acc: 1.0000 - val_loss: 4.7249 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 274/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2163e-05 - acc: 1.0000\n",
      "Epoch 274: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0876e-05 - acc: 1.0000 - val_loss: 4.7251 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 275/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1485e-05 - acc: 1.0000\n",
      "Epoch 275: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0863e-05 - acc: 1.0000 - val_loss: 4.7252 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 276/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2770e-05 - acc: 1.0000\n",
      "Epoch 276: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0863e-05 - acc: 1.0000 - val_loss: 4.7253 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 277/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2230e-05 - acc: 1.0000\n",
      "Epoch 277: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0854e-05 - acc: 1.0000 - val_loss: 4.7254 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 278/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0903e-05 - acc: 1.0000\n",
      "Epoch 278: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0854e-05 - acc: 1.0000 - val_loss: 4.7255 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 279/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1656e-05 - acc: 1.0000\n",
      "Epoch 279: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0845e-05 - acc: 1.0000 - val_loss: 4.7255 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 280/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.8083e-06 - acc: 1.0000\n",
      "Epoch 280: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0845e-05 - acc: 1.0000 - val_loss: 4.7256 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 281/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2319e-05 - acc: 1.0000\n",
      "Epoch 281: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0835e-05 - acc: 1.0000 - val_loss: 4.7257 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 282/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1768e-05 - acc: 1.0000\n",
      "Epoch 282: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0835e-05 - acc: 1.0000 - val_loss: 4.7258 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 283/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1764e-05 - acc: 1.0000\n",
      "Epoch 283: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0829e-05 - acc: 1.0000 - val_loss: 4.7258 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 284/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.9699e-06 - acc: 1.0000\n",
      "Epoch 284: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0819e-05 - acc: 1.0000 - val_loss: 4.7258 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 285/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2815e-05 - acc: 1.0000\n",
      "Epoch 285: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0816e-05 - acc: 1.0000 - val_loss: 4.7259 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 286/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1682e-05 - acc: 1.0000\n",
      "Epoch 286: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0807e-05 - acc: 1.0000 - val_loss: 4.7260 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 287/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2125e-05 - acc: 1.0000\n",
      "Epoch 287: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0804e-05 - acc: 1.0000 - val_loss: 4.7263 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 288/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0110e-05 - acc: 1.0000\n",
      "Epoch 288: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0804e-05 - acc: 1.0000 - val_loss: 4.7266 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 289/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2449e-05 - acc: 1.0000\n",
      "Epoch 289: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0794e-05 - acc: 1.0000 - val_loss: 4.7270 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 290/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2546e-05 - acc: 1.0000\n",
      "Epoch 290: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0785e-05 - acc: 1.0000 - val_loss: 4.7273 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 291/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1436e-05 - acc: 1.0000\n",
      "Epoch 291: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0779e-05 - acc: 1.0000 - val_loss: 4.7275 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 292/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.7373e-06 - acc: 1.0000\n",
      "Epoch 292: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0769e-05 - acc: 1.0000 - val_loss: 4.7278 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 293/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.2290e-06 - acc: 1.0000\n",
      "Epoch 293: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0757e-05 - acc: 1.0000 - val_loss: 4.7280 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 294/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.8304e-06 - acc: 1.0000\n",
      "Epoch 294: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0750e-05 - acc: 1.0000 - val_loss: 4.7282 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 295/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1824e-05 - acc: 1.0000\n",
      "Epoch 295: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0750e-05 - acc: 1.0000 - val_loss: 4.7283 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 296/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2394e-05 - acc: 1.0000\n",
      "Epoch 296: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0747e-05 - acc: 1.0000 - val_loss: 4.7284 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 297/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1138e-05 - acc: 1.0000\n",
      "Epoch 297: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0728e-05 - acc: 1.0000 - val_loss: 4.7286 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 298/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0255e-05 - acc: 1.0000\n",
      "Epoch 298: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0728e-05 - acc: 1.0000 - val_loss: 4.7287 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 299/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.6777e-06 - acc: 1.0000\n",
      "Epoch 299: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0728e-05 - acc: 1.0000 - val_loss: 4.7289 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 300/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1194e-05 - acc: 1.0000\n",
      "Epoch 300: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0728e-05 - acc: 1.0000 - val_loss: 4.7291 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 301/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1906e-05 - acc: 1.0000\n",
      "Epoch 301: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0710e-05 - acc: 1.0000 - val_loss: 4.7294 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 302/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2155e-05 - acc: 1.0000\n",
      "Epoch 302: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 1.0703e-05 - acc: 1.0000 - val_loss: 4.7295 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 303/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2330e-05 - acc: 1.0000\n",
      "Epoch 303: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0697e-05 - acc: 1.0000 - val_loss: 4.7296 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 304/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.4393e-06 - acc: 1.0000\n",
      "Epoch 304: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0691e-05 - acc: 1.0000 - val_loss: 4.7298 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 305/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1909e-05 - acc: 1.0000\n",
      "Epoch 305: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0688e-05 - acc: 1.0000 - val_loss: 4.7299 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 306/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0166e-05 - acc: 1.0000\n",
      "Epoch 306: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0685e-05 - acc: 1.0000 - val_loss: 4.7301 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 307/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1872e-05 - acc: 1.0000\n",
      "Epoch 307: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0678e-05 - acc: 1.0000 - val_loss: 4.7302 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 308/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0855e-05 - acc: 1.0000\n",
      "Epoch 308: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0669e-05 - acc: 1.0000 - val_loss: 4.7303 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 309/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0397e-05 - acc: 1.0000\n",
      "Epoch 309: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0666e-05 - acc: 1.0000 - val_loss: 4.7305 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 310/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1693e-05 - acc: 1.0000\n",
      "Epoch 310: val_acc did not improve from 0.50000\n",
      "\n",
      "Epoch 310: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0659e-05 - acc: 1.0000 - val_loss: 4.7306 - val_acc: 0.5000 - lr: 3.1250e-05\n",
      "Epoch 311/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2122e-05 - acc: 1.0000\n",
      "Epoch 311: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0650e-05 - acc: 1.0000 - val_loss: 4.7307 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 312/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1917e-05 - acc: 1.0000\n",
      "Epoch 312: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0650e-05 - acc: 1.0000 - val_loss: 4.7308 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 313/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1704e-05 - acc: 1.0000\n",
      "Epoch 313: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0647e-05 - acc: 1.0000 - val_loss: 4.7309 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 314/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2233e-05 - acc: 1.0000\n",
      "Epoch 314: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0641e-05 - acc: 1.0000 - val_loss: 4.7310 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 315/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0568e-05 - acc: 1.0000\n",
      "Epoch 315: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0634e-05 - acc: 1.0000 - val_loss: 4.7311 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 316/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1723e-05 - acc: 1.0000\n",
      "Epoch 316: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0631e-05 - acc: 1.0000 - val_loss: 4.7312 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 317/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2114e-05 - acc: 1.0000\n",
      "Epoch 317: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0628e-05 - acc: 1.0000 - val_loss: 4.7313 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 318/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2163e-05 - acc: 1.0000\n",
      "Epoch 318: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0622e-05 - acc: 1.0000 - val_loss: 4.7314 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 319/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.0667e-06 - acc: 1.0000\n",
      "Epoch 319: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0622e-05 - acc: 1.0000 - val_loss: 4.7315 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 320/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1436e-05 - acc: 1.0000\n",
      "Epoch 320: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0619e-05 - acc: 1.0000 - val_loss: 4.7316 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 321/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.8453e-06 - acc: 1.0000\n",
      "Epoch 321: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0619e-05 - acc: 1.0000 - val_loss: 4.7317 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 322/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1637e-05 - acc: 1.0000\n",
      "Epoch 322: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0619e-05 - acc: 1.0000 - val_loss: 4.7318 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 323/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0032e-05 - acc: 1.0000\n",
      "Epoch 323: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0619e-05 - acc: 1.0000 - val_loss: 4.7318 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 324/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2267e-05 - acc: 1.0000\n",
      "Epoch 324: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0619e-05 - acc: 1.0000 - val_loss: 4.7318 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 325/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.7671e-06 - acc: 1.0000\n",
      "Epoch 325: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0606e-05 - acc: 1.0000 - val_loss: 4.7319 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 326/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1835e-05 - acc: 1.0000\n",
      "Epoch 326: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0606e-05 - acc: 1.0000 - val_loss: 4.7319 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 327/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2096e-05 - acc: 1.0000\n",
      "Epoch 327: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0606e-05 - acc: 1.0000 - val_loss: 4.7320 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 328/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.7410e-06 - acc: 1.0000\n",
      "Epoch 328: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0603e-05 - acc: 1.0000 - val_loss: 4.7320 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 329/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1920e-05 - acc: 1.0000\n",
      "Epoch 329: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0603e-05 - acc: 1.0000 - val_loss: 4.7321 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 330/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2032e-05 - acc: 1.0000\n",
      "Epoch 330: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0603e-05 - acc: 1.0000 - val_loss: 4.7321 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 331/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.8083e-06 - acc: 1.0000\n",
      "Epoch 331: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0587e-05 - acc: 1.0000 - val_loss: 4.7322 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 332/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1984e-05 - acc: 1.0000\n",
      "Epoch 332: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0587e-05 - acc: 1.0000 - val_loss: 4.7322 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 333/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1038e-05 - acc: 1.0000\n",
      "Epoch 333: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0584e-05 - acc: 1.0000 - val_loss: 4.7323 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 334/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0732e-05 - acc: 1.0000\n",
      "Epoch 334: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0584e-05 - acc: 1.0000 - val_loss: 4.7323 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 335/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2330e-05 - acc: 1.0000\n",
      "Epoch 335: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0578e-05 - acc: 1.0000 - val_loss: 4.7324 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 336/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2315e-05 - acc: 1.0000\n",
      "Epoch 336: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0581e-05 - acc: 1.0000 - val_loss: 4.7325 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 337/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0695e-05 - acc: 1.0000\n",
      "Epoch 337: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0568e-05 - acc: 1.0000 - val_loss: 4.7326 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 338/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1406e-05 - acc: 1.0000\n",
      "Epoch 338: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0568e-05 - acc: 1.0000 - val_loss: 4.7327 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 339/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0524e-05 - acc: 1.0000\n",
      "Epoch 339: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0568e-05 - acc: 1.0000 - val_loss: 4.7329 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 340/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.5452e-06 - acc: 1.0000\n",
      "Epoch 340: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0562e-05 - acc: 1.0000 - val_loss: 4.7330 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 341/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0378e-05 - acc: 1.0000\n",
      "Epoch 341: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0553e-05 - acc: 1.0000 - val_loss: 4.7331 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 342/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2446e-05 - acc: 1.0000\n",
      "Epoch 342: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0553e-05 - acc: 1.0000 - val_loss: 4.7333 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 343/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.8120e-06 - acc: 1.0000\n",
      "Epoch 343: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0553e-05 - acc: 1.0000 - val_loss: 4.7334 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 344/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.7094e-06 - acc: 1.0000\n",
      "Epoch 344: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0553e-05 - acc: 1.0000 - val_loss: 4.7335 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 345/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1190e-05 - acc: 1.0000\n",
      "Epoch 345: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0553e-05 - acc: 1.0000 - val_loss: 4.7336 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 346/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2103e-05 - acc: 1.0000\n",
      "Epoch 346: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0546e-05 - acc: 1.0000 - val_loss: 4.7337 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 347/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.5100e-06 - acc: 1.0000\n",
      "Epoch 347: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0540e-05 - acc: 1.0000 - val_loss: 4.7337 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 348/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 4.8279e-06 - acc: 1.0000\n",
      "Epoch 348: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0537e-05 - acc: 1.0000 - val_loss: 4.7338 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 349/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0993e-05 - acc: 1.0000\n",
      "Epoch 349: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0534e-05 - acc: 1.0000 - val_loss: 4.7338 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 350/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1272e-05 - acc: 1.0000\n",
      "Epoch 350: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0531e-05 - acc: 1.0000 - val_loss: 4.7339 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 351/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0788e-05 - acc: 1.0000\n",
      "Epoch 351: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0528e-05 - acc: 1.0000 - val_loss: 4.7340 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 352/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1228e-05 - acc: 1.0000\n",
      "Epoch 352: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0528e-05 - acc: 1.0000 - val_loss: 4.7341 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 353/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.7711e-06 - acc: 1.0000\n",
      "Epoch 353: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0528e-05 - acc: 1.0000 - val_loss: 4.7341 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 354/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2259e-05 - acc: 1.0000\n",
      "Epoch 354: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0525e-05 - acc: 1.0000 - val_loss: 4.7342 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 355/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1678e-05 - acc: 1.0000\n",
      "Epoch 355: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0518e-05 - acc: 1.0000 - val_loss: 4.7343 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 356/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1589e-05 - acc: 1.0000\n",
      "Epoch 356: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0515e-05 - acc: 1.0000 - val_loss: 4.7345 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 357/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.3983e-06 - acc: 1.0000\n",
      "Epoch 357: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.0503e-05 - acc: 1.0000 - val_loss: 4.7346 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 358/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2189e-05 - acc: 1.0000\n",
      "Epoch 358: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0503e-05 - acc: 1.0000 - val_loss: 4.7348 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 359/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1190e-05 - acc: 1.0000\n",
      "Epoch 359: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0499e-05 - acc: 1.0000 - val_loss: 4.7349 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 360/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2002e-05 - acc: 1.0000\n",
      "Epoch 360: val_acc did not improve from 0.50000\n",
      "\n",
      "Epoch 360: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0493e-05 - acc: 1.0000 - val_loss: 4.7350 - val_acc: 0.5000 - lr: 1.5625e-05\n",
      "Epoch 361/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 5.0477e-06 - acc: 1.0000\n",
      "Epoch 361: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0490e-05 - acc: 1.0000 - val_loss: 4.7351 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 362/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0091e-05 - acc: 1.0000\n",
      "Epoch 362: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0490e-05 - acc: 1.0000 - val_loss: 4.7351 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 363/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0717e-05 - acc: 1.0000\n",
      "Epoch 363: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0490e-05 - acc: 1.0000 - val_loss: 4.7352 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 364/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.5343e-06 - acc: 1.0000\n",
      "Epoch 364: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0490e-05 - acc: 1.0000 - val_loss: 4.7353 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 365/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1142e-05 - acc: 1.0000\n",
      "Epoch 365: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0490e-05 - acc: 1.0000 - val_loss: 4.7353 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 366/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.4842e-06 - acc: 1.0000\n",
      "Epoch 366: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0487e-05 - acc: 1.0000 - val_loss: 4.7354 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 367/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2312e-05 - acc: 1.0000\n",
      "Epoch 367: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0487e-05 - acc: 1.0000 - val_loss: 4.7355 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 368/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1906e-05 - acc: 1.0000\n",
      "Epoch 368: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0487e-05 - acc: 1.0000 - val_loss: 4.7355 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 369/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0930e-05 - acc: 1.0000\n",
      "Epoch 369: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0487e-05 - acc: 1.0000 - val_loss: 4.7356 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 370/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0911e-05 - acc: 1.0000\n",
      "Epoch 370: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0484e-05 - acc: 1.0000 - val_loss: 4.7356 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 371/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.0016e-06 - acc: 1.0000\n",
      "Epoch 371: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0481e-05 - acc: 1.0000 - val_loss: 4.7357 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 372/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1708e-05 - acc: 1.0000\n",
      "Epoch 372: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0481e-05 - acc: 1.0000 - val_loss: 4.7358 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 373/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1827e-05 - acc: 1.0000\n",
      "Epoch 373: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0481e-05 - acc: 1.0000 - val_loss: 4.7358 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 374/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.8509e-06 - acc: 1.0000\n",
      "Epoch 374: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0474e-05 - acc: 1.0000 - val_loss: 4.7359 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 375/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1891e-05 - acc: 1.0000\n",
      "Epoch 375: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0474e-05 - acc: 1.0000 - val_loss: 4.7359 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 376/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1265e-05 - acc: 1.0000\n",
      "Epoch 376: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0474e-05 - acc: 1.0000 - val_loss: 4.7359 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 377/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.0630e-06 - acc: 1.0000\n",
      "Epoch 377: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0471e-05 - acc: 1.0000 - val_loss: 4.7360 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 378/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1589e-05 - acc: 1.0000\n",
      "Epoch 378: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0471e-05 - acc: 1.0000 - val_loss: 4.7360 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 379/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1690e-05 - acc: 1.0000\n",
      "Epoch 379: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0468e-05 - acc: 1.0000 - val_loss: 4.7361 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 380/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1000e-05 - acc: 1.0000\n",
      "Epoch 380: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0468e-05 - acc: 1.0000 - val_loss: 4.7361 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 381/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0207e-05 - acc: 1.0000\n",
      "Epoch 381: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0465e-05 - acc: 1.0000 - val_loss: 4.7362 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 382/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0564e-05 - acc: 1.0000\n",
      "Epoch 382: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0465e-05 - acc: 1.0000 - val_loss: 4.7362 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 383/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.6796e-06 - acc: 1.0000\n",
      "Epoch 383: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0465e-05 - acc: 1.0000 - val_loss: 4.7362 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 384/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.5736e-06 - acc: 1.0000\n",
      "Epoch 384: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0465e-05 - acc: 1.0000 - val_loss: 4.7363 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 385/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1909e-05 - acc: 1.0000\n",
      "Epoch 385: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0462e-05 - acc: 1.0000 - val_loss: 4.7363 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 386/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2345e-05 - acc: 1.0000\n",
      "Epoch 386: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0459e-05 - acc: 1.0000 - val_loss: 4.7364 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 387/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.4951e-06 - acc: 1.0000\n",
      "Epoch 387: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0459e-05 - acc: 1.0000 - val_loss: 4.7365 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 388/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1753e-05 - acc: 1.0000\n",
      "Epoch 388: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0459e-05 - acc: 1.0000 - val_loss: 4.7365 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 389/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1980e-05 - acc: 1.0000\n",
      "Epoch 389: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0456e-05 - acc: 1.0000 - val_loss: 4.7366 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 390/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1585e-05 - acc: 1.0000\n",
      "Epoch 390: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0456e-05 - acc: 1.0000 - val_loss: 4.7366 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 391/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.7040e-06 - acc: 1.0000\n",
      "Epoch 391: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0449e-05 - acc: 1.0000 - val_loss: 4.7367 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 392/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.1205e-06 - acc: 1.0000\n",
      "Epoch 392: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0449e-05 - acc: 1.0000 - val_loss: 4.7367 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 393/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.0484e-06 - acc: 1.0000\n",
      "Epoch 393: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.0446e-05 - acc: 1.0000 - val_loss: 4.7367 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 394/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2222e-05 - acc: 1.0000\n",
      "Epoch 394: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0443e-05 - acc: 1.0000 - val_loss: 4.7368 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 395/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2047e-05 - acc: 1.0000\n",
      "Epoch 395: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0443e-05 - acc: 1.0000 - val_loss: 4.7368 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 396/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0926e-05 - acc: 1.0000\n",
      "Epoch 396: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0443e-05 - acc: 1.0000 - val_loss: 4.7369 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 397/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1514e-05 - acc: 1.0000\n",
      "Epoch 397: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0434e-05 - acc: 1.0000 - val_loss: 4.7370 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 398/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.7091e-06 - acc: 1.0000\n",
      "Epoch 398: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0434e-05 - acc: 1.0000 - val_loss: 4.7371 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 399/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.3275e-06 - acc: 1.0000\n",
      "Epoch 399: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0430e-05 - acc: 1.0000 - val_loss: 4.7372 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 400/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2178e-05 - acc: 1.0000\n",
      "Epoch 400: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0427e-05 - acc: 1.0000 - val_loss: 4.7373 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 401/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1820e-05 - acc: 1.0000\n",
      "Epoch 401: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0424e-05 - acc: 1.0000 - val_loss: 4.7374 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 402/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1216e-05 - acc: 1.0000\n",
      "Epoch 402: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0424e-05 - acc: 1.0000 - val_loss: 4.7375 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 403/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.9052e-06 - acc: 1.0000\n",
      "Epoch 403: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1.0424e-05 - acc: 1.0000 - val_loss: 4.7375 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 404/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1600e-05 - acc: 1.0000\n",
      "Epoch 404: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0427e-05 - acc: 1.0000 - val_loss: 4.7376 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 405/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1984e-05 - acc: 1.0000\n",
      "Epoch 405: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0421e-05 - acc: 1.0000 - val_loss: 4.7376 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 406/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1876e-05 - acc: 1.0000\n",
      "Epoch 406: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0418e-05 - acc: 1.0000 - val_loss: 4.7377 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 407/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0967e-05 - acc: 1.0000\n",
      "Epoch 407: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0415e-05 - acc: 1.0000 - val_loss: 4.7377 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 408/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1298e-05 - acc: 1.0000\n",
      "Epoch 408: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0408e-05 - acc: 1.0000 - val_loss: 4.7378 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 409/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2166e-05 - acc: 1.0000\n",
      "Epoch 409: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0408e-05 - acc: 1.0000 - val_loss: 4.7378 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 410/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.9722e-06 - acc: 1.0000\n",
      "Epoch 410: val_acc did not improve from 0.50000\n",
      "\n",
      "Epoch 410: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0408e-05 - acc: 1.0000 - val_loss: 4.7379 - val_acc: 0.5000 - lr: 7.8125e-06\n",
      "Epoch 411/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.4209e-06 - acc: 1.0000\n",
      "Epoch 411: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0405e-05 - acc: 1.0000 - val_loss: 4.7379 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 412/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0810e-05 - acc: 1.0000\n",
      "Epoch 412: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0405e-05 - acc: 1.0000 - val_loss: 4.7380 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 413/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1835e-05 - acc: 1.0000\n",
      "Epoch 413: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0405e-05 - acc: 1.0000 - val_loss: 4.7380 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 414/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2081e-05 - acc: 1.0000\n",
      "Epoch 414: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0405e-05 - acc: 1.0000 - val_loss: 4.7380 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 415/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1745e-05 - acc: 1.0000\n",
      "Epoch 415: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0405e-05 - acc: 1.0000 - val_loss: 4.7380 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 416/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.0311e-06 - acc: 1.0000\n",
      "Epoch 416: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0408e-05 - acc: 1.0000 - val_loss: 4.7381 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 417/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1734e-05 - acc: 1.0000\n",
      "Epoch 417: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0408e-05 - acc: 1.0000 - val_loss: 4.7381 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 418/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0524e-05 - acc: 1.0000\n",
      "Epoch 418: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0408e-05 - acc: 1.0000 - val_loss: 4.7381 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 419/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1250e-05 - acc: 1.0000\n",
      "Epoch 419: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1.0408e-05 - acc: 1.0000 - val_loss: 4.7382 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 420/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2137e-05 - acc: 1.0000\n",
      "Epoch 420: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0408e-05 - acc: 1.0000 - val_loss: 4.7382 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 421/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.2882e-06 - acc: 1.0000\n",
      "Epoch 421: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0408e-05 - acc: 1.0000 - val_loss: 4.7383 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 422/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.2868e-06 - acc: 1.0000\n",
      "Epoch 422: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0405e-05 - acc: 1.0000 - val_loss: 4.7383 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 423/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2148e-05 - acc: 1.0000\n",
      "Epoch 423: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0405e-05 - acc: 1.0000 - val_loss: 4.7383 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 424/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.6218e-06 - acc: 1.0000\n",
      "Epoch 424: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0405e-05 - acc: 1.0000 - val_loss: 4.7384 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 425/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.6777e-06 - acc: 1.0000\n",
      "Epoch 425: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0402e-05 - acc: 1.0000 - val_loss: 4.7384 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 426/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1250e-05 - acc: 1.0000\n",
      "Epoch 426: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0402e-05 - acc: 1.0000 - val_loss: 4.7384 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 427/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0743e-05 - acc: 1.0000\n",
      "Epoch 427: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0402e-05 - acc: 1.0000 - val_loss: 4.7384 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 428/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1730e-05 - acc: 1.0000\n",
      "Epoch 428: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0402e-05 - acc: 1.0000 - val_loss: 4.7384 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 429/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1526e-05 - acc: 1.0000\n",
      "Epoch 429: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0402e-05 - acc: 1.0000 - val_loss: 4.7385 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 430/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.1452e-06 - acc: 1.0000\n",
      "Epoch 430: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0402e-05 - acc: 1.0000 - val_loss: 4.7385 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 431/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1351e-05 - acc: 1.0000\n",
      "Epoch 431: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0402e-05 - acc: 1.0000 - val_loss: 4.7385 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 432/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.5399e-06 - acc: 1.0000\n",
      "Epoch 432: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0402e-05 - acc: 1.0000 - val_loss: 4.7386 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 433/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1727e-05 - acc: 1.0000\n",
      "Epoch 433: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0399e-05 - acc: 1.0000 - val_loss: 4.7386 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 434/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1913e-05 - acc: 1.0000\n",
      "Epoch 434: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0399e-05 - acc: 1.0000 - val_loss: 4.7386 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 435/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2066e-05 - acc: 1.0000\n",
      "Epoch 435: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0399e-05 - acc: 1.0000 - val_loss: 4.7387 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 436/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1466e-05 - acc: 1.0000\n",
      "Epoch 436: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0396e-05 - acc: 1.0000 - val_loss: 4.7387 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 437/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1719e-05 - acc: 1.0000\n",
      "Epoch 437: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0396e-05 - acc: 1.0000 - val_loss: 4.7387 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 438/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1947e-05 - acc: 1.0000\n",
      "Epoch 438: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0399e-05 - acc: 1.0000 - val_loss: 4.7388 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 439/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1965e-05 - acc: 1.0000\n",
      "Epoch 439: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0396e-05 - acc: 1.0000 - val_loss: 4.7388 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 440/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.9850e-06 - acc: 1.0000\n",
      "Epoch 440: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0396e-05 - acc: 1.0000 - val_loss: 4.7389 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 441/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1891e-05 - acc: 1.0000\n",
      "Epoch 441: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0396e-05 - acc: 1.0000 - val_loss: 4.7389 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 442/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.9252e-06 - acc: 1.0000\n",
      "Epoch 442: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0396e-05 - acc: 1.0000 - val_loss: 4.7389 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 443/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1023e-05 - acc: 1.0000\n",
      "Epoch 443: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0393e-05 - acc: 1.0000 - val_loss: 4.7389 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 444/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1649e-05 - acc: 1.0000\n",
      "Epoch 444: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0390e-05 - acc: 1.0000 - val_loss: 4.7390 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 445/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1961e-05 - acc: 1.0000\n",
      "Epoch 445: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0390e-05 - acc: 1.0000 - val_loss: 4.7390 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 446/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2245e-05 - acc: 1.0000\n",
      "Epoch 446: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0393e-05 - acc: 1.0000 - val_loss: 4.7390 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 447/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1172e-05 - acc: 1.0000\n",
      "Epoch 447: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0393e-05 - acc: 1.0000 - val_loss: 4.7390 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 448/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1555e-05 - acc: 1.0000\n",
      "Epoch 448: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0390e-05 - acc: 1.0000 - val_loss: 4.7390 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 449/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0769e-05 - acc: 1.0000\n",
      "Epoch 449: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0390e-05 - acc: 1.0000 - val_loss: 4.7391 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 450/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.7226e-06 - acc: 1.0000\n",
      "Epoch 450: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0383e-05 - acc: 1.0000 - val_loss: 4.7391 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 451/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.1971e-06 - acc: 1.0000\n",
      "Epoch 451: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0383e-05 - acc: 1.0000 - val_loss: 4.7391 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 452/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1913e-05 - acc: 1.0000\n",
      "Epoch 452: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0380e-05 - acc: 1.0000 - val_loss: 4.7392 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 453/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1958e-05 - acc: 1.0000\n",
      "Epoch 453: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0380e-05 - acc: 1.0000 - val_loss: 4.7392 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 454/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0136e-05 - acc: 1.0000\n",
      "Epoch 454: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1.0380e-05 - acc: 1.0000 - val_loss: 4.7392 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 455/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1473e-05 - acc: 1.0000\n",
      "Epoch 455: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0380e-05 - acc: 1.0000 - val_loss: 4.7392 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 456/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0870e-05 - acc: 1.0000\n",
      "Epoch 456: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0377e-05 - acc: 1.0000 - val_loss: 4.7393 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 457/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1723e-05 - acc: 1.0000\n",
      "Epoch 457: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0380e-05 - acc: 1.0000 - val_loss: 4.7393 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 458/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1801e-05 - acc: 1.0000\n",
      "Epoch 458: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0377e-05 - acc: 1.0000 - val_loss: 4.7393 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 459/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1343e-05 - acc: 1.0000\n",
      "Epoch 459: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0377e-05 - acc: 1.0000 - val_loss: 4.7393 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 460/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0527e-05 - acc: 1.0000\n",
      "Epoch 460: val_acc did not improve from 0.50000\n",
      "\n",
      "Epoch 460: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0377e-05 - acc: 1.0000 - val_loss: 4.7394 - val_acc: 0.5000 - lr: 3.9063e-06\n",
      "Epoch 461/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1198e-05 - acc: 1.0000\n",
      "Epoch 461: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0377e-05 - acc: 1.0000 - val_loss: 4.7394 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 462/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1418e-05 - acc: 1.0000\n",
      "Epoch 462: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0377e-05 - acc: 1.0000 - val_loss: 4.7394 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 463/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1064e-05 - acc: 1.0000\n",
      "Epoch 463: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0377e-05 - acc: 1.0000 - val_loss: 4.7394 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 464/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0818e-05 - acc: 1.0000\n",
      "Epoch 464: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0374e-05 - acc: 1.0000 - val_loss: 4.7394 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 465/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.6519e-06 - acc: 1.0000\n",
      "Epoch 465: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.0371e-05 - acc: 1.0000 - val_loss: 4.7395 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 466/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0829e-05 - acc: 1.0000\n",
      "Epoch 466: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0368e-05 - acc: 1.0000 - val_loss: 4.7395 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 467/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1071e-05 - acc: 1.0000\n",
      "Epoch 467: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0368e-05 - acc: 1.0000 - val_loss: 4.7395 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 468/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1932e-05 - acc: 1.0000\n",
      "Epoch 468: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0368e-05 - acc: 1.0000 - val_loss: 4.7395 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 469/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.5212e-06 - acc: 1.0000\n",
      "Epoch 469: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0368e-05 - acc: 1.0000 - val_loss: 4.7396 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 470/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0352e-05 - acc: 1.0000\n",
      "Epoch 470: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0368e-05 - acc: 1.0000 - val_loss: 4.7396 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 471/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1082e-05 - acc: 1.0000\n",
      "Epoch 471: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0368e-05 - acc: 1.0000 - val_loss: 4.7396 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 472/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2189e-05 - acc: 1.0000\n",
      "Epoch 472: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.0368e-05 - acc: 1.0000 - val_loss: 4.7397 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 473/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1686e-05 - acc: 1.0000\n",
      "Epoch 473: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0365e-05 - acc: 1.0000 - val_loss: 4.7397 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 474/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1097e-05 - acc: 1.0000\n",
      "Epoch 474: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.0365e-05 - acc: 1.0000 - val_loss: 4.7397 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 475/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2029e-05 - acc: 1.0000\n",
      "Epoch 475: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0365e-05 - acc: 1.0000 - val_loss: 4.7398 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 476/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.5436e-06 - acc: 1.0000\n",
      "Epoch 476: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0365e-05 - acc: 1.0000 - val_loss: 4.7398 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 477/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1745e-05 - acc: 1.0000\n",
      "Epoch 477: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0361e-05 - acc: 1.0000 - val_loss: 4.7398 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 478/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1209e-05 - acc: 1.0000\n",
      "Epoch 478: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0361e-05 - acc: 1.0000 - val_loss: 4.7399 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 479/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0743e-05 - acc: 1.0000\n",
      "Epoch 479: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0361e-05 - acc: 1.0000 - val_loss: 4.7399 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 480/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1220e-05 - acc: 1.0000\n",
      "Epoch 480: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0361e-05 - acc: 1.0000 - val_loss: 4.7399 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 481/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.2006e-05 - acc: 1.0000\n",
      "Epoch 481: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7400 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 482/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0769e-05 - acc: 1.0000\n",
      "Epoch 482: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7400 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 483/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1753e-05 - acc: 1.0000\n",
      "Epoch 483: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7400 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 484/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1164e-05 - acc: 1.0000\n",
      "Epoch 484: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7401 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 485/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0553e-05 - acc: 1.0000\n",
      "Epoch 485: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7401 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 486/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 6.4446e-06 - acc: 1.0000\n",
      "Epoch 486: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7401 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 487/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0587e-05 - acc: 1.0000\n",
      "Epoch 487: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7402 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 488/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1809e-05 - acc: 1.0000\n",
      "Epoch 488: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7402 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 489/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1358e-05 - acc: 1.0000\n",
      "Epoch 489: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7402 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 490/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1112e-05 - acc: 1.0000\n",
      "Epoch 490: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7402 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 491/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1708e-05 - acc: 1.0000\n",
      "Epoch 491: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.0355e-05 - acc: 1.0000 - val_loss: 4.7402 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 492/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0833e-05 - acc: 1.0000\n",
      "Epoch 492: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.0355e-05 - acc: 1.0000 - val_loss: 4.7403 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 493/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.6481e-06 - acc: 1.0000\n",
      "Epoch 493: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0355e-05 - acc: 1.0000 - val_loss: 4.7403 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 494/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 7.8377e-06 - acc: 1.0000\n",
      "Epoch 494: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0355e-05 - acc: 1.0000 - val_loss: 4.7403 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 495/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0844e-05 - acc: 1.0000\n",
      "Epoch 495: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7403 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 496/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 9.5066e-06 - acc: 1.0000\n",
      "Epoch 496: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7403 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 497/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1514e-05 - acc: 1.0000\n",
      "Epoch 497: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7403 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 498/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 8.9217e-06 - acc: 1.0000\n",
      "Epoch 498: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7404 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 499/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.1824e-05 - acc: 1.0000\n",
      "Epoch 499: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7404 - val_acc: 0.5000 - lr: 1.9531e-06\n",
      "Epoch 500/500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 1.0352e-05 - acc: 1.0000\n",
      "Epoch 500: val_acc did not improve from 0.50000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0358e-05 - acc: 1.0000 - val_loss: 4.7404 - val_acc: 0.5000 - lr: 1.9531e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=500,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('../model/model_.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[9, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[6, 2],\n",
       "        [1, 1]],\n",
       "\n",
       "       [[7, 2],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[9, 1],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[8, 0],\n",
       "        [0, 2]],\n",
       "\n",
       "       [[6, 0],\n",
       "        [4, 0]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('../model/model_.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01-3. LSTM - 성능 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 12:21:50.259230: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:21:50.296656: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:21:50.296840: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:21:50.298155: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:21:50.298380: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:21:50.298496: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:21:51.585825: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:21:51.586158: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:21:51.586293: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-13 12:21:51.586393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3977 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1702437712.186775   47413 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702437712.191672   47553 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.0.4-0ubuntu1~22.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 4, 15), found shape=(None, 4, 99)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 75\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     73\u001b[0m input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(np\u001b[38;5;241m.\u001b[39marray(seq[\u001b[38;5;241m-\u001b[39mseq_length:], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     77\u001b[0m i_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39margmax(y_pred))\n\u001b[1;32m     78\u001b[0m conf \u001b[38;5;241m=\u001b[39m y_pred[i_pred]\n",
      "File \u001b[0;32m~/venv/mp_venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filel98pli47.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 4, 15), found shape=(None, 4, 99)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 8가지 제스처 인식 Test\n",
    "max_num_hands = 1\n",
    "actions = ['go', 'back', 'stop', 'left_spin', 'right_spin', 'speed_up', 'speed_down', 'bad_gesture']\n",
    "\n",
    "# 시퀀스 길이 지정\n",
    "seq_length = 4\n",
    "\n",
    "model = keras.models.load_model(\"../model/model_.h5\")\n",
    "\n",
    "# 미디어파이프 패키지에서 손 인식을 위한 객체 생성\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands = max_num_hands,\n",
    "    min_detection_confidence = 0.5,\n",
    "    min_tracking_confidence = 0.5)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "seq = []\n",
    "action_seq = []\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        print(\"카메라 연결 실패\")\n",
    "        # break\n",
    "        continue\n",
    "    \n",
    "    img = cv2.flip(img, 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # 손 인식 여부 확인\n",
    "    if result.multi_hand_landmarks is not None:\n",
    "\n",
    "        for res in result.multi_hand_landmarks:\n",
    "        \n",
    "            joint = np.zeros((21, 4))\n",
    "        \n",
    "            for j, lm in enumerate(res.landmark):\n",
    "                joint[j] = [lm.x, lm.y, lm.z, lm.visibility]\n",
    "\n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19], :3]\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], :3]\n",
    "            v = v2 - v1 # [20, 3]\n",
    "\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "            angle = np.degrees(angle)\n",
    "\n",
    "            d = np.concatenate([joint.flatten(), angle])\n",
    "\n",
    "            seq.append(d)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img,\n",
    "                                      res,\n",
    "                                      mp_hands.HAND_CONNECTIONS\n",
    "                                    #   mp_hands.get_default_hand_landmarks_style(),\n",
    "                                    #   mp_hands.get_default_hand_connections_style()\n",
    "            )\n",
    "\n",
    "            if len(seq) < seq_length:\n",
    "                continue\n",
    "\n",
    "            input_data = np.expand_dims(np.array(seq[-seq_length:], dtype=np.float32), axis=0)\n",
    "\n",
    "            y_pred = model.predict(input_data).squeeze()\n",
    "\n",
    "            i_pred = int(np.argmax(y_pred))\n",
    "            conf = y_pred[i_pred]\n",
    "\n",
    "            if conf < 0.9:\n",
    "                continue\n",
    "\n",
    "            action = actions[i_pred]\n",
    "            action_seq.append(action)\n",
    "\n",
    "            if len(action_seq) < 8:\n",
    "                continue\n",
    "\n",
    "            this_action = '?'\n",
    "            if action_seq[-1] == action_seq[-2] == action_seq[-3]:\n",
    "                this_action = action\n",
    "\n",
    "            cv2.putText(img, f'{this_action.upper()}', org=(int(res.landmark[0].x * img.shape[1]), int(res.landmark[0].y * img.shape[0] + 20)), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "    cv2.imshow('Test', img)\n",
    "\n",
    "    key = cv2.waitKey(5) & 0xFF\n",
    "\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        break2-13 12:21:50.259230: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
    "2023-12-13 12:21:50.296656: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
    "2023-12-13 12:21:50.296840: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
    "2023-12-13 12:21:50.298155: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
    "2023-12-13 12:21:50.298380: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
    "2023-12-13 12:21:50.298496: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
    "2023-12-13 12:21:51.585825: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
    "2023-12-13 12:21:51.586158: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
    "2023-12-13 12:21:51.586293: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
    "2023-12-13 12:21:51.586393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3977 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
    "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
    "I0000 00:00:1702437712.186775   47413 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
    "I0000 00:00:1702437712.191672   47553 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.0.4-0ubuntu1~22.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
    "INFO: Created TensorFlow Lite XNNPACK delegate for CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02-1. KNN - 데이터셋 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv파일 로드됨 (16,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1702281672.960599    7169 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702281672.961473   73687 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.0.4-0ubuntu1~22.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 16)\n",
      "(3, 16)\n",
      "(4, 16)\n",
      "(5, 16)\n",
      "(6, 16)\n",
      "(7, 16)\n",
      "(8, 16)\n",
      "(9, 16)\n",
      "(10, 16)\n",
      "(11, 16)\n",
      "(12, 16)\n",
      "(13, 16)\n",
      "(14, 16)\n",
      "(15, 16)\n",
      "(16, 16)\n",
      "(17, 16)\n",
      "(18, 16)\n",
      "(19, 16)\n",
      "(20, 16)\n",
      "(21, 16)\n",
      "(22, 16)\n",
      "(23, 16)\n",
      "(24, 16)\n",
      "(25, 16)\n",
      "(26, 16)\n",
      "(27, 16)\n",
      "(28, 16)\n",
      "(29, 16)\n",
      "(30, 16)\n",
      "(31, 16)\n",
      "(32, 16)\n",
      "(33, 16)\n",
      "(34, 16)\n",
      "(35, 16)\n",
      "(36, 16)\n",
      "(37, 16)\n",
      "(38, 16)\n",
      "(39, 16)\n",
      "(40, 16)\n",
      "(41, 16)\n",
      "(42, 16)\n",
      "(43, 16)\n",
      "(44, 16)\n",
      "(45, 16)\n",
      "(46, 16)\n",
      "(47, 16)\n",
      "(48, 16)\n",
      "(49, 16)\n",
      "(50, 16)\n",
      "(51, 16)\n",
      "(52, 16)\n",
      "(53, 16)\n",
      "(54, 16)\n",
      "(55, 16)\n",
      "(56, 16)\n",
      "(57, 16)\n",
      "(58, 16)\n",
      "(59, 16)\n",
      "(60, 16)\n",
      "(61, 16)\n",
      "(62, 16)\n",
      "(63, 16)\n",
      "(64, 16)\n",
      "(65, 16)\n",
      "(66, 16)\n",
      "(67, 16)\n",
      "(68, 16)\n",
      "(69, 16)\n",
      "(70, 16)\n",
      "(71, 16)\n",
      "(72, 16)\n",
      "(73, 16)\n",
      "(74, 16)\n",
      "(75, 16)\n",
      "(76, 16)\n",
      "(77, 16)\n",
      "(78, 16)\n",
      "(79, 16)\n",
      "(80, 16)\n",
      "(81, 16)\n",
      "(82, 16)\n",
      "(83, 16)\n",
      "(84, 16)\n",
      "(85, 16)\n",
      "(86, 16)\n",
      "(87, 16)\n",
      "(88, 16)\n",
      "(89, 16)\n",
      "(90, 16)\n",
      "(91, 16)\n",
      "(92, 16)\n",
      "(93, 16)\n",
      "(94, 16)\n",
      "(95, 16)\n",
      "(96, 16)\n",
      "(97, 16)\n",
      "(98, 16)\n",
      "(99, 16)\n",
      "(100, 16)\n",
      "(101, 16)\n",
      "csv파일 로드됨 (16,)\n",
      "(2, 16)\n",
      "(3, 16)\n",
      "(4, 16)\n",
      "(5, 16)\n",
      "(6, 16)\n",
      "(7, 16)\n",
      "(8, 16)\n",
      "(9, 16)\n",
      "(10, 16)\n",
      "(11, 16)\n",
      "(12, 16)\n",
      "(13, 16)\n",
      "(14, 16)\n",
      "(15, 16)\n",
      "(16, 16)\n",
      "(17, 16)\n",
      "(18, 16)\n",
      "(19, 16)\n",
      "(20, 16)\n",
      "(21, 16)\n",
      "(22, 16)\n",
      "(23, 16)\n",
      "(24, 16)\n",
      "(25, 16)\n",
      "(26, 16)\n",
      "(27, 16)\n",
      "(28, 16)\n",
      "(29, 16)\n",
      "(30, 16)\n",
      "(31, 16)\n",
      "(32, 16)\n",
      "(33, 16)\n",
      "(34, 16)\n",
      "(35, 16)\n",
      "(36, 16)\n",
      "(37, 16)\n",
      "(38, 16)\n",
      "(39, 16)\n",
      "(40, 16)\n",
      "(41, 16)\n",
      "(42, 16)\n",
      "(43, 16)\n",
      "(44, 16)\n",
      "(45, 16)\n",
      "(46, 16)\n",
      "(47, 16)\n",
      "(48, 16)\n",
      "(49, 16)\n",
      "(50, 16)\n",
      "(51, 16)\n",
      "(52, 16)\n",
      "(53, 16)\n",
      "(54, 16)\n",
      "(55, 16)\n",
      "(56, 16)\n",
      "(57, 16)\n",
      "(58, 16)\n",
      "(59, 16)\n",
      "(60, 16)\n",
      "(61, 16)\n",
      "(62, 16)\n",
      "(63, 16)\n",
      "(64, 16)\n",
      "(65, 16)\n",
      "(66, 16)\n",
      "(67, 16)\n",
      "(68, 16)\n",
      "(69, 16)\n",
      "(70, 16)\n",
      "(71, 16)\n",
      "(72, 16)\n",
      "(73, 16)\n",
      "(74, 16)\n",
      "(75, 16)\n",
      "(76, 16)\n",
      "(77, 16)\n",
      "(78, 16)\n",
      "(79, 16)\n",
      "(80, 16)\n",
      "(81, 16)\n",
      "(82, 16)\n",
      "(83, 16)\n",
      "(84, 16)\n",
      "(85, 16)\n",
      "(86, 16)\n",
      "(87, 16)\n",
      "(88, 16)\n",
      "(89, 16)\n",
      "(90, 16)\n",
      "(91, 16)\n",
      "(92, 16)\n",
      "(93, 16)\n",
      "(94, 16)\n",
      "(95, 16)\n",
      "(96, 16)\n",
      "(97, 16)\n",
      "(98, 16)\n",
      "(99, 16)\n",
      "(100, 16)\n",
      "(101, 16)\n",
      "csv파일 로드됨 (16,)\n",
      "(2, 16)\n",
      "(3, 16)\n",
      "(4, 16)\n",
      "(5, 16)\n",
      "(6, 16)\n",
      "(7, 16)\n",
      "(8, 16)\n",
      "(9, 16)\n",
      "(10, 16)\n",
      "(11, 16)\n",
      "(12, 16)\n",
      "(13, 16)\n",
      "(14, 16)\n",
      "(15, 16)\n",
      "(16, 16)\n",
      "(17, 16)\n",
      "(18, 16)\n",
      "(19, 16)\n",
      "(20, 16)\n",
      "(21, 16)\n",
      "(22, 16)\n",
      "(23, 16)\n",
      "(24, 16)\n",
      "(25, 16)\n",
      "(26, 16)\n",
      "(27, 16)\n",
      "(28, 16)\n",
      "(29, 16)\n",
      "(30, 16)\n",
      "(31, 16)\n",
      "(32, 16)\n",
      "(33, 16)\n",
      "(34, 16)\n",
      "(35, 16)\n",
      "(36, 16)\n",
      "(37, 16)\n",
      "(38, 16)\n",
      "(39, 16)\n",
      "(40, 16)\n",
      "(41, 16)\n",
      "(42, 16)\n",
      "(43, 16)\n",
      "(44, 16)\n",
      "(45, 16)\n",
      "(46, 16)\n",
      "(47, 16)\n",
      "(48, 16)\n",
      "(49, 16)\n",
      "(50, 16)\n",
      "(51, 16)\n",
      "(52, 16)\n",
      "(53, 16)\n",
      "(54, 16)\n",
      "(55, 16)\n",
      "(56, 16)\n",
      "(57, 16)\n",
      "(58, 16)\n",
      "(59, 16)\n",
      "(60, 16)\n",
      "(61, 16)\n",
      "(62, 16)\n",
      "(63, 16)\n",
      "(64, 16)\n",
      "(65, 16)\n",
      "(66, 16)\n",
      "(67, 16)\n",
      "(68, 16)\n",
      "(69, 16)\n",
      "(70, 16)\n",
      "(71, 16)\n",
      "(72, 16)\n",
      "(73, 16)\n",
      "(74, 16)\n",
      "(75, 16)\n",
      "(76, 16)\n",
      "(77, 16)\n",
      "(78, 16)\n",
      "(79, 16)\n",
      "(80, 16)\n",
      "(81, 16)\n",
      "(82, 16)\n",
      "(83, 16)\n",
      "(84, 16)\n",
      "(85, 16)\n",
      "(86, 16)\n",
      "(87, 16)\n",
      "(88, 16)\n",
      "(89, 16)\n",
      "(90, 16)\n",
      "(91, 16)\n",
      "(92, 16)\n",
      "(93, 16)\n",
      "(94, 16)\n",
      "(95, 16)\n",
      "(96, 16)\n",
      "(97, 16)\n",
      "(98, 16)\n",
      "(99, 16)\n",
      "(100, 16)\n",
      "(101, 16)\n",
      "csv파일 로드됨 (16,)\n",
      "(2, 16)\n",
      "(3, 16)\n",
      "(4, 16)\n",
      "(5, 16)\n",
      "(6, 16)\n",
      "(7, 16)\n",
      "(8, 16)\n",
      "(9, 16)\n",
      "(10, 16)\n",
      "(11, 16)\n",
      "(12, 16)\n",
      "(13, 16)\n",
      "(14, 16)\n",
      "(15, 16)\n",
      "(16, 16)\n",
      "(17, 16)\n",
      "(18, 16)\n",
      "(19, 16)\n",
      "(20, 16)\n",
      "(21, 16)\n",
      "(22, 16)\n",
      "(23, 16)\n",
      "(24, 16)\n",
      "(25, 16)\n",
      "(26, 16)\n",
      "(27, 16)\n",
      "(28, 16)\n",
      "(29, 16)\n",
      "(30, 16)\n",
      "(31, 16)\n",
      "(32, 16)\n",
      "(33, 16)\n",
      "(34, 16)\n",
      "(35, 16)\n",
      "(36, 16)\n",
      "(37, 16)\n",
      "(38, 16)\n",
      "(39, 16)\n",
      "(40, 16)\n",
      "(41, 16)\n",
      "(42, 16)\n",
      "(43, 16)\n",
      "(44, 16)\n",
      "(45, 16)\n",
      "(46, 16)\n",
      "(47, 16)\n",
      "(48, 16)\n",
      "(49, 16)\n",
      "(50, 16)\n",
      "(51, 16)\n",
      "(52, 16)\n",
      "(53, 16)\n",
      "(54, 16)\n",
      "(55, 16)\n",
      "(56, 16)\n",
      "(57, 16)\n",
      "(58, 16)\n",
      "(59, 16)\n",
      "(60, 16)\n",
      "(61, 16)\n",
      "(62, 16)\n",
      "(63, 16)\n",
      "(64, 16)\n",
      "(65, 16)\n",
      "(66, 16)\n",
      "(67, 16)\n",
      "(68, 16)\n",
      "(69, 16)\n",
      "(70, 16)\n",
      "(71, 16)\n",
      "(72, 16)\n",
      "(73, 16)\n",
      "(74, 16)\n",
      "(75, 16)\n",
      "(76, 16)\n",
      "(77, 16)\n",
      "(78, 16)\n",
      "(79, 16)\n",
      "(80, 16)\n",
      "(81, 16)\n",
      "(82, 16)\n",
      "(83, 16)\n",
      "(84, 16)\n",
      "(85, 16)\n",
      "(86, 16)\n",
      "(87, 16)\n",
      "(88, 16)\n",
      "(89, 16)\n",
      "(90, 16)\n",
      "(91, 16)\n",
      "(92, 16)\n",
      "(93, 16)\n",
      "(94, 16)\n",
      "(95, 16)\n",
      "(96, 16)\n",
      "(97, 16)\n",
      "(98, 16)\n",
      "(99, 16)\n",
      "(100, 16)\n",
      "(101, 16)\n",
      "csv파일 로드됨 (16,)\n",
      "(2, 16)\n",
      "(3, 16)\n",
      "(4, 16)\n",
      "(5, 16)\n",
      "(6, 16)\n",
      "(7, 16)\n",
      "(8, 16)\n",
      "(9, 16)\n",
      "(10, 16)\n",
      "(11, 16)\n",
      "(12, 16)\n",
      "(13, 16)\n",
      "(14, 16)\n",
      "(15, 16)\n",
      "(16, 16)\n",
      "(17, 16)\n",
      "(18, 16)\n",
      "(19, 16)\n",
      "(20, 16)\n",
      "(21, 16)\n",
      "(22, 16)\n",
      "(23, 16)\n",
      "(24, 16)\n",
      "(25, 16)\n",
      "(26, 16)\n",
      "(27, 16)\n",
      "(28, 16)\n",
      "(29, 16)\n",
      "(30, 16)\n",
      "(31, 16)\n",
      "(32, 16)\n",
      "(33, 16)\n",
      "(34, 16)\n",
      "(35, 16)\n",
      "(36, 16)\n",
      "(37, 16)\n",
      "(38, 16)\n",
      "(39, 16)\n",
      "(40, 16)\n",
      "(41, 16)\n",
      "(42, 16)\n",
      "(43, 16)\n",
      "(44, 16)\n",
      "(45, 16)\n",
      "(46, 16)\n",
      "(47, 16)\n",
      "(48, 16)\n",
      "(49, 16)\n",
      "(50, 16)\n",
      "(51, 16)\n",
      "(52, 16)\n",
      "(53, 16)\n",
      "(54, 16)\n",
      "(55, 16)\n",
      "(56, 16)\n",
      "(57, 16)\n",
      "(58, 16)\n",
      "(59, 16)\n",
      "(60, 16)\n",
      "(61, 16)\n",
      "(62, 16)\n",
      "(63, 16)\n",
      "(64, 16)\n",
      "(65, 16)\n",
      "(66, 16)\n",
      "(67, 16)\n",
      "(68, 16)\n",
      "(69, 16)\n",
      "(70, 16)\n",
      "(71, 16)\n",
      "(72, 16)\n",
      "(73, 16)\n",
      "(74, 16)\n",
      "(75, 16)\n",
      "(76, 16)\n",
      "(77, 16)\n",
      "(78, 16)\n",
      "(79, 16)\n",
      "(80, 16)\n",
      "(81, 16)\n",
      "(82, 16)\n",
      "(83, 16)\n",
      "(84, 16)\n",
      "(85, 16)\n",
      "(86, 16)\n",
      "(87, 16)\n",
      "(88, 16)\n",
      "(89, 16)\n",
      "(90, 16)\n",
      "(91, 16)\n",
      "(92, 16)\n",
      "(93, 16)\n",
      "(94, 16)\n",
      "(95, 16)\n",
      "(96, 16)\n",
      "(97, 16)\n",
      "(98, 16)\n",
      "(99, 16)\n",
      "(100, 16)\n",
      "(101, 16)\n",
      "csv파일 로드됨 (16,)\n",
      "(2, 16)\n",
      "(3, 16)\n",
      "(4, 16)\n",
      "(5, 16)\n",
      "(6, 16)\n",
      "(7, 16)\n",
      "(8, 16)\n",
      "(9, 16)\n",
      "(10, 16)\n",
      "(11, 16)\n",
      "(12, 16)\n",
      "(13, 16)\n",
      "(14, 16)\n",
      "(15, 16)\n",
      "(16, 16)\n",
      "(17, 16)\n",
      "(18, 16)\n",
      "(19, 16)\n",
      "(20, 16)\n",
      "(21, 16)\n",
      "(22, 16)\n",
      "(23, 16)\n",
      "(24, 16)\n",
      "(25, 16)\n",
      "(26, 16)\n",
      "(27, 16)\n",
      "(28, 16)\n",
      "(29, 16)\n",
      "(30, 16)\n",
      "(31, 16)\n",
      "(32, 16)\n",
      "(33, 16)\n",
      "(34, 16)\n",
      "(35, 16)\n",
      "(36, 16)\n",
      "(37, 16)\n",
      "(38, 16)\n",
      "(39, 16)\n",
      "(40, 16)\n",
      "(41, 16)\n",
      "(42, 16)\n",
      "(43, 16)\n",
      "(44, 16)\n",
      "(45, 16)\n",
      "(46, 16)\n",
      "(47, 16)\n",
      "(48, 16)\n",
      "(49, 16)\n",
      "(50, 16)\n",
      "(51, 16)\n",
      "(52, 16)\n",
      "(53, 16)\n",
      "(54, 16)\n",
      "(55, 16)\n",
      "(56, 16)\n",
      "(57, 16)\n",
      "(58, 16)\n",
      "(59, 16)\n",
      "(60, 16)\n",
      "(61, 16)\n",
      "(62, 16)\n",
      "(63, 16)\n",
      "(64, 16)\n",
      "(65, 16)\n",
      "(66, 16)\n",
      "(67, 16)\n",
      "(68, 16)\n",
      "(69, 16)\n",
      "(70, 16)\n",
      "(71, 16)\n",
      "(72, 16)\n",
      "(73, 16)\n",
      "(74, 16)\n",
      "(75, 16)\n",
      "(76, 16)\n",
      "(77, 16)\n",
      "(78, 16)\n",
      "(79, 16)\n",
      "(80, 16)\n",
      "(81, 16)\n",
      "(82, 16)\n",
      "(83, 16)\n",
      "(84, 16)\n",
      "(85, 16)\n",
      "(86, 16)\n",
      "(87, 16)\n",
      "(88, 16)\n",
      "(89, 16)\n",
      "(90, 16)\n",
      "(91, 16)\n",
      "(92, 16)\n",
      "(93, 16)\n",
      "(94, 16)\n",
      "(95, 16)\n",
      "(96, 16)\n",
      "(97, 16)\n",
      "(98, 16)\n",
      "(99, 16)\n",
      "(100, 16)\n",
      "(101, 16)\n",
      "csv파일 로드됨 (16,)\n",
      "(2, 16)\n",
      "(3, 16)\n",
      "(4, 16)\n",
      "(5, 16)\n",
      "(6, 16)\n",
      "(7, 16)\n",
      "(8, 16)\n",
      "(9, 16)\n",
      "(10, 16)\n",
      "(11, 16)\n",
      "(12, 16)\n",
      "(13, 16)\n",
      "(14, 16)\n",
      "(15, 16)\n",
      "(16, 16)\n",
      "(17, 16)\n",
      "(18, 16)\n",
      "(19, 16)\n",
      "(20, 16)\n",
      "(21, 16)\n",
      "(22, 16)\n",
      "(23, 16)\n",
      "(24, 16)\n",
      "(25, 16)\n",
      "(26, 16)\n",
      "(27, 16)\n",
      "(28, 16)\n",
      "(29, 16)\n",
      "(30, 16)\n",
      "(31, 16)\n",
      "(32, 16)\n",
      "(33, 16)\n",
      "(34, 16)\n",
      "(35, 16)\n",
      "(36, 16)\n",
      "(37, 16)\n",
      "(38, 16)\n",
      "(39, 16)\n",
      "(40, 16)\n",
      "(41, 16)\n",
      "(42, 16)\n",
      "(43, 16)\n",
      "(44, 16)\n",
      "(45, 16)\n",
      "(46, 16)\n",
      "(47, 16)\n",
      "(48, 16)\n",
      "(49, 16)\n",
      "(50, 16)\n",
      "(51, 16)\n",
      "(52, 16)\n",
      "(53, 16)\n",
      "(54, 16)\n",
      "(55, 16)\n",
      "(56, 16)\n",
      "(57, 16)\n",
      "(58, 16)\n",
      "(59, 16)\n",
      "(60, 16)\n",
      "(61, 16)\n",
      "(62, 16)\n",
      "(63, 16)\n",
      "(64, 16)\n",
      "(65, 16)\n",
      "(66, 16)\n",
      "(67, 16)\n",
      "(68, 16)\n",
      "(69, 16)\n",
      "(70, 16)\n",
      "(71, 16)\n",
      "(72, 16)\n",
      "(73, 16)\n",
      "(74, 16)\n",
      "(75, 16)\n",
      "(76, 16)\n",
      "(77, 16)\n",
      "(78, 16)\n",
      "(79, 16)\n",
      "(80, 16)\n",
      "(81, 16)\n",
      "(82, 16)\n",
      "(83, 16)\n",
      "(84, 16)\n",
      "(85, 16)\n",
      "(86, 16)\n",
      "(87, 16)\n",
      "(88, 16)\n",
      "(89, 16)\n",
      "(90, 16)\n",
      "(91, 16)\n",
      "(92, 16)\n",
      "(93, 16)\n",
      "(94, 16)\n",
      "(95, 16)\n",
      "(96, 16)\n",
      "(97, 16)\n",
      "(98, 16)\n",
      "(99, 16)\n",
      "(100, 16)\n",
      "(101, 16)\n",
      "csv파일 로드됨 (16,)\n",
      "(2, 16)\n",
      "(3, 16)\n",
      "(4, 16)\n",
      "(5, 16)\n",
      "(6, 16)\n",
      "(7, 16)\n",
      "(8, 16)\n",
      "(9, 16)\n",
      "(10, 16)\n",
      "(11, 16)\n",
      "(12, 16)\n",
      "(13, 16)\n",
      "(14, 16)\n",
      "(15, 16)\n",
      "(16, 16)\n",
      "(17, 16)\n",
      "(18, 16)\n",
      "(19, 16)\n",
      "(20, 16)\n",
      "(21, 16)\n",
      "(22, 16)\n",
      "(23, 16)\n",
      "(24, 16)\n",
      "(25, 16)\n",
      "(26, 16)\n",
      "(27, 16)\n",
      "(28, 16)\n",
      "(29, 16)\n",
      "(30, 16)\n",
      "(31, 16)\n",
      "(32, 16)\n",
      "(33, 16)\n",
      "(34, 16)\n",
      "(35, 16)\n",
      "(36, 16)\n",
      "(37, 16)\n",
      "(38, 16)\n",
      "(39, 16)\n",
      "(40, 16)\n",
      "(41, 16)\n",
      "(42, 16)\n",
      "(43, 16)\n",
      "(44, 16)\n",
      "(45, 16)\n",
      "(46, 16)\n",
      "(47, 16)\n",
      "(48, 16)\n",
      "(49, 16)\n",
      "(50, 16)\n",
      "(51, 16)\n",
      "(52, 16)\n",
      "(53, 16)\n",
      "(54, 16)\n",
      "(55, 16)\n",
      "(56, 16)\n",
      "(57, 16)\n",
      "(58, 16)\n",
      "(59, 16)\n",
      "(60, 16)\n",
      "(61, 16)\n",
      "(62, 16)\n",
      "(63, 16)\n",
      "(64, 16)\n",
      "(65, 16)\n",
      "(66, 16)\n",
      "(67, 16)\n",
      "(68, 16)\n",
      "(69, 16)\n",
      "(70, 16)\n",
      "(71, 16)\n",
      "(72, 16)\n",
      "(73, 16)\n",
      "(74, 16)\n",
      "(75, 16)\n",
      "(76, 16)\n",
      "(77, 16)\n",
      "(78, 16)\n",
      "(79, 16)\n",
      "(80, 16)\n",
      "(81, 16)\n",
      "(82, 16)\n",
      "(83, 16)\n",
      "(84, 16)\n",
      "(85, 16)\n",
      "(86, 16)\n",
      "(87, 16)\n",
      "(88, 16)\n",
      "(89, 16)\n",
      "(90, 16)\n",
      "(91, 16)\n",
      "(92, 16)\n",
      "(93, 16)\n",
      "(94, 16)\n",
      "(95, 16)\n",
      "(96, 16)\n",
      "(97, 16)\n",
      "(98, 16)\n",
      "(99, 16)\n",
      "(100, 16)\n",
      "(101, 16)\n"
     ]
    }
   ],
   "source": [
    "max_num_hands = 1\n",
    "count_click = 0\n",
    "\n",
    "# 제스처 클래스 정의\n",
    "gestures = {\n",
    "    0:'go', 1:'back', 2:'stop', 3:'left_spin', 4:'right_spin', 5:'speed_up',\n",
    "    6:'speed_down', 7:'bad_gesture'}\n",
    "action_label = 0\n",
    "action = str(gestures[action_label])\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=max_num_hands,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "file = np.genfromtxt('../data/gesture_train_tovstack.csv', delimiter=',')\n",
    "print(\"csv파일 로드됨\", file.shape)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 클릭 이벤트\n",
    "# 화면을 클릭했을 때 각도 값을 csv파일에 추가\n",
    "def click(event, x, y, flags, param):\n",
    "    global data, file, count_click\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        count_click += 1\n",
    "        file = np.vstack((file, data))  # numpy의 vstack 사용\n",
    "        print(file.shape)\n",
    "\n",
    "cv2.namedWindow('Dataset')\n",
    "cv2.setMouseCallback('Dataset', click)\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"카메라 연결 실패\")\n",
    "        # break\n",
    "        continue\n",
    "\n",
    "    img = cv2.flip(img, 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    cv2.putText(img, action, org=(10, 30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0, 0, 255), thickness=3)\n",
    "    cv2.putText(img, str(count_click), org=(10, 80), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "    \n",
    "    # 손 인식 여부 확인\n",
    "    if result.multi_hand_landmarks is not None:\n",
    "\n",
    "        for res in result.multi_hand_landmarks:\n",
    "\n",
    "            joint = np.zeros((21, 3))\n",
    "\n",
    "            for j, lm in enumerate(res.landmark):\n",
    "                joint[j] = [lm.x, lm.y, lm.z]\n",
    "\n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19],:]\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],:]\n",
    "            v = v2 - v1 # [20,3]\n",
    "\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "            angle = np.degrees(angle)\n",
    "\n",
    "            data = np.array([angle], dtype=np.float32)\n",
    "            data = np.append(data, action_label)\n",
    "            \n",
    "            # 각도값 출력 확인\n",
    "            # print(data)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img,\n",
    "                                      res,\n",
    "                                      mp_hands.HAND_CONNECTIONS\n",
    "                                    #   mp_hands.get_default_hand_landmarks_style(),\n",
    "                                    #   mp_hands.get_default_hand_connections_style()\n",
    "            )\n",
    "\n",
    "    cv2.imshow('Dataset', img)\n",
    "\n",
    "    key = cv2.waitKey(5) & 0xFF\n",
    "\n",
    "    if key == ord('a'):\n",
    "        created_time = str(time.strftime('%X', time.localtime(time.time())))\n",
    "        os.makedirs('../data/dataset', exist_ok=True)\n",
    "        np.savetxt(os.path.join('../data/dataset', f'{action}_{created_time}.csv'), file[1:], delimiter=',')\n",
    "        \n",
    "        if action_label == 7:\n",
    "            action_label = 0\n",
    "        else:\n",
    "            action_label += 1\n",
    "        action = str(gestures[action_label])\n",
    "        count_click = 0\n",
    "\n",
    "        file = np.genfromtxt('../data/gesture_train_tovstack.csv', delimiter=',')\n",
    "        print(\"csv파일 로드됨\", file.shape)\n",
    "\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "\n",
    "created_time = str(time.strftime('%X', time.localtime(time.time())))\n",
    "# exist_ok를 True로 설정하지 않았을 땐, 해당 디렉토리가 존재하는 경우 exception 에러 발생\n",
    "os.makedirs('../data/dataset', exist_ok=True)\n",
    "# 한 동작만 저장\n",
    "action = str(gestures[action_label])\n",
    "np.savetxt(os.path.join('../data/dataset', f'{action}_{created_time}.csv'), file[1:], delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02-2. KNN - 성능 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제스처당 10개 dataset\n",
    "df_file_10_go = pd.read_csv('../data/dataset_10_231211/go_04:54:34 PM.csv', header=None)\n",
    "df_file_10_back = pd.read_csv('../data/dataset_10_231211/back_04:55:04 PM.csv', header=None)\n",
    "df_file_10_stop = pd.read_csv('../data/dataset_10_231211/stop_04:55:31 PM.csv', header=None)\n",
    "df_file_10_left = pd.read_csv('../data/dataset_10_231211/left_spin_04:55:49 PM.csv', header=None)\n",
    "df_file_10_right = pd.read_csv('../data/dataset_10_231211/right_spin_04:56:08 PM.csv', header=None)\n",
    "df_file_10_up = pd.read_csv('../data/dataset_10_231211/speed_up_04:57:54 PM.csv', header=None)\n",
    "df_file_10_down = pd.read_csv('../data/dataset_10_231211/speed_down_04:58:18 PM.csv', header=None)\n",
    "df_file_10_bad = pd.read_csv('../data/dataset_10_231211/bad_gesture_05:00:03 PM.csv', header=None)\n",
    "\n",
    "df_file_10 = pd.concat([df_file_10_go, df_file_10_back, df_file_10_stop, df_file_10_left, df_file_10_right, df_file_10_up, df_file_10_down, df_file_10_bad], ignore_index=True)\n",
    "df_file_10.to_csv(\"../data/dataset_10_231211/total_10.csv\", index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제스처당 100개 dataset\n",
    "df_file_100_go = pd.read_csv('../data/dataset_100_231211_2/go_05:04:05 PM.csv', header=None)\n",
    "df_file_100_back = pd.read_csv('../data/dataset_100_231211_2/back_05:06:55 PM.csv', header=None)\n",
    "df_file_100_stop = pd.read_csv('../data/dataset_100_231211_2/stop_05:09:41 PM.csv', header=None)\n",
    "df_file_100_left = pd.read_csv('../data/dataset_100_231211_2/left_spin_05:12:50 PM.csv', header=None)\n",
    "df_file_100_right = pd.read_csv('../data/dataset_100_231211_2/right_spin_05:15:07 PM.csv', header=None)\n",
    "df_file_100_up = pd.read_csv('../data/dataset_100_231211_2/speed_up_05:18:02 PM.csv', header=None)\n",
    "df_file_100_down = pd.read_csv('../data/dataset_100_231211_2/speed_down_05:20:26 PM.csv', header=None)\n",
    "df_file_100_bad = pd.read_csv('../data/dataset_100_231211_2/bad_gesture_05:23:23 PM.csv', header=None)\n",
    "\n",
    "df_file_100 = pd.concat([df_file_100_go, df_file_100_back, df_file_100_stop, df_file_100_left, df_file_100_right, df_file_100_up, df_file_100_down, df_file_100_bad], ignore_index=True)\n",
    "df_file_100.to_csv(\"../data/dataset_100_231211_2/total_100.csv\", index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = np.genfromtxt('../data/dataset_10_231211/total_10.csv', delimiter=',')\n",
    "# file = np.genfromtxt('../data/dataset_100_231211_2/total_100.csv', delimiter=',')\n",
    "# file = np.genfromtxt('../data/dataset_2_1/bad_gesture_03:15:29 AM.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 16)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x데이터와 y데이터 나누기\n",
    "# train셋, test셋 split\n",
    "# file = np.genfromtxt('../data/dataset_2_1/bad_gesture_03:15:29 AM.csv', delimiter=',')\n",
    "angle = file[:,:-1].astype(np.float32)\n",
    "label = file[:, -1].astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(angle,\n",
    "                                                                    label,\n",
    "                                                                    test_size = 0.2,\n",
    "                                                                    random_state = 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN 모델 생성 후 학습\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(X_train, cv2.ml.ROW_SAMPLE, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "# 정확도 계산\n",
    "ret, result, neighbours, dist = knn.findNearest(np.array(X_test, dtype=np.float32), k=3)\n",
    "accuracy = accuracy_score(y_test, result.flatten())\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1702284721.226737    7169 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702284721.227843   75142 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.0.4-0ubuntu1~22.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n"
     ]
    }
   ],
   "source": [
    "# 인식 결과를 단순히 출력하도록\n",
    "max_num_hands = 1\n",
    "\n",
    "gestures = {\n",
    "    0:'go', 1:'back', 2:'stop', 3:'left_spin', 4:'right_spin', 5:'speed_up',\n",
    "    6:'speed_down', 7:'bad_gesture'}\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=max_num_hands,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "file = np.genfromtxt('../data/dataset_100_231211_2/total_100.csv', delimiter=',')\n",
    "angle = file[:,:-1].astype(np.float32)\n",
    "label = file[:, -1].astype(np.float32)\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(angle, cv2.ml.ROW_SAMPLE, label)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"카메라 연결 실패\")\n",
    "        break\n",
    "        # continue\n",
    "\n",
    "    img = cv2.flip(img, 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    result = hands.process(img)\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if result.multi_hand_landmarks is not None:\n",
    "\n",
    "        for res in result.multi_hand_landmarks:\n",
    "\n",
    "            joint = np.zeros((21, 3))\n",
    "\n",
    "            for j, lm in enumerate(res.landmark):\n",
    "                joint[j] = [lm.x, lm.y, lm.z]\n",
    "\n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19],:]\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],:]\n",
    "            v = v2 - v1 # [20,3]\n",
    "\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "\n",
    "            angle = np.degrees(angle)\n",
    "\n",
    "            data = np.array([angle], dtype=np.float32)\n",
    "            ret, results, neighbours, dist = knn.findNearest(data, 5)\n",
    "            idx = int(results[0][0])\n",
    "\n",
    "            if idx in gestures.keys():\n",
    "                cv2.putText(img, text=gestures[idx].upper(), org=(int(res.landmark[0].x * img.shape[1]), int(res.landmark[0].y * img.shape[0] + 20)), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img,\n",
    "                                      res,\n",
    "                                      mp_hands.HAND_CONNECTIONS\n",
    "                                    #   mp_hands.get_default_hand_landmarks_style(),\n",
    "                                    #   mp_hands.get_default_hand_connections_style()\n",
    "            )\n",
    "    \n",
    "    cv2.imshow('Test', img)\n",
    "\n",
    "    key = cv2.waitKey(5) & 0xFF\n",
    "\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03-1. RNN - 모델 생성 후 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_file = pd.read_csv('../data/dataset_10_231211/total_10.csv', delimiter=',', header=None)\n",
    "df_file = pd.read_csv('../data/dataset_100_231211_2/total_100.csv', delimiter=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 16)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.817553</td>\n",
       "      <td>6.911163</td>\n",
       "      <td>13.913456</td>\n",
       "      <td>11.891656</td>\n",
       "      <td>7.431317</td>\n",
       "      <td>5.680053</td>\n",
       "      <td>6.239611</td>\n",
       "      <td>4.427707</td>\n",
       "      <td>3.422860</td>\n",
       "      <td>9.662763</td>\n",
       "      <td>3.757614</td>\n",
       "      <td>4.510948</td>\n",
       "      <td>4.989828</td>\n",
       "      <td>5.536578</td>\n",
       "      <td>4.706629</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.436653</td>\n",
       "      <td>3.327865</td>\n",
       "      <td>20.474810</td>\n",
       "      <td>6.176126</td>\n",
       "      <td>3.330752</td>\n",
       "      <td>3.422201</td>\n",
       "      <td>2.895099</td>\n",
       "      <td>3.855422</td>\n",
       "      <td>2.389583</td>\n",
       "      <td>5.062871</td>\n",
       "      <td>3.134106</td>\n",
       "      <td>4.606619</td>\n",
       "      <td>8.898752</td>\n",
       "      <td>4.048503</td>\n",
       "      <td>6.283424</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.762844</td>\n",
       "      <td>7.114627</td>\n",
       "      <td>8.630678</td>\n",
       "      <td>11.170781</td>\n",
       "      <td>9.344625</td>\n",
       "      <td>5.904938</td>\n",
       "      <td>4.165658</td>\n",
       "      <td>6.866282</td>\n",
       "      <td>4.478986</td>\n",
       "      <td>5.621472</td>\n",
       "      <td>5.232038</td>\n",
       "      <td>5.797524</td>\n",
       "      <td>2.415509</td>\n",
       "      <td>7.242287</td>\n",
       "      <td>7.996302</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.550770</td>\n",
       "      <td>12.552555</td>\n",
       "      <td>20.597082</td>\n",
       "      <td>16.350975</td>\n",
       "      <td>11.464218</td>\n",
       "      <td>6.685272</td>\n",
       "      <td>8.198183</td>\n",
       "      <td>6.388839</td>\n",
       "      <td>4.680421</td>\n",
       "      <td>9.917696</td>\n",
       "      <td>5.143094</td>\n",
       "      <td>6.091669</td>\n",
       "      <td>1.582255</td>\n",
       "      <td>6.358165</td>\n",
       "      <td>6.398254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.223051</td>\n",
       "      <td>3.957166</td>\n",
       "      <td>13.519729</td>\n",
       "      <td>7.740565</td>\n",
       "      <td>4.435032</td>\n",
       "      <td>4.299756</td>\n",
       "      <td>3.553062</td>\n",
       "      <td>4.972548</td>\n",
       "      <td>3.501531</td>\n",
       "      <td>1.849782</td>\n",
       "      <td>5.823893</td>\n",
       "      <td>5.117098</td>\n",
       "      <td>8.688388</td>\n",
       "      <td>6.932795</td>\n",
       "      <td>6.490625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>32.363659</td>\n",
       "      <td>15.577159</td>\n",
       "      <td>32.668846</td>\n",
       "      <td>38.600334</td>\n",
       "      <td>94.585861</td>\n",
       "      <td>56.851692</td>\n",
       "      <td>45.577324</td>\n",
       "      <td>6.582920</td>\n",
       "      <td>16.107603</td>\n",
       "      <td>73.659637</td>\n",
       "      <td>71.023376</td>\n",
       "      <td>48.703438</td>\n",
       "      <td>83.975502</td>\n",
       "      <td>64.367081</td>\n",
       "      <td>40.280941</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>31.872707</td>\n",
       "      <td>20.150658</td>\n",
       "      <td>45.110435</td>\n",
       "      <td>28.549080</td>\n",
       "      <td>117.074310</td>\n",
       "      <td>38.961689</td>\n",
       "      <td>31.785032</td>\n",
       "      <td>7.770251</td>\n",
       "      <td>10.991480</td>\n",
       "      <td>71.379311</td>\n",
       "      <td>72.125885</td>\n",
       "      <td>54.303837</td>\n",
       "      <td>95.119141</td>\n",
       "      <td>58.032421</td>\n",
       "      <td>37.676659</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>23.975588</td>\n",
       "      <td>8.008963</td>\n",
       "      <td>14.328184</td>\n",
       "      <td>30.514959</td>\n",
       "      <td>91.281586</td>\n",
       "      <td>28.018032</td>\n",
       "      <td>16.497669</td>\n",
       "      <td>17.120991</td>\n",
       "      <td>11.196115</td>\n",
       "      <td>25.950314</td>\n",
       "      <td>128.337112</td>\n",
       "      <td>17.018614</td>\n",
       "      <td>51.290264</td>\n",
       "      <td>117.223816</td>\n",
       "      <td>20.038288</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>24.604853</td>\n",
       "      <td>10.077657</td>\n",
       "      <td>18.128210</td>\n",
       "      <td>25.286041</td>\n",
       "      <td>105.439560</td>\n",
       "      <td>24.751562</td>\n",
       "      <td>12.923851</td>\n",
       "      <td>16.054342</td>\n",
       "      <td>7.480577</td>\n",
       "      <td>19.583553</td>\n",
       "      <td>143.034241</td>\n",
       "      <td>13.651463</td>\n",
       "      <td>42.423565</td>\n",
       "      <td>130.454437</td>\n",
       "      <td>14.911717</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>21.849928</td>\n",
       "      <td>8.833130</td>\n",
       "      <td>9.202619</td>\n",
       "      <td>28.175606</td>\n",
       "      <td>87.867386</td>\n",
       "      <td>30.947699</td>\n",
       "      <td>13.672752</td>\n",
       "      <td>10.581129</td>\n",
       "      <td>8.744481</td>\n",
       "      <td>23.694559</td>\n",
       "      <td>151.915085</td>\n",
       "      <td>12.930564</td>\n",
       "      <td>39.853985</td>\n",
       "      <td>146.094498</td>\n",
       "      <td>12.250643</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3           4          5   \\\n",
       "0    20.817553   6.911163  13.913456  11.891656    7.431317   5.680053   \n",
       "1    17.436653   3.327865  20.474810   6.176126    3.330752   3.422201   \n",
       "2    17.762844   7.114627   8.630678  11.170781    9.344625   5.904938   \n",
       "3    19.550770  12.552555  20.597082  16.350975   11.464218   6.685272   \n",
       "4    19.223051   3.957166  13.519729   7.740565    4.435032   4.299756   \n",
       "..         ...        ...        ...        ...         ...        ...   \n",
       "795  32.363659  15.577159  32.668846  38.600334   94.585861  56.851692   \n",
       "796  31.872707  20.150658  45.110435  28.549080  117.074310  38.961689   \n",
       "797  23.975588   8.008963  14.328184  30.514959   91.281586  28.018032   \n",
       "798  24.604853  10.077657  18.128210  25.286041  105.439560  24.751562   \n",
       "799  21.849928   8.833130   9.202619  28.175606   87.867386  30.947699   \n",
       "\n",
       "            6          7          8          9           10         11  \\\n",
       "0     6.239611   4.427707   3.422860   9.662763    3.757614   4.510948   \n",
       "1     2.895099   3.855422   2.389583   5.062871    3.134106   4.606619   \n",
       "2     4.165658   6.866282   4.478986   5.621472    5.232038   5.797524   \n",
       "3     8.198183   6.388839   4.680421   9.917696    5.143094   6.091669   \n",
       "4     3.553062   4.972548   3.501531   1.849782    5.823893   5.117098   \n",
       "..         ...        ...        ...        ...         ...        ...   \n",
       "795  45.577324   6.582920  16.107603  73.659637   71.023376  48.703438   \n",
       "796  31.785032   7.770251  10.991480  71.379311   72.125885  54.303837   \n",
       "797  16.497669  17.120991  11.196115  25.950314  128.337112  17.018614   \n",
       "798  12.923851  16.054342   7.480577  19.583553  143.034241  13.651463   \n",
       "799  13.672752  10.581129   8.744481  23.694559  151.915085  12.930564   \n",
       "\n",
       "            12          13         14   15  \n",
       "0     4.989828    5.536578   4.706629  0.0  \n",
       "1     8.898752    4.048503   6.283424  0.0  \n",
       "2     2.415509    7.242287   7.996302  0.0  \n",
       "3     1.582255    6.358165   6.398254  0.0  \n",
       "4     8.688388    6.932795   6.490625  0.0  \n",
       "..         ...         ...        ...  ...  \n",
       "795  83.975502   64.367081  40.280941  7.0  \n",
       "796  95.119141   58.032421  37.676659  7.0  \n",
       "797  51.290264  117.223816  20.038288  7.0  \n",
       "798  42.423565  130.454437  14.911717  7.0  \n",
       "799  39.853985  146.094498  12.250643  7.0  \n",
       "\n",
       "[800 rows x 16 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x데이터와 y데이터 나누기\n",
    "# train셋, test셋 split\n",
    "# df_file = pd.read_csv('/home/ckdal/dev_ws/project/Dl_Project/data/dataset_knn_1211/bad_gesture_01:03:08 PM.csv', header=None)\n",
    "df_angle = df_file.iloc[:, 0:15]\n",
    "df_label = df_file.iloc[:, -1]\n",
    "\n",
    "# 훈련 데이터는 전체 데이터를 대표할 수 있도록 라벨이 골고루 포함되어야 함\n",
    "# stratify: 원래 데이터의 분포와 유사하게 데이터를 추출해주는 파라미터\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(df_angle,\n",
    "                                                                    df_label,\n",
    "                                                                    test_size = 0.2,\n",
    "                                                                    random_state = 2023,\n",
    "                                                                    stratify=df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output = False)\n",
    "\n",
    "y_train_np = y_train.to_numpy()\n",
    "# 1D 배열을 열이 1인 2D 배열로 변환\n",
    "y_train_2d = y_train_np.reshape(-1, 1)\n",
    "y_train_encoded = encoder.fit_transform(y_train_2d)\n",
    "\n",
    "y_test_np = y_test.to_numpy()\n",
    "y_test_2d = y_test_np.reshape(-1, 1)\n",
    "y_test_encoded = encoder.fit_transform(y_test_2d)\n",
    "\n",
    "# y_train_encoded\n",
    "y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640, 8)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded.shape\n",
    "# y_test_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델 생성\n",
    "# 이진 분류\n",
    "# model = models.Sequential()\n",
    "\n",
    "# model.add(layers.Dense(input_dim=15, units=64, activation=None, kernel_initializer=initializers.he_uniform()))\n",
    "\n",
    "# model.add(layers.Activation('elu'))\n",
    "\n",
    "# model.add(layers.Dense(units=32, activation=None, kernel_initializer=initializers.he_uniform())) \n",
    "# model.add(layers.Activation('elu')) \n",
    "\n",
    "# model.add(layers.Dense(units=32, activation=None, kernel_initializer=initializers.he_uniform())) \n",
    "# model.add(layers.Activation('elu'))\n",
    "\n",
    "# model.add(layers.Dropout(rate=0.5))\n",
    "\n",
    "# # 출력 레이어\n",
    "# model.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# model.compile(optimizer=optimizers.Adam(),\n",
    "#               loss=losses.binary_crossentropy,\n",
    "#               metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "# 다중 클래스 분류\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(input_dim=15, units=64, activation=None, kernel_initializer=initializers.he_uniform()))\n",
    "\n",
    "model.add(layers.Activation('elu'))\n",
    "\n",
    "model.add(layers.Dense(units=32, activation=None, kernel_initializer=initializers.he_uniform())) \n",
    "model.add(layers.Activation('elu')) \n",
    "\n",
    "model.add(layers.Dense(units=32, activation=None, kernel_initializer=initializers.he_uniform())) \n",
    "model.add(layers.Activation('elu'))\n",
    "\n",
    "model.add(layers.Dropout(rate=0.5))\n",
    "\n",
    "# 출력 레이어\n",
    "model.add(layers.Dense(units=8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss=losses.categorical_crossentropy,\n",
    "              metrics=[metrics.categorical_accuracy]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(layers.LSTM(64, return_sequences=True,\n",
    "#                 input_shape=(70, 84))) \n",
    "\n",
    "# model.add(layers.LSTM(32, return_sequences=True))\n",
    "\n",
    "# model.add(layers.LSTM(32))\n",
    "\n",
    "# model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#                 optimizer='adam',\n",
    "#                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 113ms/step - loss: 178.1456 - categorical_accuracy: 0.1250 - val_loss: 100.2381 - val_categorical_accuracy: 0.1979\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 154.4971 - categorical_accuracy: 0.1205 - val_loss: 77.7591 - val_categorical_accuracy: 0.2292\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 129.9858 - categorical_accuracy: 0.1607 - val_loss: 59.2337 - val_categorical_accuracy: 0.2240\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 107.1803 - categorical_accuracy: 0.2076 - val_loss: 46.8906 - val_categorical_accuracy: 0.2552\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 94.0995 - categorical_accuracy: 0.1942 - val_loss: 39.2543 - val_categorical_accuracy: 0.2604\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 83.3265 - categorical_accuracy: 0.2121 - val_loss: 34.1211 - val_categorical_accuracy: 0.3125\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 73.3505 - categorical_accuracy: 0.2321 - val_loss: 29.4237 - val_categorical_accuracy: 0.3385\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 61.7982 - categorical_accuracy: 0.2188 - val_loss: 24.6059 - val_categorical_accuracy: 0.3490\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 51.9448 - categorical_accuracy: 0.2746 - val_loss: 20.2605 - val_categorical_accuracy: 0.3542\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 44.8831 - categorical_accuracy: 0.2433 - val_loss: 16.6632 - val_categorical_accuracy: 0.3750\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 37.1916 - categorical_accuracy: 0.3036 - val_loss: 14.0113 - val_categorical_accuracy: 0.4271\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 36.6093 - categorical_accuracy: 0.2969 - val_loss: 11.9487 - val_categorical_accuracy: 0.4427\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 32.1628 - categorical_accuracy: 0.2924 - val_loss: 10.2557 - val_categorical_accuracy: 0.4844\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 25.1897 - categorical_accuracy: 0.3415 - val_loss: 8.7213 - val_categorical_accuracy: 0.5052\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 24.6232 - categorical_accuracy: 0.3371 - val_loss: 7.3317 - val_categorical_accuracy: 0.5469\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 21.7460 - categorical_accuracy: 0.3415 - val_loss: 6.1116 - val_categorical_accuracy: 0.5677\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 16.9404 - categorical_accuracy: 0.3728 - val_loss: 5.0984 - val_categorical_accuracy: 0.5781\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 17.5311 - categorical_accuracy: 0.4219 - val_loss: 4.2099 - val_categorical_accuracy: 0.6510\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 14.1374 - categorical_accuracy: 0.4196 - val_loss: 3.4367 - val_categorical_accuracy: 0.7083\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 12.6340 - categorical_accuracy: 0.4487 - val_loss: 2.9020 - val_categorical_accuracy: 0.7500\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 12.0706 - categorical_accuracy: 0.4621 - val_loss: 2.5408 - val_categorical_accuracy: 0.7812\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 9.8683 - categorical_accuracy: 0.5045 - val_loss: 2.2972 - val_categorical_accuracy: 0.8125\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 9.6519 - categorical_accuracy: 0.4777 - val_loss: 2.1336 - val_categorical_accuracy: 0.8125\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 9.7647 - categorical_accuracy: 0.4821 - val_loss: 1.9527 - val_categorical_accuracy: 0.8281\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 8.6106 - categorical_accuracy: 0.5089 - val_loss: 1.7786 - val_categorical_accuracy: 0.8385\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 8.5009 - categorical_accuracy: 0.5268 - val_loss: 1.6589 - val_categorical_accuracy: 0.8646\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 6.0620 - categorical_accuracy: 0.5446 - val_loss: 1.5613 - val_categorical_accuracy: 0.8594\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 6.7119 - categorical_accuracy: 0.5670 - val_loss: 1.4625 - val_categorical_accuracy: 0.8594\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 5.8463 - categorical_accuracy: 0.6183 - val_loss: 1.3857 - val_categorical_accuracy: 0.8490\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 6.0230 - categorical_accuracy: 0.5982 - val_loss: 1.3234 - val_categorical_accuracy: 0.8438\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 5.1826 - categorical_accuracy: 0.6071 - val_loss: 1.2496 - val_categorical_accuracy: 0.8385\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 5.3278 - categorical_accuracy: 0.6228 - val_loss: 1.1856 - val_categorical_accuracy: 0.8385\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 4.4943 - categorical_accuracy: 0.6451 - val_loss: 1.0828 - val_categorical_accuracy: 0.8385\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.9906 - categorical_accuracy: 0.6763 - val_loss: 0.9726 - val_categorical_accuracy: 0.8490\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.5512 - categorical_accuracy: 0.6786 - val_loss: 0.9030 - val_categorical_accuracy: 0.8542\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.2029 - categorical_accuracy: 0.6496 - val_loss: 0.8723 - val_categorical_accuracy: 0.8646\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.7894 - categorical_accuracy: 0.6540 - val_loss: 0.8641 - val_categorical_accuracy: 0.8750\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8142 - categorical_accuracy: 0.6496 - val_loss: 0.8404 - val_categorical_accuracy: 0.8698\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.5228 - categorical_accuracy: 0.6607 - val_loss: 0.8319 - val_categorical_accuracy: 0.8698\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.1003 - categorical_accuracy: 0.6942 - val_loss: 0.8247 - val_categorical_accuracy: 0.8750\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2.9665 - categorical_accuracy: 0.7054 - val_loss: 0.8304 - val_categorical_accuracy: 0.8698\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2.7281 - categorical_accuracy: 0.7254 - val_loss: 0.8387 - val_categorical_accuracy: 0.8698\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 2.3148 - categorical_accuracy: 0.7121 - val_loss: 0.8135 - val_categorical_accuracy: 0.8750\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.7258 - categorical_accuracy: 0.7031 - val_loss: 0.7591 - val_categorical_accuracy: 0.8802\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 2.7286 - categorical_accuracy: 0.6786 - val_loss: 0.6993 - val_categorical_accuracy: 0.8854\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 2.8651 - categorical_accuracy: 0.7054 - val_loss: 0.6429 - val_categorical_accuracy: 0.8802\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.3854 - categorical_accuracy: 0.7076 - val_loss: 0.6040 - val_categorical_accuracy: 0.8958\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 2.6428 - categorical_accuracy: 0.7210 - val_loss: 0.5964 - val_categorical_accuracy: 0.8854\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.2317 - categorical_accuracy: 0.7455 - val_loss: 0.6054 - val_categorical_accuracy: 0.8802\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2.2958 - categorical_accuracy: 0.7098 - val_loss: 0.6396 - val_categorical_accuracy: 0.8802\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 1.9595 - categorical_accuracy: 0.7277 - val_loss: 0.6694 - val_categorical_accuracy: 0.8854\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.6879 - categorical_accuracy: 0.7545 - val_loss: 0.6738 - val_categorical_accuracy: 0.8802\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 2.2203 - categorical_accuracy: 0.7277 - val_loss: 0.6728 - val_categorical_accuracy: 0.8854\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.0548 - categorical_accuracy: 0.7210 - val_loss: 0.6540 - val_categorical_accuracy: 0.8854\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.6640 - categorical_accuracy: 0.7388 - val_loss: 0.6366 - val_categorical_accuracy: 0.8906\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.6003 - categorical_accuracy: 0.7634 - val_loss: 0.6144 - val_categorical_accuracy: 0.8906\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2.0449 - categorical_accuracy: 0.7232 - val_loss: 0.6086 - val_categorical_accuracy: 0.8854\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.4206 - categorical_accuracy: 0.7879 - val_loss: 0.6051 - val_categorical_accuracy: 0.8854\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.6676 - categorical_accuracy: 0.7254 - val_loss: 0.5935 - val_categorical_accuracy: 0.8906\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.4863 - categorical_accuracy: 0.7545 - val_loss: 0.5696 - val_categorical_accuracy: 0.8958\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.6127 - categorical_accuracy: 0.7612 - val_loss: 0.5393 - val_categorical_accuracy: 0.8958\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.4888 - categorical_accuracy: 0.7366 - val_loss: 0.5017 - val_categorical_accuracy: 0.8958\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.6611 - categorical_accuracy: 0.7567 - val_loss: 0.4720 - val_categorical_accuracy: 0.9010\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.6178 - categorical_accuracy: 0.7500 - val_loss: 0.4648 - val_categorical_accuracy: 0.9062\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.3353 - categorical_accuracy: 0.7701 - val_loss: 0.4818 - val_categorical_accuracy: 0.9062\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.3642 - categorical_accuracy: 0.7567 - val_loss: 0.4896 - val_categorical_accuracy: 0.9010\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3022 - categorical_accuracy: 0.7411 - val_loss: 0.4862 - val_categorical_accuracy: 0.8958\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.4201 - categorical_accuracy: 0.7344 - val_loss: 0.4795 - val_categorical_accuracy: 0.8906\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.2948 - categorical_accuracy: 0.7656 - val_loss: 0.4675 - val_categorical_accuracy: 0.8958\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.3598 - categorical_accuracy: 0.7723 - val_loss: 0.4580 - val_categorical_accuracy: 0.8958\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.1320 - categorical_accuracy: 0.8147 - val_loss: 0.4653 - val_categorical_accuracy: 0.8958\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.0699 - categorical_accuracy: 0.8036 - val_loss: 0.4687 - val_categorical_accuracy: 0.9010\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.0280 - categorical_accuracy: 0.8058 - val_loss: 0.4629 - val_categorical_accuracy: 0.9062\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8846 - categorical_accuracy: 0.7924 - val_loss: 0.4438 - val_categorical_accuracy: 0.9115\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.9499 - categorical_accuracy: 0.8170 - val_loss: 0.4134 - val_categorical_accuracy: 0.9115\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.1020 - categorical_accuracy: 0.7701 - val_loss: 0.3730 - val_categorical_accuracy: 0.9167\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.9343 - categorical_accuracy: 0.8103 - val_loss: 0.3543 - val_categorical_accuracy: 0.9167\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7918 - categorical_accuracy: 0.8103 - val_loss: 0.3357 - val_categorical_accuracy: 0.9219\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.0649 - categorical_accuracy: 0.7857 - val_loss: 0.3160 - val_categorical_accuracy: 0.9271\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.0482 - categorical_accuracy: 0.7746 - val_loss: 0.3130 - val_categorical_accuracy: 0.9323\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9479 - categorical_accuracy: 0.8036 - val_loss: 0.3400 - val_categorical_accuracy: 0.9271\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9070 - categorical_accuracy: 0.8125 - val_loss: 0.3738 - val_categorical_accuracy: 0.9167\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.9156 - categorical_accuracy: 0.8013 - val_loss: 0.3985 - val_categorical_accuracy: 0.9115\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8873 - categorical_accuracy: 0.7924 - val_loss: 0.3954 - val_categorical_accuracy: 0.9115\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7536 - categorical_accuracy: 0.8326 - val_loss: 0.3678 - val_categorical_accuracy: 0.9115\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.8446 - categorical_accuracy: 0.7991 - val_loss: 0.3479 - val_categorical_accuracy: 0.9062\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.9041 - categorical_accuracy: 0.7924 - val_loss: 0.3397 - val_categorical_accuracy: 0.9115\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.9923 - categorical_accuracy: 0.7656 - val_loss: 0.3416 - val_categorical_accuracy: 0.9115\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5969 - categorical_accuracy: 0.8415 - val_loss: 0.3447 - val_categorical_accuracy: 0.9167\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.6945 - categorical_accuracy: 0.8103 - val_loss: 0.3474 - val_categorical_accuracy: 0.9115\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.7353 - categorical_accuracy: 0.8147 - val_loss: 0.3690 - val_categorical_accuracy: 0.9167\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6675 - categorical_accuracy: 0.8326 - val_loss: 0.4072 - val_categorical_accuracy: 0.9219\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7481 - categorical_accuracy: 0.8192 - val_loss: 0.4475 - val_categorical_accuracy: 0.9271\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7957 - categorical_accuracy: 0.7991 - val_loss: 0.4464 - val_categorical_accuracy: 0.9271\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7618 - categorical_accuracy: 0.7969 - val_loss: 0.4192 - val_categorical_accuracy: 0.9323\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6380 - categorical_accuracy: 0.8393 - val_loss: 0.3898 - val_categorical_accuracy: 0.9323\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6139 - categorical_accuracy: 0.8348 - val_loss: 0.3650 - val_categorical_accuracy: 0.9323\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.7133 - categorical_accuracy: 0.8214 - val_loss: 0.3436 - val_categorical_accuracy: 0.9271\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.7074 - categorical_accuracy: 0.8393 - val_loss: 0.3290 - val_categorical_accuracy: 0.9323\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6818 - categorical_accuracy: 0.8326 - val_loss: 0.3253 - val_categorical_accuracy: 0.9271\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5314 - categorical_accuracy: 0.8415 - val_loss: 0.3307 - val_categorical_accuracy: 0.9167\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5600 - categorical_accuracy: 0.8594 - val_loss: 0.3354 - val_categorical_accuracy: 0.9219\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7355 - categorical_accuracy: 0.8214 - val_loss: 0.3417 - val_categorical_accuracy: 0.9167\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.7128 - categorical_accuracy: 0.7946 - val_loss: 0.3513 - val_categorical_accuracy: 0.9115\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6551 - categorical_accuracy: 0.8214 - val_loss: 0.3581 - val_categorical_accuracy: 0.9167\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.4424 - categorical_accuracy: 0.8661 - val_loss: 0.3505 - val_categorical_accuracy: 0.9219\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5542 - categorical_accuracy: 0.8438 - val_loss: 0.3360 - val_categorical_accuracy: 0.9219\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.6554 - categorical_accuracy: 0.8281 - val_loss: 0.3224 - val_categorical_accuracy: 0.9219\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5506 - categorical_accuracy: 0.8549 - val_loss: 0.3111 - val_categorical_accuracy: 0.9219\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4942 - categorical_accuracy: 0.8527 - val_loss: 0.2986 - val_categorical_accuracy: 0.9219\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5943 - categorical_accuracy: 0.8326 - val_loss: 0.2935 - val_categorical_accuracy: 0.9271\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4812 - categorical_accuracy: 0.8549 - val_loss: 0.2932 - val_categorical_accuracy: 0.9427\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5325 - categorical_accuracy: 0.8438 - val_loss: 0.3047 - val_categorical_accuracy: 0.9427\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4374 - categorical_accuracy: 0.8638 - val_loss: 0.3163 - val_categorical_accuracy: 0.9375\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4775 - categorical_accuracy: 0.8616 - val_loss: 0.3208 - val_categorical_accuracy: 0.9375\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5499 - categorical_accuracy: 0.8326 - val_loss: 0.3069 - val_categorical_accuracy: 0.9323\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5157 - categorical_accuracy: 0.8371 - val_loss: 0.2731 - val_categorical_accuracy: 0.9375\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5358 - categorical_accuracy: 0.8549 - val_loss: 0.2490 - val_categorical_accuracy: 0.9479\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5355 - categorical_accuracy: 0.8638 - val_loss: 0.2426 - val_categorical_accuracy: 0.9531\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4807 - categorical_accuracy: 0.8795 - val_loss: 0.2404 - val_categorical_accuracy: 0.9531\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4631 - categorical_accuracy: 0.8460 - val_loss: 0.2347 - val_categorical_accuracy: 0.9531\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5115 - categorical_accuracy: 0.8438 - val_loss: 0.2280 - val_categorical_accuracy: 0.9531\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4923 - categorical_accuracy: 0.8549 - val_loss: 0.2312 - val_categorical_accuracy: 0.9427\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3803 - categorical_accuracy: 0.8683 - val_loss: 0.2364 - val_categorical_accuracy: 0.9531\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.5695 - categorical_accuracy: 0.8482 - val_loss: 0.2407 - val_categorical_accuracy: 0.9479\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.4228 - categorical_accuracy: 0.8795 - val_loss: 0.2500 - val_categorical_accuracy: 0.9479\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5194 - categorical_accuracy: 0.8661 - val_loss: 0.2569 - val_categorical_accuracy: 0.9271\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.5190 - categorical_accuracy: 0.8460 - val_loss: 0.2662 - val_categorical_accuracy: 0.9219\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4982 - categorical_accuracy: 0.8348 - val_loss: 0.2720 - val_categorical_accuracy: 0.9271\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4245 - categorical_accuracy: 0.8571 - val_loss: 0.2744 - val_categorical_accuracy: 0.9323\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3942 - categorical_accuracy: 0.8549 - val_loss: 0.2762 - val_categorical_accuracy: 0.9271\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3895 - categorical_accuracy: 0.8750 - val_loss: 0.2724 - val_categorical_accuracy: 0.9375\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4799 - categorical_accuracy: 0.8683 - val_loss: 0.2742 - val_categorical_accuracy: 0.9219\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4356 - categorical_accuracy: 0.8594 - val_loss: 0.2719 - val_categorical_accuracy: 0.9271\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3877 - categorical_accuracy: 0.8795 - val_loss: 0.2545 - val_categorical_accuracy: 0.9427\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4589 - categorical_accuracy: 0.8549 - val_loss: 0.2301 - val_categorical_accuracy: 0.9583\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3890 - categorical_accuracy: 0.8817 - val_loss: 0.2136 - val_categorical_accuracy: 0.9635\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3944 - categorical_accuracy: 0.8839 - val_loss: 0.2118 - val_categorical_accuracy: 0.9635\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3924 - categorical_accuracy: 0.8705 - val_loss: 0.2132 - val_categorical_accuracy: 0.9635\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3882 - categorical_accuracy: 0.8571 - val_loss: 0.2175 - val_categorical_accuracy: 0.9635\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3391 - categorical_accuracy: 0.8929 - val_loss: 0.2245 - val_categorical_accuracy: 0.9531\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4008 - categorical_accuracy: 0.8661 - val_loss: 0.2321 - val_categorical_accuracy: 0.9531\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3712 - categorical_accuracy: 0.8817 - val_loss: 0.2433 - val_categorical_accuracy: 0.9531\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3871 - categorical_accuracy: 0.8951 - val_loss: 0.2465 - val_categorical_accuracy: 0.9531\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3590 - categorical_accuracy: 0.8906 - val_loss: 0.2463 - val_categorical_accuracy: 0.9479\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4272 - categorical_accuracy: 0.8527 - val_loss: 0.2485 - val_categorical_accuracy: 0.9479\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3146 - categorical_accuracy: 0.9018 - val_loss: 0.2455 - val_categorical_accuracy: 0.9427\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3392 - categorical_accuracy: 0.9040 - val_loss: 0.2509 - val_categorical_accuracy: 0.9427\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4394 - categorical_accuracy: 0.8728 - val_loss: 0.2540 - val_categorical_accuracy: 0.9427\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3683 - categorical_accuracy: 0.8772 - val_loss: 0.2490 - val_categorical_accuracy: 0.9427\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3405 - categorical_accuracy: 0.8661 - val_loss: 0.2394 - val_categorical_accuracy: 0.9479\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3913 - categorical_accuracy: 0.8750 - val_loss: 0.2283 - val_categorical_accuracy: 0.9531\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3787 - categorical_accuracy: 0.8772 - val_loss: 0.2263 - val_categorical_accuracy: 0.9531\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3241 - categorical_accuracy: 0.8817 - val_loss: 0.2279 - val_categorical_accuracy: 0.9583\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2652 - categorical_accuracy: 0.9107 - val_loss: 0.2385 - val_categorical_accuracy: 0.9479\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3551 - categorical_accuracy: 0.8772 - val_loss: 0.2554 - val_categorical_accuracy: 0.9479\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.3160 - categorical_accuracy: 0.8884 - val_loss: 0.2625 - val_categorical_accuracy: 0.9427\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3330 - categorical_accuracy: 0.8772 - val_loss: 0.2585 - val_categorical_accuracy: 0.9375\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3466 - categorical_accuracy: 0.8728 - val_loss: 0.2485 - val_categorical_accuracy: 0.9531\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3434 - categorical_accuracy: 0.8884 - val_loss: 0.2434 - val_categorical_accuracy: 0.9583\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3060 - categorical_accuracy: 0.8839 - val_loss: 0.2414 - val_categorical_accuracy: 0.9583\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2633 - categorical_accuracy: 0.9062 - val_loss: 0.2344 - val_categorical_accuracy: 0.9583\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3727 - categorical_accuracy: 0.8817 - val_loss: 0.2271 - val_categorical_accuracy: 0.9635\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2724 - categorical_accuracy: 0.9174 - val_loss: 0.2268 - val_categorical_accuracy: 0.9635\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3460 - categorical_accuracy: 0.8728 - val_loss: 0.2354 - val_categorical_accuracy: 0.9531\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3217 - categorical_accuracy: 0.8750 - val_loss: 0.2440 - val_categorical_accuracy: 0.9479\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2935 - categorical_accuracy: 0.9018 - val_loss: 0.2410 - val_categorical_accuracy: 0.9531\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3245 - categorical_accuracy: 0.8795 - val_loss: 0.2339 - val_categorical_accuracy: 0.9531\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3099 - categorical_accuracy: 0.8929 - val_loss: 0.2261 - val_categorical_accuracy: 0.9583\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3262 - categorical_accuracy: 0.8973 - val_loss: 0.2208 - val_categorical_accuracy: 0.9635\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2905 - categorical_accuracy: 0.8996 - val_loss: 0.2218 - val_categorical_accuracy: 0.9635\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2360 - categorical_accuracy: 0.9129 - val_loss: 0.2272 - val_categorical_accuracy: 0.9583\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3044 - categorical_accuracy: 0.8906 - val_loss: 0.2296 - val_categorical_accuracy: 0.9531\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2718 - categorical_accuracy: 0.9085 - val_loss: 0.2326 - val_categorical_accuracy: 0.9531\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2495 - categorical_accuracy: 0.9129 - val_loss: 0.2314 - val_categorical_accuracy: 0.9531\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2425 - categorical_accuracy: 0.9308 - val_loss: 0.2338 - val_categorical_accuracy: 0.9479\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3264 - categorical_accuracy: 0.8906 - val_loss: 0.2316 - val_categorical_accuracy: 0.9479\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3028 - categorical_accuracy: 0.8884 - val_loss: 0.2296 - val_categorical_accuracy: 0.9479\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2823 - categorical_accuracy: 0.8996 - val_loss: 0.2306 - val_categorical_accuracy: 0.9531\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2806 - categorical_accuracy: 0.9062 - val_loss: 0.2254 - val_categorical_accuracy: 0.9531\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2665 - categorical_accuracy: 0.9062 - val_loss: 0.2205 - val_categorical_accuracy: 0.9583\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2059 - categorical_accuracy: 0.9263 - val_loss: 0.2199 - val_categorical_accuracy: 0.9583\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3144 - categorical_accuracy: 0.8839 - val_loss: 0.2205 - val_categorical_accuracy: 0.9583\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2742 - categorical_accuracy: 0.8996 - val_loss: 0.2295 - val_categorical_accuracy: 0.9531\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2875 - categorical_accuracy: 0.9085 - val_loss: 0.2391 - val_categorical_accuracy: 0.9479\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3042 - categorical_accuracy: 0.8996 - val_loss: 0.2476 - val_categorical_accuracy: 0.9375\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2980 - categorical_accuracy: 0.9196 - val_loss: 0.2433 - val_categorical_accuracy: 0.9427\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.3119 - categorical_accuracy: 0.8951 - val_loss: 0.2327 - val_categorical_accuracy: 0.9479\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2806 - categorical_accuracy: 0.9196 - val_loss: 0.2246 - val_categorical_accuracy: 0.9479\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2744 - categorical_accuracy: 0.8996 - val_loss: 0.2183 - val_categorical_accuracy: 0.9583\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2197 - categorical_accuracy: 0.9241 - val_loss: 0.2133 - val_categorical_accuracy: 0.9583\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2260 - categorical_accuracy: 0.9196 - val_loss: 0.2144 - val_categorical_accuracy: 0.9583\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2679 - categorical_accuracy: 0.9107 - val_loss: 0.2134 - val_categorical_accuracy: 0.9583\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2816 - categorical_accuracy: 0.9129 - val_loss: 0.2123 - val_categorical_accuracy: 0.9583\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2562 - categorical_accuracy: 0.9129 - val_loss: 0.2103 - val_categorical_accuracy: 0.9583\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2326 - categorical_accuracy: 0.9219 - val_loss: 0.2119 - val_categorical_accuracy: 0.9583\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2635 - categorical_accuracy: 0.9085 - val_loss: 0.2100 - val_categorical_accuracy: 0.9583\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2157 - categorical_accuracy: 0.9219 - val_loss: 0.2070 - val_categorical_accuracy: 0.9583\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2794 - categorical_accuracy: 0.9174 - val_loss: 0.2044 - val_categorical_accuracy: 0.9583\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2453 - categorical_accuracy: 0.9040 - val_loss: 0.2026 - val_categorical_accuracy: 0.9583\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.2560 - categorical_accuracy: 0.9040 - val_loss: 0.2023 - val_categorical_accuracy: 0.9583\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2916 - categorical_accuracy: 0.8929 - val_loss: 0.2089 - val_categorical_accuracy: 0.9583\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2950 - categorical_accuracy: 0.8906 - val_loss: 0.2220 - val_categorical_accuracy: 0.9583\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2162 - categorical_accuracy: 0.9174 - val_loss: 0.2392 - val_categorical_accuracy: 0.9479\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3130 - categorical_accuracy: 0.9107 - val_loss: 0.2523 - val_categorical_accuracy: 0.9427\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3023 - categorical_accuracy: 0.8884 - val_loss: 0.2555 - val_categorical_accuracy: 0.9427\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2461 - categorical_accuracy: 0.9219 - val_loss: 0.2480 - val_categorical_accuracy: 0.9531\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2277 - categorical_accuracy: 0.9196 - val_loss: 0.2328 - val_categorical_accuracy: 0.9531\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2107 - categorical_accuracy: 0.9353 - val_loss: 0.2190 - val_categorical_accuracy: 0.9635\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2129 - categorical_accuracy: 0.9286 - val_loss: 0.2118 - val_categorical_accuracy: 0.9635\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2492 - categorical_accuracy: 0.9263 - val_loss: 0.2081 - val_categorical_accuracy: 0.9635\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2513 - categorical_accuracy: 0.9152 - val_loss: 0.2084 - val_categorical_accuracy: 0.9635\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2838 - categorical_accuracy: 0.9018 - val_loss: 0.2080 - val_categorical_accuracy: 0.9635\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2296 - categorical_accuracy: 0.9196 - val_loss: 0.2088 - val_categorical_accuracy: 0.9635\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2396 - categorical_accuracy: 0.9107 - val_loss: 0.2097 - val_categorical_accuracy: 0.9635\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2434 - categorical_accuracy: 0.9174 - val_loss: 0.2150 - val_categorical_accuracy: 0.9635\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.2444 - categorical_accuracy: 0.9129 - val_loss: 0.2218 - val_categorical_accuracy: 0.9635\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2005 - categorical_accuracy: 0.9241 - val_loss: 0.2284 - val_categorical_accuracy: 0.9531\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2358 - categorical_accuracy: 0.9241 - val_loss: 0.2319 - val_categorical_accuracy: 0.9531\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2204 - categorical_accuracy: 0.9129 - val_loss: 0.2300 - val_categorical_accuracy: 0.9583\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2361 - categorical_accuracy: 0.9152 - val_loss: 0.2307 - val_categorical_accuracy: 0.9635\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2147 - categorical_accuracy: 0.9375 - val_loss: 0.2273 - val_categorical_accuracy: 0.9531\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2458 - categorical_accuracy: 0.9129 - val_loss: 0.2268 - val_categorical_accuracy: 0.9531\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2352 - categorical_accuracy: 0.9129 - val_loss: 0.2290 - val_categorical_accuracy: 0.9531\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1957 - categorical_accuracy: 0.9397 - val_loss: 0.2288 - val_categorical_accuracy: 0.9531\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2107 - categorical_accuracy: 0.9152 - val_loss: 0.2257 - val_categorical_accuracy: 0.9531\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2022 - categorical_accuracy: 0.9241 - val_loss: 0.2165 - val_categorical_accuracy: 0.9635\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1735 - categorical_accuracy: 0.9397 - val_loss: 0.2074 - val_categorical_accuracy: 0.9635\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1982 - categorical_accuracy: 0.9330 - val_loss: 0.2015 - val_categorical_accuracy: 0.9635\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2027 - categorical_accuracy: 0.9330 - val_loss: 0.1964 - val_categorical_accuracy: 0.9635\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.2199 - categorical_accuracy: 0.9085 - val_loss: 0.1973 - val_categorical_accuracy: 0.9583\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2322 - categorical_accuracy: 0.9286 - val_loss: 0.2026 - val_categorical_accuracy: 0.9635\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2074 - categorical_accuracy: 0.9263 - val_loss: 0.2091 - val_categorical_accuracy: 0.9635\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2049 - categorical_accuracy: 0.9241 - val_loss: 0.2187 - val_categorical_accuracy: 0.9635\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2254 - categorical_accuracy: 0.9107 - val_loss: 0.2206 - val_categorical_accuracy: 0.9635\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2358 - categorical_accuracy: 0.9219 - val_loss: 0.2148 - val_categorical_accuracy: 0.9635\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2220 - categorical_accuracy: 0.9308 - val_loss: 0.2113 - val_categorical_accuracy: 0.9635\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2006 - categorical_accuracy: 0.9196 - val_loss: 0.2069 - val_categorical_accuracy: 0.9635\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2259 - categorical_accuracy: 0.9174 - val_loss: 0.2022 - val_categorical_accuracy: 0.9583\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2776 - categorical_accuracy: 0.8951 - val_loss: 0.1998 - val_categorical_accuracy: 0.9583\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2044 - categorical_accuracy: 0.9375 - val_loss: 0.2037 - val_categorical_accuracy: 0.9583\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2435 - categorical_accuracy: 0.9174 - val_loss: 0.2102 - val_categorical_accuracy: 0.9583\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2058 - categorical_accuracy: 0.9152 - val_loss: 0.2144 - val_categorical_accuracy: 0.9583\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1937 - categorical_accuracy: 0.9397 - val_loss: 0.2129 - val_categorical_accuracy: 0.9583\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1978 - categorical_accuracy: 0.9196 - val_loss: 0.2067 - val_categorical_accuracy: 0.9583\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2233 - categorical_accuracy: 0.9129 - val_loss: 0.2005 - val_categorical_accuracy: 0.9635\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1703 - categorical_accuracy: 0.9487 - val_loss: 0.1986 - val_categorical_accuracy: 0.9635\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1529 - categorical_accuracy: 0.9442 - val_loss: 0.2010 - val_categorical_accuracy: 0.9635\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2149 - categorical_accuracy: 0.9397 - val_loss: 0.2050 - val_categorical_accuracy: 0.9635\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2019 - categorical_accuracy: 0.9286 - val_loss: 0.2074 - val_categorical_accuracy: 0.9635\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2136 - categorical_accuracy: 0.9129 - val_loss: 0.2108 - val_categorical_accuracy: 0.9635\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1501 - categorical_accuracy: 0.9397 - val_loss: 0.2151 - val_categorical_accuracy: 0.9635\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2165 - categorical_accuracy: 0.9263 - val_loss: 0.2174 - val_categorical_accuracy: 0.9635\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1813 - categorical_accuracy: 0.9353 - val_loss: 0.2204 - val_categorical_accuracy: 0.9635\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2199 - categorical_accuracy: 0.9219 - val_loss: 0.2221 - val_categorical_accuracy: 0.9635\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1447 - categorical_accuracy: 0.9487 - val_loss: 0.2238 - val_categorical_accuracy: 0.9635\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1860 - categorical_accuracy: 0.9219 - val_loss: 0.2263 - val_categorical_accuracy: 0.9635\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2026 - categorical_accuracy: 0.9286 - val_loss: 0.2289 - val_categorical_accuracy: 0.9583\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2213 - categorical_accuracy: 0.9241 - val_loss: 0.2317 - val_categorical_accuracy: 0.9531\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2122 - categorical_accuracy: 0.9152 - val_loss: 0.2312 - val_categorical_accuracy: 0.9531\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1688 - categorical_accuracy: 0.9397 - val_loss: 0.2283 - val_categorical_accuracy: 0.9531\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1536 - categorical_accuracy: 0.9420 - val_loss: 0.2240 - val_categorical_accuracy: 0.9583\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2352 - categorical_accuracy: 0.9219 - val_loss: 0.2198 - val_categorical_accuracy: 0.9583\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1830 - categorical_accuracy: 0.9353 - val_loss: 0.2167 - val_categorical_accuracy: 0.9583\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1837 - categorical_accuracy: 0.9442 - val_loss: 0.2158 - val_categorical_accuracy: 0.9583\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1943 - categorical_accuracy: 0.9286 - val_loss: 0.2160 - val_categorical_accuracy: 0.9583\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2031 - categorical_accuracy: 0.9330 - val_loss: 0.2175 - val_categorical_accuracy: 0.9583\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1959 - categorical_accuracy: 0.9330 - val_loss: 0.2162 - val_categorical_accuracy: 0.9635\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1562 - categorical_accuracy: 0.9353 - val_loss: 0.2105 - val_categorical_accuracy: 0.9635\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1764 - categorical_accuracy: 0.9330 - val_loss: 0.2050 - val_categorical_accuracy: 0.9635\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1811 - categorical_accuracy: 0.9397 - val_loss: 0.2034 - val_categorical_accuracy: 0.9635\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1720 - categorical_accuracy: 0.9397 - val_loss: 0.2063 - val_categorical_accuracy: 0.9635\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1550 - categorical_accuracy: 0.9308 - val_loss: 0.2083 - val_categorical_accuracy: 0.9635\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1727 - categorical_accuracy: 0.9353 - val_loss: 0.2114 - val_categorical_accuracy: 0.9635\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1858 - categorical_accuracy: 0.9174 - val_loss: 0.2162 - val_categorical_accuracy: 0.9635\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2183 - categorical_accuracy: 0.9241 - val_loss: 0.2221 - val_categorical_accuracy: 0.9635\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2092 - categorical_accuracy: 0.9263 - val_loss: 0.2232 - val_categorical_accuracy: 0.9635\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1735 - categorical_accuracy: 0.9241 - val_loss: 0.2244 - val_categorical_accuracy: 0.9635\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1674 - categorical_accuracy: 0.9397 - val_loss: 0.2231 - val_categorical_accuracy: 0.9635\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1653 - categorical_accuracy: 0.9397 - val_loss: 0.2183 - val_categorical_accuracy: 0.9635\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1779 - categorical_accuracy: 0.9353 - val_loss: 0.2081 - val_categorical_accuracy: 0.9635\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1880 - categorical_accuracy: 0.9308 - val_loss: 0.2035 - val_categorical_accuracy: 0.9635\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2269 - categorical_accuracy: 0.9174 - val_loss: 0.2019 - val_categorical_accuracy: 0.9635\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1735 - categorical_accuracy: 0.9330 - val_loss: 0.2024 - val_categorical_accuracy: 0.9635\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1593 - categorical_accuracy: 0.9531 - val_loss: 0.2013 - val_categorical_accuracy: 0.9635\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1932 - categorical_accuracy: 0.9308 - val_loss: 0.2022 - val_categorical_accuracy: 0.9635\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1632 - categorical_accuracy: 0.9420 - val_loss: 0.2035 - val_categorical_accuracy: 0.9635\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1638 - categorical_accuracy: 0.9397 - val_loss: 0.2022 - val_categorical_accuracy: 0.9635\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1798 - categorical_accuracy: 0.9442 - val_loss: 0.2015 - val_categorical_accuracy: 0.9635\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1731 - categorical_accuracy: 0.9263 - val_loss: 0.2001 - val_categorical_accuracy: 0.9635\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1795 - categorical_accuracy: 0.9353 - val_loss: 0.1943 - val_categorical_accuracy: 0.9635\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1616 - categorical_accuracy: 0.9397 - val_loss: 0.1910 - val_categorical_accuracy: 0.9635\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1640 - categorical_accuracy: 0.9464 - val_loss: 0.1915 - val_categorical_accuracy: 0.9635\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1941 - categorical_accuracy: 0.9330 - val_loss: 0.1963 - val_categorical_accuracy: 0.9583\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1934 - categorical_accuracy: 0.9263 - val_loss: 0.2013 - val_categorical_accuracy: 0.9583\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1728 - categorical_accuracy: 0.9442 - val_loss: 0.2031 - val_categorical_accuracy: 0.9583\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1971 - categorical_accuracy: 0.9308 - val_loss: 0.2033 - val_categorical_accuracy: 0.9583\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1641 - categorical_accuracy: 0.9509 - val_loss: 0.2031 - val_categorical_accuracy: 0.9583\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1615 - categorical_accuracy: 0.9330 - val_loss: 0.2035 - val_categorical_accuracy: 0.9583\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1866 - categorical_accuracy: 0.9353 - val_loss: 0.2032 - val_categorical_accuracy: 0.9583\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1807 - categorical_accuracy: 0.9330 - val_loss: 0.2062 - val_categorical_accuracy: 0.9635\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1941 - categorical_accuracy: 0.9353 - val_loss: 0.2076 - val_categorical_accuracy: 0.9635\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1458 - categorical_accuracy: 0.9464 - val_loss: 0.2095 - val_categorical_accuracy: 0.9635\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2109 - categorical_accuracy: 0.9263 - val_loss: 0.2084 - val_categorical_accuracy: 0.9635\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1677 - categorical_accuracy: 0.9397 - val_loss: 0.2070 - val_categorical_accuracy: 0.9583\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1569 - categorical_accuracy: 0.9442 - val_loss: 0.2041 - val_categorical_accuracy: 0.9583\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2245 - categorical_accuracy: 0.9174 - val_loss: 0.1992 - val_categorical_accuracy: 0.9583\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1397 - categorical_accuracy: 0.9531 - val_loss: 0.1961 - val_categorical_accuracy: 0.9583\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1818 - categorical_accuracy: 0.9286 - val_loss: 0.1982 - val_categorical_accuracy: 0.9583\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1398 - categorical_accuracy: 0.9531 - val_loss: 0.1967 - val_categorical_accuracy: 0.9583\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1834 - categorical_accuracy: 0.9420 - val_loss: 0.1961 - val_categorical_accuracy: 0.9583\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1649 - categorical_accuracy: 0.9330 - val_loss: 0.1974 - val_categorical_accuracy: 0.9531\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1591 - categorical_accuracy: 0.9442 - val_loss: 0.1996 - val_categorical_accuracy: 0.9531\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1644 - categorical_accuracy: 0.9442 - val_loss: 0.1964 - val_categorical_accuracy: 0.9531\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1526 - categorical_accuracy: 0.9531 - val_loss: 0.1919 - val_categorical_accuracy: 0.9531\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2063 - categorical_accuracy: 0.9308 - val_loss: 0.1862 - val_categorical_accuracy: 0.9583\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1702 - categorical_accuracy: 0.9442 - val_loss: 0.1773 - val_categorical_accuracy: 0.9583\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1427 - categorical_accuracy: 0.9464 - val_loss: 0.1742 - val_categorical_accuracy: 0.9583\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1607 - categorical_accuracy: 0.9397 - val_loss: 0.1721 - val_categorical_accuracy: 0.9583\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2329 - categorical_accuracy: 0.9062 - val_loss: 0.1719 - val_categorical_accuracy: 0.9583\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1302 - categorical_accuracy: 0.9509 - val_loss: 0.1770 - val_categorical_accuracy: 0.9583\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1434 - categorical_accuracy: 0.9509 - val_loss: 0.1851 - val_categorical_accuracy: 0.9583\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.1144 - categorical_accuracy: 0.9576 - val_loss: 0.1937 - val_categorical_accuracy: 0.9635\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1644 - categorical_accuracy: 0.9420 - val_loss: 0.1991 - val_categorical_accuracy: 0.9635\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1573 - categorical_accuracy: 0.9375 - val_loss: 0.2018 - val_categorical_accuracy: 0.9635\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1870 - categorical_accuracy: 0.9308 - val_loss: 0.2005 - val_categorical_accuracy: 0.9635\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1517 - categorical_accuracy: 0.9531 - val_loss: 0.2002 - val_categorical_accuracy: 0.9635\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1402 - categorical_accuracy: 0.9531 - val_loss: 0.1989 - val_categorical_accuracy: 0.9635\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1514 - categorical_accuracy: 0.9420 - val_loss: 0.1972 - val_categorical_accuracy: 0.9635\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1334 - categorical_accuracy: 0.9598 - val_loss: 0.1971 - val_categorical_accuracy: 0.9635\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1699 - categorical_accuracy: 0.9397 - val_loss: 0.1971 - val_categorical_accuracy: 0.9635\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1263 - categorical_accuracy: 0.9554 - val_loss: 0.2038 - val_categorical_accuracy: 0.9635\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1186 - categorical_accuracy: 0.9621 - val_loss: 0.2112 - val_categorical_accuracy: 0.9583\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1256 - categorical_accuracy: 0.9487 - val_loss: 0.2155 - val_categorical_accuracy: 0.9531\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1585 - categorical_accuracy: 0.9397 - val_loss: 0.2165 - val_categorical_accuracy: 0.9531\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1584 - categorical_accuracy: 0.9353 - val_loss: 0.2080 - val_categorical_accuracy: 0.9583\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1533 - categorical_accuracy: 0.9576 - val_loss: 0.2015 - val_categorical_accuracy: 0.9635\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1313 - categorical_accuracy: 0.9442 - val_loss: 0.1993 - val_categorical_accuracy: 0.9635\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1878 - categorical_accuracy: 0.9308 - val_loss: 0.1953 - val_categorical_accuracy: 0.9583\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1297 - categorical_accuracy: 0.9554 - val_loss: 0.1895 - val_categorical_accuracy: 0.9583\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1473 - categorical_accuracy: 0.9509 - val_loss: 0.1864 - val_categorical_accuracy: 0.9583\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1376 - categorical_accuracy: 0.9531 - val_loss: 0.1836 - val_categorical_accuracy: 0.9583\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1412 - categorical_accuracy: 0.9420 - val_loss: 0.1895 - val_categorical_accuracy: 0.9583\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1710 - categorical_accuracy: 0.9375 - val_loss: 0.1926 - val_categorical_accuracy: 0.9635\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1369 - categorical_accuracy: 0.9576 - val_loss: 0.1955 - val_categorical_accuracy: 0.9635\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1499 - categorical_accuracy: 0.9442 - val_loss: 0.1965 - val_categorical_accuracy: 0.9635\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1184 - categorical_accuracy: 0.9598 - val_loss: 0.1972 - val_categorical_accuracy: 0.9635\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1451 - categorical_accuracy: 0.9531 - val_loss: 0.1960 - val_categorical_accuracy: 0.9635\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1396 - categorical_accuracy: 0.9509 - val_loss: 0.1947 - val_categorical_accuracy: 0.9635\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2133 - categorical_accuracy: 0.9308 - val_loss: 0.1930 - val_categorical_accuracy: 0.9635\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1612 - categorical_accuracy: 0.9420 - val_loss: 0.1891 - val_categorical_accuracy: 0.9635\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.0961 - categorical_accuracy: 0.9643 - val_loss: 0.1891 - val_categorical_accuracy: 0.9635\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1476 - categorical_accuracy: 0.9509 - val_loss: 0.1905 - val_categorical_accuracy: 0.9635\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1064 - categorical_accuracy: 0.9621 - val_loss: 0.1923 - val_categorical_accuracy: 0.9635\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1465 - categorical_accuracy: 0.9420 - val_loss: 0.1959 - val_categorical_accuracy: 0.9635\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1487 - categorical_accuracy: 0.9330 - val_loss: 0.1973 - val_categorical_accuracy: 0.9635\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1251 - categorical_accuracy: 0.9554 - val_loss: 0.1929 - val_categorical_accuracy: 0.9635\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1602 - categorical_accuracy: 0.9375 - val_loss: 0.1866 - val_categorical_accuracy: 0.9583\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1647 - categorical_accuracy: 0.9375 - val_loss: 0.1772 - val_categorical_accuracy: 0.9583\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1560 - categorical_accuracy: 0.9442 - val_loss: 0.1666 - val_categorical_accuracy: 0.9583\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1298 - categorical_accuracy: 0.9554 - val_loss: 0.1652 - val_categorical_accuracy: 0.9583\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1480 - categorical_accuracy: 0.9420 - val_loss: 0.1785 - val_categorical_accuracy: 0.9583\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1749 - categorical_accuracy: 0.9420 - val_loss: 0.1902 - val_categorical_accuracy: 0.9583\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1678 - categorical_accuracy: 0.9487 - val_loss: 0.2002 - val_categorical_accuracy: 0.9583\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1234 - categorical_accuracy: 0.9509 - val_loss: 0.2038 - val_categorical_accuracy: 0.9635\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1378 - categorical_accuracy: 0.9464 - val_loss: 0.1930 - val_categorical_accuracy: 0.9583\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1765 - categorical_accuracy: 0.9241 - val_loss: 0.1842 - val_categorical_accuracy: 0.9583\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1659 - categorical_accuracy: 0.9442 - val_loss: 0.1782 - val_categorical_accuracy: 0.9635\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1617 - categorical_accuracy: 0.9330 - val_loss: 0.1734 - val_categorical_accuracy: 0.9635\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1444 - categorical_accuracy: 0.9598 - val_loss: 0.1650 - val_categorical_accuracy: 0.9635\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1542 - categorical_accuracy: 0.9464 - val_loss: 0.1566 - val_categorical_accuracy: 0.9688\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1874 - categorical_accuracy: 0.9286 - val_loss: 0.1460 - val_categorical_accuracy: 0.9688\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1256 - categorical_accuracy: 0.9598 - val_loss: 0.1377 - val_categorical_accuracy: 0.9635\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1585 - categorical_accuracy: 0.9509 - val_loss: 0.1426 - val_categorical_accuracy: 0.9583\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1878 - categorical_accuracy: 0.9397 - val_loss: 0.1553 - val_categorical_accuracy: 0.9583\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1374 - categorical_accuracy: 0.9531 - val_loss: 0.1667 - val_categorical_accuracy: 0.9635\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1096 - categorical_accuracy: 0.9576 - val_loss: 0.1727 - val_categorical_accuracy: 0.9635\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1172 - categorical_accuracy: 0.9621 - val_loss: 0.1750 - val_categorical_accuracy: 0.9635\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1544 - categorical_accuracy: 0.9464 - val_loss: 0.1758 - val_categorical_accuracy: 0.9635\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1732 - categorical_accuracy: 0.9330 - val_loss: 0.1749 - val_categorical_accuracy: 0.9635\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1452 - categorical_accuracy: 0.9509 - val_loss: 0.1743 - val_categorical_accuracy: 0.9583\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.1603 - categorical_accuracy: 0.9464 - val_loss: 0.1762 - val_categorical_accuracy: 0.9583\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1037 - categorical_accuracy: 0.9576 - val_loss: 0.1783 - val_categorical_accuracy: 0.9635\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1409 - categorical_accuracy: 0.9420 - val_loss: 0.1771 - val_categorical_accuracy: 0.9635\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1400 - categorical_accuracy: 0.9464 - val_loss: 0.1779 - val_categorical_accuracy: 0.9635\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1526 - categorical_accuracy: 0.9487 - val_loss: 0.1819 - val_categorical_accuracy: 0.9635\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1118 - categorical_accuracy: 0.9710 - val_loss: 0.1817 - val_categorical_accuracy: 0.9635\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1156 - categorical_accuracy: 0.9643 - val_loss: 0.1762 - val_categorical_accuracy: 0.9635\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1535 - categorical_accuracy: 0.9442 - val_loss: 0.1725 - val_categorical_accuracy: 0.9635\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1543 - categorical_accuracy: 0.9554 - val_loss: 0.1706 - val_categorical_accuracy: 0.9635\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1653 - categorical_accuracy: 0.9442 - val_loss: 0.1747 - val_categorical_accuracy: 0.9635\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1662 - categorical_accuracy: 0.9397 - val_loss: 0.1866 - val_categorical_accuracy: 0.9635\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1305 - categorical_accuracy: 0.9554 - val_loss: 0.1916 - val_categorical_accuracy: 0.9583\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1459 - categorical_accuracy: 0.9397 - val_loss: 0.1937 - val_categorical_accuracy: 0.9583\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1290 - categorical_accuracy: 0.9487 - val_loss: 0.1923 - val_categorical_accuracy: 0.9583\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1267 - categorical_accuracy: 0.9509 - val_loss: 0.1876 - val_categorical_accuracy: 0.9583\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1302 - categorical_accuracy: 0.9598 - val_loss: 0.1834 - val_categorical_accuracy: 0.9688\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1137 - categorical_accuracy: 0.9554 - val_loss: 0.1768 - val_categorical_accuracy: 0.9688\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1534 - categorical_accuracy: 0.9397 - val_loss: 0.1676 - val_categorical_accuracy: 0.9635\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1041 - categorical_accuracy: 0.9621 - val_loss: 0.1577 - val_categorical_accuracy: 0.9635\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1270 - categorical_accuracy: 0.9554 - val_loss: 0.1536 - val_categorical_accuracy: 0.9688\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1791 - categorical_accuracy: 0.9330 - val_loss: 0.1533 - val_categorical_accuracy: 0.9688\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1483 - categorical_accuracy: 0.9353 - val_loss: 0.1547 - val_categorical_accuracy: 0.9635\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1344 - categorical_accuracy: 0.9554 - val_loss: 0.1586 - val_categorical_accuracy: 0.9635\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1559 - categorical_accuracy: 0.9464 - val_loss: 0.1722 - val_categorical_accuracy: 0.9688\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1183 - categorical_accuracy: 0.9531 - val_loss: 0.1817 - val_categorical_accuracy: 0.9688\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0933 - categorical_accuracy: 0.9598 - val_loss: 0.1880 - val_categorical_accuracy: 0.9688\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1621 - categorical_accuracy: 0.9420 - val_loss: 0.1868 - val_categorical_accuracy: 0.9635\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1413 - categorical_accuracy: 0.9576 - val_loss: 0.1816 - val_categorical_accuracy: 0.9635\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1118 - categorical_accuracy: 0.9643 - val_loss: 0.1761 - val_categorical_accuracy: 0.9583\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0891 - categorical_accuracy: 0.9754 - val_loss: 0.1696 - val_categorical_accuracy: 0.9583\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1373 - categorical_accuracy: 0.9576 - val_loss: 0.1635 - val_categorical_accuracy: 0.9583\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1159 - categorical_accuracy: 0.9576 - val_loss: 0.1606 - val_categorical_accuracy: 0.9583\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0925 - categorical_accuracy: 0.9688 - val_loss: 0.1623 - val_categorical_accuracy: 0.9583\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0816 - categorical_accuracy: 0.9777 - val_loss: 0.1611 - val_categorical_accuracy: 0.9583\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1094 - categorical_accuracy: 0.9554 - val_loss: 0.1605 - val_categorical_accuracy: 0.9583\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1335 - categorical_accuracy: 0.9554 - val_loss: 0.1590 - val_categorical_accuracy: 0.9583\n",
      "Epoch 418/500\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.1149 - categorical_accuracy: 0.9621 - val_loss: 0.1520 - val_categorical_accuracy: 0.9583\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1211 - categorical_accuracy: 0.9531 - val_loss: 0.1474 - val_categorical_accuracy: 0.9583\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1208 - categorical_accuracy: 0.9554 - val_loss: 0.1497 - val_categorical_accuracy: 0.9583\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1395 - categorical_accuracy: 0.9397 - val_loss: 0.1560 - val_categorical_accuracy: 0.9635\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1207 - categorical_accuracy: 0.9554 - val_loss: 0.1674 - val_categorical_accuracy: 0.9635\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1427 - categorical_accuracy: 0.9487 - val_loss: 0.1692 - val_categorical_accuracy: 0.9635\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1554 - categorical_accuracy: 0.9397 - val_loss: 0.1649 - val_categorical_accuracy: 0.9635\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1172 - categorical_accuracy: 0.9598 - val_loss: 0.1570 - val_categorical_accuracy: 0.9635\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1078 - categorical_accuracy: 0.9665 - val_loss: 0.1514 - val_categorical_accuracy: 0.9583\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0873 - categorical_accuracy: 0.9688 - val_loss: 0.1497 - val_categorical_accuracy: 0.9583\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1560 - categorical_accuracy: 0.9464 - val_loss: 0.1530 - val_categorical_accuracy: 0.9583\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1215 - categorical_accuracy: 0.9665 - val_loss: 0.1602 - val_categorical_accuracy: 0.9583\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1052 - categorical_accuracy: 0.9598 - val_loss: 0.1710 - val_categorical_accuracy: 0.9583\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1085 - categorical_accuracy: 0.9643 - val_loss: 0.1861 - val_categorical_accuracy: 0.9531\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0838 - categorical_accuracy: 0.9754 - val_loss: 0.1945 - val_categorical_accuracy: 0.9583\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1327 - categorical_accuracy: 0.9464 - val_loss: 0.1959 - val_categorical_accuracy: 0.9583\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1102 - categorical_accuracy: 0.9576 - val_loss: 0.1944 - val_categorical_accuracy: 0.9583\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1271 - categorical_accuracy: 0.9442 - val_loss: 0.1818 - val_categorical_accuracy: 0.9635\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0787 - categorical_accuracy: 0.9688 - val_loss: 0.1611 - val_categorical_accuracy: 0.9583\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1148 - categorical_accuracy: 0.9576 - val_loss: 0.1541 - val_categorical_accuracy: 0.9635\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1030 - categorical_accuracy: 0.9554 - val_loss: 0.1535 - val_categorical_accuracy: 0.9635\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0936 - categorical_accuracy: 0.9710 - val_loss: 0.1550 - val_categorical_accuracy: 0.9635\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0862 - categorical_accuracy: 0.9643 - val_loss: 0.1567 - val_categorical_accuracy: 0.9635\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1364 - categorical_accuracy: 0.9487 - val_loss: 0.1606 - val_categorical_accuracy: 0.9583\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1187 - categorical_accuracy: 0.9643 - val_loss: 0.1639 - val_categorical_accuracy: 0.9635\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1059 - categorical_accuracy: 0.9576 - val_loss: 0.1670 - val_categorical_accuracy: 0.9635\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0997 - categorical_accuracy: 0.9665 - val_loss: 0.1678 - val_categorical_accuracy: 0.9635\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1028 - categorical_accuracy: 0.9554 - val_loss: 0.1677 - val_categorical_accuracy: 0.9688\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0854 - categorical_accuracy: 0.9665 - val_loss: 0.1697 - val_categorical_accuracy: 0.9688\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0998 - categorical_accuracy: 0.9598 - val_loss: 0.1737 - val_categorical_accuracy: 0.9688\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1159 - categorical_accuracy: 0.9621 - val_loss: 0.1756 - val_categorical_accuracy: 0.9635\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1064 - categorical_accuracy: 0.9598 - val_loss: 0.1821 - val_categorical_accuracy: 0.9635\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1155 - categorical_accuracy: 0.9531 - val_loss: 0.1864 - val_categorical_accuracy: 0.9635\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1183 - categorical_accuracy: 0.9531 - val_loss: 0.1824 - val_categorical_accuracy: 0.9583\n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1102 - categorical_accuracy: 0.9621 - val_loss: 0.1784 - val_categorical_accuracy: 0.9583\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1057 - categorical_accuracy: 0.9554 - val_loss: 0.1745 - val_categorical_accuracy: 0.9583\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1555 - categorical_accuracy: 0.9375 - val_loss: 0.1699 - val_categorical_accuracy: 0.9583\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1029 - categorical_accuracy: 0.9576 - val_loss: 0.1713 - val_categorical_accuracy: 0.9583\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0579 - categorical_accuracy: 0.9844 - val_loss: 0.1715 - val_categorical_accuracy: 0.9583\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0992 - categorical_accuracy: 0.9598 - val_loss: 0.1700 - val_categorical_accuracy: 0.9583\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1148 - categorical_accuracy: 0.9598 - val_loss: 0.1717 - val_categorical_accuracy: 0.9583\n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0951 - categorical_accuracy: 0.9643 - val_loss: 0.1688 - val_categorical_accuracy: 0.9635\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0924 - categorical_accuracy: 0.9665 - val_loss: 0.1605 - val_categorical_accuracy: 0.9688\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0815 - categorical_accuracy: 0.9643 - val_loss: 0.1549 - val_categorical_accuracy: 0.9688\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1029 - categorical_accuracy: 0.9576 - val_loss: 0.1537 - val_categorical_accuracy: 0.9688\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1310 - categorical_accuracy: 0.9554 - val_loss: 0.1571 - val_categorical_accuracy: 0.9688\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1232 - categorical_accuracy: 0.9665 - val_loss: 0.1615 - val_categorical_accuracy: 0.9635\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0880 - categorical_accuracy: 0.9710 - val_loss: 0.1700 - val_categorical_accuracy: 0.9635\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1143 - categorical_accuracy: 0.9531 - val_loss: 0.1788 - val_categorical_accuracy: 0.9583\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1285 - categorical_accuracy: 0.9554 - val_loss: 0.1872 - val_categorical_accuracy: 0.9583\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1113 - categorical_accuracy: 0.9487 - val_loss: 0.1949 - val_categorical_accuracy: 0.9635\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1367 - categorical_accuracy: 0.9487 - val_loss: 0.1974 - val_categorical_accuracy: 0.9635\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1275 - categorical_accuracy: 0.9487 - val_loss: 0.1906 - val_categorical_accuracy: 0.9583\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1362 - categorical_accuracy: 0.9509 - val_loss: 0.1704 - val_categorical_accuracy: 0.9583\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0881 - categorical_accuracy: 0.9643 - val_loss: 0.1542 - val_categorical_accuracy: 0.9688\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1106 - categorical_accuracy: 0.9665 - val_loss: 0.1513 - val_categorical_accuracy: 0.9688\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1147 - categorical_accuracy: 0.9509 - val_loss: 0.1571 - val_categorical_accuracy: 0.9635\n",
      "Epoch 475/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1240 - categorical_accuracy: 0.9509 - val_loss: 0.1731 - val_categorical_accuracy: 0.9635\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1040 - categorical_accuracy: 0.9665 - val_loss: 0.1872 - val_categorical_accuracy: 0.9635\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1321 - categorical_accuracy: 0.9576 - val_loss: 0.1958 - val_categorical_accuracy: 0.9635\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0877 - categorical_accuracy: 0.9732 - val_loss: 0.1982 - val_categorical_accuracy: 0.9635\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0951 - categorical_accuracy: 0.9710 - val_loss: 0.1958 - val_categorical_accuracy: 0.9635\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1162 - categorical_accuracy: 0.9531 - val_loss: 0.1900 - val_categorical_accuracy: 0.9635\n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1186 - categorical_accuracy: 0.9576 - val_loss: 0.1867 - val_categorical_accuracy: 0.9635\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0817 - categorical_accuracy: 0.9688 - val_loss: 0.1829 - val_categorical_accuracy: 0.9635\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1020 - categorical_accuracy: 0.9509 - val_loss: 0.1798 - val_categorical_accuracy: 0.9635\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.1303 - categorical_accuracy: 0.9397 - val_loss: 0.1775 - val_categorical_accuracy: 0.9583\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.0891 - categorical_accuracy: 0.9665 - val_loss: 0.1800 - val_categorical_accuracy: 0.9583\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1085 - categorical_accuracy: 0.9688 - val_loss: 0.1829 - val_categorical_accuracy: 0.9583\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0820 - categorical_accuracy: 0.9688 - val_loss: 0.1858 - val_categorical_accuracy: 0.9583\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1069 - categorical_accuracy: 0.9643 - val_loss: 0.1911 - val_categorical_accuracy: 0.9583\n",
      "Epoch 489/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1376 - categorical_accuracy: 0.9464 - val_loss: 0.1933 - val_categorical_accuracy: 0.9583\n",
      "Epoch 490/500\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.1047 - categorical_accuracy: 0.9598 - val_loss: 0.1946 - val_categorical_accuracy: 0.9635\n",
      "Epoch 491/500\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0909 - categorical_accuracy: 0.9621 - val_loss: 0.1967 - val_categorical_accuracy: 0.9635\n",
      "Epoch 492/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0727 - categorical_accuracy: 0.9688 - val_loss: 0.1932 - val_categorical_accuracy: 0.9635\n",
      "Epoch 493/500\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1092 - categorical_accuracy: 0.9576 - val_loss: 0.1887 - val_categorical_accuracy: 0.9635\n",
      "Epoch 494/500\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.0830 - categorical_accuracy: 0.9665 - val_loss: 0.1854 - val_categorical_accuracy: 0.9635\n",
      "Epoch 495/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1232 - categorical_accuracy: 0.9531 - val_loss: 0.1848 - val_categorical_accuracy: 0.9635\n",
      "Epoch 496/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0730 - categorical_accuracy: 0.9777 - val_loss: 0.1799 - val_categorical_accuracy: 0.9688\n",
      "Epoch 497/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0875 - categorical_accuracy: 0.9732 - val_loss: 0.1736 - val_categorical_accuracy: 0.9688\n",
      "Epoch 498/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.1062 - categorical_accuracy: 0.9598 - val_loss: 0.1683 - val_categorical_accuracy: 0.9688\n",
      "Epoch 499/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1020 - categorical_accuracy: 0.9621 - val_loss: 0.1681 - val_categorical_accuracy: 0.9635\n",
      "Epoch 500/500\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0911 - categorical_accuracy: 0.9665 - val_loss: 0.1687 - val_categorical_accuracy: 0.9635\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_encoded, batch_size = 200, epochs = 500, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0633 - categorical_accuracy: 0.9688\n",
      "loss (cross-entropy) : 0.06334622949361801\n",
      "test accuracy : 0.96875\n"
     ]
    }
   ],
   "source": [
    "# 정확도\n",
    "result = model.evaluate(X_test, y_test_encoded)\n",
    "\n",
    "print('loss (cross-entropy) :', result[0])\n",
    "print('test accuracy :', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델\n",
    "# 이진 분류\n",
    "# fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "# acc_ax = loss_ax.twinx()\n",
    "\n",
    "# loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "# loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "# loss_ax.set_xlabel('epoch')\n",
    "# loss_ax.set_ylabel('loss')\n",
    "# loss_ax.legend(loc='upper left')\n",
    "\n",
    "# acc = history.history['binary_accuracy']\n",
    "# val_acc = history.history['val_binary_accuracy']\n",
    "\n",
    "# acc_ax.plot(acc, 'b', label='train acc')\n",
    "# acc_ax.plot(val_acc, 'g', label='val acc')\n",
    "# acc_ax.set_ylabel('accuracy')\n",
    "# acc_ax.legend(loc='upper left')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 다중 분류\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "\n",
    "acc_ax.plot(acc, 'b', label='train acc')\n",
    "acc_ax.plot(val_acc, 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MLP 모델\n",
    "# 이진 분류\n",
    "fig, axes = plt.subplots(1, 2, figsize = (12, 4))\n",
    "\n",
    "sns.lineplot(x = range(len(history.history[\"loss\"])),\n",
    "             y = history.history[\"loss\"], ax = axes[0],\n",
    "             label = 'Training Loss')\n",
    "\n",
    "sns.lineplot(x = range(len(history.history[\"loss\"])),\n",
    "             y = history.history[\"val_loss\"], ax = axes[0],\n",
    "             label = 'Validation Loss')\n",
    "\n",
    "\n",
    "sns.lineplot(x = range(len(history.history[\"categorical_accuracy\"])),\n",
    "             y = history.history[\"categorical_accuracy\"], ax = axes[1],\n",
    "             label = 'Training Accuracy')\n",
    "\n",
    "sns.lineplot(x = range(len(history.history[\"categorical_accuracy\"])),\n",
    "             y = history.history[\"val_categorical_accuracy\"], ax = axes[1],\n",
    "             label = 'Validation Accuracy')\n",
    "axes[0].set_title(\"Loss\"); axes[1].set_title(\"Accuracy\")\n",
    "\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckdal/venv/mp_venv/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "model.save('../model/model_100_231211_2_epoch500.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03-2. RNN - 성능 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>9.924472</td>\n",
       "      <td>5.437760</td>\n",
       "      <td>16.093966</td>\n",
       "      <td>34.917622</td>\n",
       "      <td>151.029160</td>\n",
       "      <td>23.662046</td>\n",
       "      <td>16.038351</td>\n",
       "      <td>129.254013</td>\n",
       "      <td>42.001671</td>\n",
       "      <td>30.698189</td>\n",
       "      <td>120.998001</td>\n",
       "      <td>45.441139</td>\n",
       "      <td>47.977879</td>\n",
       "      <td>110.705086</td>\n",
       "      <td>50.572929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>16.359552</td>\n",
       "      <td>2.998557</td>\n",
       "      <td>12.931503</td>\n",
       "      <td>119.032211</td>\n",
       "      <td>45.824856</td>\n",
       "      <td>113.178497</td>\n",
       "      <td>131.724228</td>\n",
       "      <td>63.422493</td>\n",
       "      <td>114.784874</td>\n",
       "      <td>134.195648</td>\n",
       "      <td>88.537025</td>\n",
       "      <td>87.874741</td>\n",
       "      <td>126.493759</td>\n",
       "      <td>30.961140</td>\n",
       "      <td>149.614975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>28.981226</td>\n",
       "      <td>11.005153</td>\n",
       "      <td>10.501713</td>\n",
       "      <td>81.253159</td>\n",
       "      <td>81.924286</td>\n",
       "      <td>77.597328</td>\n",
       "      <td>90.256813</td>\n",
       "      <td>98.426567</td>\n",
       "      <td>71.599548</td>\n",
       "      <td>93.740395</td>\n",
       "      <td>104.135040</td>\n",
       "      <td>68.671860</td>\n",
       "      <td>95.473099</td>\n",
       "      <td>114.793884</td>\n",
       "      <td>63.180790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24.956261</td>\n",
       "      <td>7.135846</td>\n",
       "      <td>16.957922</td>\n",
       "      <td>7.740575</td>\n",
       "      <td>3.122910</td>\n",
       "      <td>4.644784</td>\n",
       "      <td>3.623511</td>\n",
       "      <td>3.526766</td>\n",
       "      <td>2.837470</td>\n",
       "      <td>6.240818</td>\n",
       "      <td>2.599354</td>\n",
       "      <td>3.236579</td>\n",
       "      <td>4.473602</td>\n",
       "      <td>6.060120</td>\n",
       "      <td>2.901892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>12.332101</td>\n",
       "      <td>7.578300</td>\n",
       "      <td>18.158735</td>\n",
       "      <td>119.052231</td>\n",
       "      <td>38.103939</td>\n",
       "      <td>102.778076</td>\n",
       "      <td>132.649734</td>\n",
       "      <td>56.182476</td>\n",
       "      <td>108.353302</td>\n",
       "      <td>128.010391</td>\n",
       "      <td>59.890751</td>\n",
       "      <td>110.785576</td>\n",
       "      <td>117.685890</td>\n",
       "      <td>31.542004</td>\n",
       "      <td>132.033340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>30.093987</td>\n",
       "      <td>59.041405</td>\n",
       "      <td>30.627752</td>\n",
       "      <td>10.745037</td>\n",
       "      <td>1.583387</td>\n",
       "      <td>4.301016</td>\n",
       "      <td>7.553125</td>\n",
       "      <td>1.945184</td>\n",
       "      <td>7.336160</td>\n",
       "      <td>27.930441</td>\n",
       "      <td>137.999695</td>\n",
       "      <td>14.299557</td>\n",
       "      <td>43.494587</td>\n",
       "      <td>122.158958</td>\n",
       "      <td>11.817131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>27.608139</td>\n",
       "      <td>23.696928</td>\n",
       "      <td>27.915325</td>\n",
       "      <td>38.170364</td>\n",
       "      <td>123.204643</td>\n",
       "      <td>36.351780</td>\n",
       "      <td>29.730982</td>\n",
       "      <td>5.521902</td>\n",
       "      <td>1.188966</td>\n",
       "      <td>30.792360</td>\n",
       "      <td>154.541473</td>\n",
       "      <td>14.303607</td>\n",
       "      <td>45.125725</td>\n",
       "      <td>133.548126</td>\n",
       "      <td>24.054884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>14.709100</td>\n",
       "      <td>17.596455</td>\n",
       "      <td>19.980736</td>\n",
       "      <td>43.646629</td>\n",
       "      <td>114.848457</td>\n",
       "      <td>61.407406</td>\n",
       "      <td>45.880585</td>\n",
       "      <td>122.197044</td>\n",
       "      <td>56.627579</td>\n",
       "      <td>56.748974</td>\n",
       "      <td>119.358849</td>\n",
       "      <td>51.230583</td>\n",
       "      <td>62.894932</td>\n",
       "      <td>112.625580</td>\n",
       "      <td>56.640041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>37.125217</td>\n",
       "      <td>8.850159</td>\n",
       "      <td>19.058865</td>\n",
       "      <td>119.954292</td>\n",
       "      <td>62.158768</td>\n",
       "      <td>94.701416</td>\n",
       "      <td>134.632767</td>\n",
       "      <td>73.803780</td>\n",
       "      <td>90.499092</td>\n",
       "      <td>142.788696</td>\n",
       "      <td>74.412376</td>\n",
       "      <td>92.303520</td>\n",
       "      <td>145.909821</td>\n",
       "      <td>53.419239</td>\n",
       "      <td>109.832878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>31.487349</td>\n",
       "      <td>51.922657</td>\n",
       "      <td>23.354895</td>\n",
       "      <td>10.503264</td>\n",
       "      <td>0.715396</td>\n",
       "      <td>3.940364</td>\n",
       "      <td>8.537649</td>\n",
       "      <td>4.957355</td>\n",
       "      <td>6.974284</td>\n",
       "      <td>21.189432</td>\n",
       "      <td>142.766418</td>\n",
       "      <td>13.521779</td>\n",
       "      <td>43.747990</td>\n",
       "      <td>121.580238</td>\n",
       "      <td>11.765368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2           3           4           5   \\\n",
       "539   9.924472   5.437760  16.093966   34.917622  151.029160   23.662046   \n",
       "308  16.359552   2.998557  12.931503  119.032211   45.824856  113.178497   \n",
       "491  28.981226  11.005153  10.501713   81.253159   81.924286   77.597328   \n",
       "17   24.956261   7.135846  16.957922    7.740575    3.122910    4.644784   \n",
       "398  12.332101   7.578300  18.158735  119.052231   38.103939  102.778076   \n",
       "..         ...        ...        ...         ...         ...         ...   \n",
       "212  30.093987  59.041405  30.627752   10.745037    1.583387    4.301016   \n",
       "785  27.608139  23.696928  27.915325   38.170364  123.204643   36.351780   \n",
       "366  14.709100  17.596455  19.980736   43.646629  114.848457   61.407406   \n",
       "446  37.125217   8.850159  19.058865  119.954292   62.158768   94.701416   \n",
       "221  31.487349  51.922657  23.354895   10.503264    0.715396    3.940364   \n",
       "\n",
       "             6           7           8           9           10          11  \\\n",
       "539   16.038351  129.254013   42.001671   30.698189  120.998001   45.441139   \n",
       "308  131.724228   63.422493  114.784874  134.195648   88.537025   87.874741   \n",
       "491   90.256813   98.426567   71.599548   93.740395  104.135040   68.671860   \n",
       "17     3.623511    3.526766    2.837470    6.240818    2.599354    3.236579   \n",
       "398  132.649734   56.182476  108.353302  128.010391   59.890751  110.785576   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "212    7.553125    1.945184    7.336160   27.930441  137.999695   14.299557   \n",
       "785   29.730982    5.521902    1.188966   30.792360  154.541473   14.303607   \n",
       "366   45.880585  122.197044   56.627579   56.748974  119.358849   51.230583   \n",
       "446  134.632767   73.803780   90.499092  142.788696   74.412376   92.303520   \n",
       "221    8.537649    4.957355    6.974284   21.189432  142.766418   13.521779   \n",
       "\n",
       "             12          13          14  \n",
       "539   47.977879  110.705086   50.572929  \n",
       "308  126.493759   30.961140  149.614975  \n",
       "491   95.473099  114.793884   63.180790  \n",
       "17     4.473602    6.060120    2.901892  \n",
       "398  117.685890   31.542004  132.033340  \n",
       "..          ...         ...         ...  \n",
       "212   43.494587  122.158958   11.817131  \n",
       "785   45.125725  133.548126   24.054884  \n",
       "366   62.894932  112.625580   56.640041  \n",
       "446  145.909821   53.419239  109.832878  \n",
       "221   43.747990  121.580238   11.765368  \n",
       "\n",
       "[160 rows x 15 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>25.297415</td>\n",
       "      <td>24.738119</td>\n",
       "      <td>13.825315</td>\n",
       "      <td>141.55397</td>\n",
       "      <td>25.708836</td>\n",
       "      <td>123.127533</td>\n",
       "      <td>145.452499</td>\n",
       "      <td>37.806629</td>\n",
       "      <td>141.609589</td>\n",
       "      <td>140.173065</td>\n",
       "      <td>51.290585</td>\n",
       "      <td>119.159897</td>\n",
       "      <td>129.32782</td>\n",
       "      <td>40.220798</td>\n",
       "      <td>124.801559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4           5   \\\n",
       "35  25.297415  24.738119  13.825315  141.55397  25.708836  123.127533   \n",
       "\n",
       "            6          7           8           9          10          11  \\\n",
       "35  145.452499  37.806629  141.609589  140.173065  51.290585  119.159897   \n",
       "\n",
       "           12         13          14  \n",
       "35  129.32782  40.220798  124.801559  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_angle_test = pd.DataFrame(X_test.iloc[13,:])\n",
    "df_angle_test = df_angle_test.transpose()\n",
    "df_angle_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "model_test = keras.models.load_model(\"../model/model_epoch500.h5\")\n",
    "# angle_test = np.array([[2.356400489807128906e+01,6.761012554168701172e+00,6.285949230194091797e+00,8.304659843444824219e+00,6.339200019836425781e+00,4.894902706146240234e+00,4.375961303710937500e+00,6.588742256164550781e+00,4.068197727203369141e+00,7.041219234466552734e+00,5.034504413604736328e+00,4.858801364898681641e+00,1.002417564392089844e+01,7.321394920349121094e+00,4.523040771484375000e+00]])\n",
    "# angle_test = df_\n",
    "print(encoder.inverse_transform(model_test.predict(df_angle_test))[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카메라 인덱스 확인\n",
    "# sudo apt-get install v4l-utils -y\n",
    "# v4l2-ctl --list-devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1702287010.722097    7169 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702287010.723405  147369 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.0.4-0ubuntu1~22.04.1), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "# 인식 결과를 단순히 출력하도록\n",
    "max_num_hands = 1\n",
    "actions = ['go', 'back', 'stop', 'left_spin', 'right_spin', 'speed_up', 'speed_down', 'bad_gesture']\n",
    "gestures = {\n",
    "    0:'go', 1:'back', 2:'stop', 3:'left_spin', 4:'right_spin', 5:'speed_up',\n",
    "    6:'speed_down', 7:'bad_gesture'}\n",
    "\n",
    "# encoder = OneHotEncoder(sparse_output = False)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=max_num_hands,                            \n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "model = keras.models.load_model(\"../model/model_100_231211_2_epoch500.h5\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "seq = []\n",
    "action_seq = [] \n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"카메라 연결 실패\")\n",
    "        # break\n",
    "        continue\n",
    "\n",
    "    img = cv2.flip(img, 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    result = hands.process(img)\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if result.multi_hand_landmarks is not None:\n",
    "\n",
    "        for res in result.multi_hand_landmarks:\n",
    "\n",
    "            joint = np.zeros((21, 3))\n",
    "\n",
    "            for j, lm in enumerate(res.landmark):\n",
    "                joint[j] = [lm.x, lm.y, lm.z]\n",
    "\n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19],:]\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],:]\n",
    "            v = v2 - v1 # [20,3]\n",
    "\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "\n",
    "            angles = []\n",
    "\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # [15,]\n",
    "            \n",
    "            angle = np.degrees(angle)\n",
    "\n",
    "            data = np.array([angle], dtype=np.float32)\n",
    "            \n",
    "            idx = encoder.inverse_transform(model.predict([data]))[0,0]\n",
    "\n",
    "            if idx in gestures.keys():\n",
    "                cv2.putText(img, text=gestures[idx].upper(), org=(int(res.landmark[0].x * img.shape[1]), int(res.landmark[0].y * img.shape[0] + 20)), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "            mp_drawing.draw_landmarks(img,\n",
    "                                      res,\n",
    "                                      mp_hands.HAND_CONNECTIONS\n",
    "                                    #   mp_hands.get_default_hand_landmarks_style(),\n",
    "                                    #   mp_hands.get_default_hand_connections_style()\n",
    "            )\n",
    "    \n",
    "    cv2.imshow('Test', img)\n",
    "\n",
    "    key = cv2.waitKey(5) & 0xFF\n",
    "\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
